<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Grasshoppermouse</title>
<link>https://blog.edhagen.net/index.html</link>
<atom:link href="https://blog.edhagen.net/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.340</generator>
<lastBuildDate>Tue, 21 Jan 2020 08:00:00 GMT</lastBuildDate>
<item>
  <title>Is evolutionary psychology impossible?</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2020-01-21-is-evolutionary-psychology-impossible/index.html</link>
  <description><![CDATA[ 




<p>Subrena Smith recently argued that “evolutionary psychology, as it is currently understood, is…impossible” (<a href="https://doi.org/10.1007/s13752-019-00336-4">Smith 2019</a>). I agree with most of Smith’s premises, which are based on the logic of evolution by natural selection, and I think other evolutionary psychologists would too. So why does Smith conclude that evolutionary psychology (EP) is impossible but I conclude the opposite? Well, actually, Smith provides an example of evolved psychology that she considers “highly plausible,” directly contradicting her strong conclusion that EP is impossible. As I will show, this highly plausible example shares essential features with broad swaths of research in EP.</p>
<p>Smith does a decent job capturing the core tenets of EP: much like the rest of the body, the brain comprises many distinct functional components, termed psychological adaptations. These evolved by natural selection to solve particular computational problems related to survival and reproduction in ancestral environments, otherwise known as the <em>environment of evolutionary adaptedness</em> (EEA).</p>
<p>According to EP, evidence for the existence of a psychological adaptation includes (1) evidence of a computational problem posed by the ancestral environment (e.g., recognizing different types of foods and other objects); (2) evidence or argument that solving this computational problem would have increased the biological fitness of ancestors with the trait relative to those without it (e.g., by enabling them to find more food); (3) evidence that humans have the computational ability to solve precisely this problem (e.g., are able to rapidly recognize a large number of objects), which would typically include details about the specific algorithms involved; and (4) evidence that the computational ability reliably develops in (almost) all humans (of at least one sex), in all environments that do not deviate too much from the EEA. Together, these are taken as evidence of <em>design</em> – qualities that have been recognized since antiquity to distinguish “beneficial” organism traits from other natural phenomena (Aristotle, Physics II 8), and for which Darwin’s theory of natural selection provides the modern scientific explanation (Darwin 1859; Williams 1966).</p>
<p>Vision and hearing are uncontroversial examples of psychological adaptations, whereas mate preferences that differ between the sexes are somewhat controversial examples.</p>
<p>Smith’s main critique of EP involves what she calls the “matching problem.” For a cognitive trait such as object recognition to be an adaptation, it must be the case that not only does this trait reliably develop in modern humans, but it must have reliably developed in ancestral humans too, which Smith terms “strong vertical homology”:</p>
<blockquote class="blockquote">
<p>For a contemporary trait to be a strong vertical homolog of an ancestral trait, the contemporary trait must be of the same kind as the ancestral one. It must also have the same function as the ancestral one, and must be related by descent to that ancestral trait as part of a continuous reproductive lineage extending back to the EEA. Additionally, it must be the case that the contemporary trait and the ancestral trait are of the same kind and have the same function because the present-day trait is descended from the ancestral trait.</p>
</blockquote>
<p>I agree, and I think most evolutionary psychologists would too. In essence, Smith has added more requirements to the already long list that distinguish adaptations from other traits.</p>
<p>Smith then identifies the “matching problem”: how can we know that ancestral humans had the cognitive trait in question? After all, cognitive traits don’t fossilize. Furthermore, complex cognitive abilities can be acquired via learning. As one example, Smith points to reading.</p>
<p>EP would exclude reading cognition as a possible psychological adaptation because reading abilities do not reliably develop in all humans – many populations are non-literate, and many individuals within populations can fail to learn how to read. Still, it’s not hard to imagine an alternate universe where EP emerges as a discipline after literacy had become essentially universal and the existence of non-literate populations had been forgotten. Reading would then satisfy all three criteria above: it’s a complex cognitive ability, it provides many benefits, and (in the alternate universe) it reliably develops in essentially all modern humans. Yet the inference that reading is an adaptation would be incorrect. As Smith argues:</p>
<blockquote class="blockquote">
<p>[E]volutionary psychological claims fail unless practitioners can show that mental structures underpinning present-day behaviors are structures that evolved in the EEA for the performance of adaptive tasks that it is still their function to perform. This is the matching problem.</p>
</blockquote>
<p>At first, it seems like the matching problem is insurmountable. How can we possibly know the mental structures of ancestors living hundreds of thousands or millions of years ago?</p>
<p>In the face of such a barrier to scientific investigation, Smith seems to favor what she views as the evolutionary alternative to EP, that “evolution fashioned the human mind as a domain-general or modestly modular learning system.” This leaves the impression that because (in her view) EP hypotheses cannot be tested, they are therefore false, and that because (in her view) a domain-general learning system can be tested, it is more likely to be true. No such inference is possible, of course. At best, based on her analysis, we would have to admit that EP hypotheses could be true but we can’t collect some of the evidence needed to test them.</p>
<p>Fortunately, Smith herself provides a solution to the matching problem:</p>
<blockquote class="blockquote">
<p>To appreciate the differences between good evolutionary biological inferences and the inferences made in evolutionary psychological studies such as the one described in the previous section, consider a highly plausible evolutionary account – the claim that the eye-blink reflex (corneal reflex) was selected for as a mechanism to protect the eye from injury (Hall 1945). There are several converging lines of evidence that give substance to this claim. The first is that the reflex is highly conserved, as it is found in all mammalian taxa, and even in other taxa such as avians. Thus, comparative methods suggest that the reflex is under genetic control and that it was retained in the lineage because of its function.<sup>1</sup></p>
</blockquote>
<p>So, it turns out that ordinary homology provides convincing evidence for strong vertical homology, and thus solves the matching problem.</p>
<p>Although not acknowledged by Smith, evolutionary psychologists emphasize the importance of comparative data, including both homologies and analogies (see Figure&nbsp;1).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-schmitt" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2020-01-21-is-evolutionary-psychology-impossible/SchmittPilcher.png" class="img-fluid figure-img" width="466"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Schematic representation of the different forms of evidence used to evaluate the validity of psychological adaptations. AI: artificial intelligence. Figure and caption from Schmitt and Pilcher (2004).</figcaption>
</figure>
</div>
</div>
</div>
<p>Broad swaths of evolutionary psychology draw on homologies between human psychology and the psychology of our primate and mammalian relatives. There is even an Oxford Handbook of Comparative Evolutionary Psychology (Vonk &amp; Shackelford 2012).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vonk" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2020-01-21-is-evolutionary-psychology-impossible/ComparativeEP.png" class="img-fluid figure-img" width="261"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Oxford Handbook of Comparative Evolutionary Psychology, Vonk &amp; Shackelford, Eds. (2012).</figcaption>
</figure>
</div>
</div>
</div>
<p>Examples of comparative evolutionary psychology include spatial memory (Haun et al.&nbsp;2006), pathogen avoidance (Schaller 2015), attachment and maternal care (Maestripieri &amp; Roney 2006), the expression of emotions (Darwin 1872), prosociality (Silk and House 2012), the biological roots of music (Hagen and Hammerstein, 2009), and social learning (Whiten 2017). To the degree that the evidence supports homology (and can rule out analogy), we can be confident that human ancestors possessed the trait in question.</p>
<p>Keep in mind that Smith is arguing that EP is impossible <em>in principle</em>. The strength or weakness of the empirical evidence in each of the above examples, which varies quite a bit, is therefore not at issue. At issue is whether it is <em>possible</em> to provide convincing evidence of homology, and thus that human ancestors possessed the cognitive mechanisms in question. The eye-blink and other examples make clear that it is, and that evolutionary psychologists are attuned to the theoretical importance of homologies between psychological traits in humans and those in our relatives. By Smith’s own criteria, much EP is possible.</p>
<p>Putative psychological adaptations that are unique to the human lineage, however, present difficulties. One can no longer invoke homology as evidence that cognitive structures that reliably develop in modern humans also did so in ancestral humans. Language is an ideal example because language abilities are not present in chimpanzees or other primate relatives. Indeed, although some evolutionary psychologists argue that language has all the hallmarks of adaptation, such as complex cognitive design, fitness benefits, and reliable development in all humans (e.g., Pinker and Bloom 1990; Pinker and Jackendoff 2005), other evolutionary and cognitive researchers argue that there was no selection for language specifically and that it instead emerges, e.g., as a byproduct of cognitive abilities such as recursion (Hauser et al.&nbsp;2002) or from learning and other cognitive biases and coordination with others (Christiansen and Chater 2008).</p>
<p>As Smith repeatedly notes, psychological adaptations, like other adaptations, are inherited genetically. She fails to acknowledge, though, that we now have the complete sequence of the human genome, and the genome contains information on human-specific positive selection (I blog about genetic evolution in the human lineage <a href="../../2018/03/03/while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists/">here</a>). We do not yet have the knowledge to link the development of most human adaptations, psychological or physiological, to specific sequences in the genome. But when it comes to language, there is progress. Rare mutations in FOXP2, a transcription factor, appear to disrupt language development, suggesting that FOXP2 plays a critical role in language. There is evidence that transcriptional enhancers in the FOXP2 locus underwent accelerated evolution in the human lineage (Caporale et al.&nbsp;2019).</p>
<p>At this point, such evidence is suggestive at best. Genes have multiple effects and it could be that positive selection on FOXP2 regulation was due to non-language or non-cognitive effects of FOXP2. It could also be that FOXP2 influences language via, e.g., its effects on aspects of cognition that are not specific to language, such as recursion, and it was these abilities that underwent recent positive selection. Still, these results indicate that in coming years it might be possible to test EP and other adaptationist hypotheses using genetic data.</p>
<p>But even without genetic data, it is possible to test adaptationist hypotheses about species-specific adaptations. Imagine, for instance, that species X, which is living in an environment disturbed by recent human activity, has a complex soft-tissue trait that reliably develops in all members of the species. This trait doesn’t fossilize, it does not appear in any other species, and its genetic basis is unknown. It could be that this trait is a non-functional developmental consequence of novel environmental factors – perhaps chemical pollutants. But it could be an adaptation. Research on the trait, its relationship to what we know about the species’ ancestral environment, how the species makes a living, and on the underlying developmental mechanisms, as well as theoretical advances, can either indicate <em>design</em> or the lack thereof, and thus add weight to an adaptationist or non-adaptationist hypothesis, respectively. This approach characterizes research on menopause, which only occurs in humans and four species of toothed whales, and for which there are many competing hypotheses involving adaptation vs.&nbsp;byproduct of senescence (e.g., Kirkwood &amp; Shanley 2010; Johnstone &amp; Cant 2019). Yet according to Smith, in such cases scientists should just throw up their hands.</p>
<p>Smith’s view of science is myopic. Abduction, i.e., inference to the best explanation, is the cornerstone of scientific methodology (Douven 2017). Scientific hypotheses compete with one another to provide the “best” explanation of some phenomenon, where “best” typically involves criteria like accurately predicting new and surprising observations, parsimony, and coherence. Abduction specifically does not require that scientists produce direct evidence for every single entailment of the hypothesis. The eye-blink adaptation hypothesis entails a genetic basis for the reflex, yet Smith is willing to accept the hypothesis without direct evidence for eye-blink genes. “Strong vertical homology” is just another of the many criteria any hypothesis of complex adaptation must meet, and not the most important one (that honor belongs to <em>design</em>). And, contra Smith, more such criteria make a theory more testable, not less, because there are now more ways to falsify it. EP hypotheses make many unique predictions that are testable in living humans, and are thus able to compete with other hypotheses to explain language and other cognitive phenomena.</p>
<p>Smith, nevertheless, is right to draw attention to the importance of homology and the comparative method in testing adaptationist hypotheses. And to be fair, EP probably under-utilizes this powerful tool. She is wrong to ignore the many EP studies that do employ the comparative method, however, and she incorrectly concludes that if evidence for one of the many predictions of an adaptationist hypothesis is currently missing (e.g., evidence of “strong vertical homology”) it is therefore impossible to test that hypothesis against competing hypotheses.</p>
<p><em>Many thanks to Laith Al-Shawaf for helpful comments on an earlier draft.</em></p>
<p><em>2020/01/25: Added refs for menopause example.</em></p>
<section id="references" class="level1">
<h1>References</h1>
<p>Caporale, A. L., Gonda, C. M., &amp; Franchini, L. F. (2019). Transcriptional Enhancers in the FOXP2 Locus Underwent Accelerated Evolution in the Human Lineage. Molecular biology and evolution, 36(11), 2432-2450.</p>
<p>Christiansen, M. H., &amp; Chater, N. (2008). Language as shaped by the brain. Behavioral and Brain Sciences, 31(5), 489-509.</p>
<p>Darwin, C (1859) On the Origin of Species. John Murray.</p>
<p>Darwin, C (1872) The Expression of the Emotions in Man and Animals. John Murray.</p>
<p>Douven, Igor, “Abduction”, The Stanford Encyclopedia of Philosophy (Summer 2017 Edition), Edward N. Zalta (ed.), <a href="https://plato.stanford.edu/archives/sum2017/entries/abduction/" class="uri">https://plato.stanford.edu/archives/sum2017/entries/abduction/</a>.</p>
<p>Hagen EH and Hammerstein P (2009). Did Neanderthals and other early humans sing? Seeking the biological roots of music in the loud calls of primates, lions, hyenas, and wolves. Musicae Scientiae, 291-320.</p>
<p>Haun, D. B., Call, J., Janzen, G., &amp; Levinson, S. C. (2006). Evolutionary psychology of spatial representations in the hominidae. Current Biology, 16(17), 1736-1740.</p>
<p>Hauser, M. D., Chomsky, N., &amp; Fitch, W. T. (2002). The faculty of language: what is it, who has it, and how did it evolve? Science, 298(5598), 1569-1579.</p>
<p>Johnstone, R. A., &amp; Cant, M. A. (2019). Evolution of menopause. Current Biology, 29(4), R112-R115.</p>
<p>Kirkwood, T. B., &amp; Shanley, D. P. (2010). The connections between general and reproductive senescence and the evolutionary basis of menopause. Annals of the New York Academy of Sciences, 1204(1), 21-29.</p>
<p>Maestripieri, D., &amp; Roney, J. R. (2006). Evolutionary developmental psychology: Contributions from comparative research with nonhuman primates. Developmental Review, 26(2), 120-137.</p>
<p>Pinker, Steven, and Paul Bloom. “Natural language and natural selection.” Behavioral and brain sciences 13.4 (1990): 707-727.</p>
<p>Pinker, S., &amp; Jackendoff, R. (2005). The faculty of language: what’s special about it?. Cognition, 95(2), 201-236.</p>
<p>Schaller, M. (2015). The behavioral immune system. The Handbook of Evolutionary Psychology.</p>
<p>Schmitt, D. P., &amp; Pilcher, J. J. (2004). Evaluating evidence of psychological adaptation: How do we know one when we see one?. Psychological Science, 15(10), 643-649.</p>
<p>Silk, J. B., &amp; House, B. R. (2012). The Phylogeny and Ontogeny of Prosocial Behavior. The Oxford Handbook of Comparative Evolutionary Psychology, 381.</p>
<p>Smith, S. E. (2019). Is Evolutionary Psychology Possible? Biological Theory. https://doi.org/10.1007/s13752-019-00336-4</p>
<p>Vonk, J., &amp; Shackelford, T. K. (Eds.). (2012). The Oxford Handbook of Comparative Evolutionary Psychology. OUP USA.</p>
<p>Whiten, A. (2017). Social learning and culture in child and chimpanzee. Annual Review of Psychology, 68, 129-154.</p>
<p>Williams, G. C. (1966) Adaptation and Natural Selection. Princeton University Press.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Smith provides additional lines of evidence for an eye-blink adaptation that are either the same as standard adaptationist arguments and/or do not address the matching problem: “Second, it is clear that the eye-blink reflex protects the eye from injury in the taxa where it is found. Third, it is clear that the fitness of organisms that rely on vision would be impeded if there were not some mechanism for protecting the eye from injury. Fourth, the physiological mechanism underpinning the reflex is well understood. Fifth and finally, the reflex operates automatically, and is therefore mandatory. It is not “up to” the organism whose reflex it is. These five factors, taken together, support the claim that the eye-blink reflex in contemporary humans is strongly vertically homologous to the eye-blink reflex in earlier members of the lineage.”↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2020-01-21-is-evolutionary-psychology-impossible/index.html</guid>
  <pubDate>Tue, 21 Jan 2020 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2020-01-21-is-evolutionary-psychology-impossible/Gabriel_Cornelius_von_Max.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>About 90% of the genome is junk, which is very informative about ancestry but says little about biology</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/index.html</link>
  <description><![CDATA[ 




<p>The genome, taken as a whole, has a profound influence on our biology. Many scientists, myself included, see it as a blueprint for the organism, or perhaps more accurately, as <a href="../../2018/06/25/the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/">I explain here</a>, a program that generates the entire organism. Why, then, have many geneticists concluded that about 90% of the human genome has no influence on the human organism whatsoever, that it’s “junk”? And if most of the genome is junk, how can it reveal anything about an individual’s ancestry?</p>
<p>I’ll explain why most genetic differences among individuals and populations are probably differences in junk DNA, and therefore, perhaps counter-intuitively, are incredibly informative about ancestry but say little about biology.</p>
<section id="why-is-most-of-the-genome-thought-to-be-junk" class="level1">
<h1>Why is most of the genome thought to be junk?</h1>
<section id="clue-1-huge-variation-in-eurkaryotic-genome-size" class="level2">
<h2 class="anchored" data-anchor-id="clue-1-huge-variation-in-eurkaryotic-genome-size">Clue #1: huge variation in eurkaryotic genome size</h2>
<p>In the 1940’s and 50’s, biologists determined that the quantity of DNA was remarkably <em>constant</em> in cells from the same species, and therefore dubbed this quantity the “C-value”, but that it was quite variable across cells from different species. Importantly, the C-value, which we now know is the size of the genome (i.e., the number of nucleotides, or “letters”), bears little obvious relationship to the complexity of the organism. Some amoeba, for instance, which are single-celled organisms, have genomes that are 100x larger than the human genome (<a href="https://www.cell.com/current-biology/pdf/S0960-9822(12)01154-2.pdf">Eddy 2012</a>). The human genome contains eight times more DNA than that of a puffer fish but 40 times less than that of a lungfish, and among the &gt;200 salamander genomes analyzed as of 2014, all are between 4 and 35 times larger than the human genome (<a href="https://doi.org/10.1371/journal.pgen.1004351">Palazzo and Gregory 2014</a>). See Figure&nbsp;1 (note the logarithmic scale).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cvalue" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/journal.pgen.1004351.g001.png" class="img-fluid figure-img" width="1206"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Summary of haploid nuclear DNA contents (“genome sizes”) [in megabases] for various groups of eukaryotes. This graph is based on data for about 10,000 species. There is a wide range in genome sizes even among developmentally similar species, and there is no correspondence between genome size and general organism complexity. Humans, which have an average-sized genome for a mammal, are indicated by a star. <strong>Note the logarithmic scale.</strong> Figure and caption from <a href="https://doi.org/10.1371/journal.pgen.1004351">Palazzo and Gregory 2014</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Why would the “blueprints” of some simple organisms be so much larger than those of more complex ones, and why would the genomes of very closely related species often differ so dramatically? It is hard to escape the conclusion that a substantial fraction of a large genome has little, if any, influence on the phenotype of the organism. What, then, explains the expansion in genome size in some lineages?</p>
</section>
<section id="clue-2-pervasive-parasitic-dna" class="level2">
<h2 class="anchored" data-anchor-id="clue-2-pervasive-parasitic-dna">Clue #2: pervasive parasitic DNA</h2>
<p>A key property of DNA is that it can copy itself. Typically, this serves to make a <em>new</em> copy of the genome in a daughter cell, but sometimes sections of DNA copy themselves from one part of the genome into another, a type of mutation that often causes disease (<a href="https://doi.org/10.1186/s13100-016-0065-9">Hancks &amp; Kazazian, 2016</a>). These sequences of DNA, termed <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2874221/"><em>transposons</em></a>, are considered to be <a href="https://en.wikipedia.org/wiki/Selfish_genetic_element"><em>selfish</em> or <em>parasitic</em> DNA</a> because they have evolved features that increase their own replication at the expense of other genes in the genome, e.g., by inserting themselves into or near a gene and thus disrupting its function, consequently harming the organism itself.</p>
<p>There are two major classes of transposons. <a href="https://en.wikipedia.org/wiki/Transposable_element#DNA_transposons">DNA transposons</a> operate by a <em>cut</em>-and-paste mechanism – so-called “jumping genes” – and make up only about 3% percent of the human genome. <a href="https://en.wikipedia.org/wiki/Retrotransposon">Retrotransposons</a>, in contrast, operate by a <em>copy</em>-and-paste mechanism, and therefore increase the size of the genome (see Figure&nbsp;2). Retrotransposons make up at least 45% of the human genome (<a href="https://doi.org/10.1038/nrg2640">Cordaux and Batzer 2009</a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-retrotransposon" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/retrotransposons.png" class="img-fluid figure-img" width="512"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Retrotransposon. Figure from <a href="https://commons.wikimedia.org/wiki/File:Retrotransposons.png">Wikimedia.org</a></figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Alu_element"><em>Alu</em></a> and <a href="https://en.wikipedia.org/wiki/LINE1">LINE-1</a> retrotransposons in the human genome insert perhaps as frequently as once every 20 births (<a href="https://doi.org/10.1038/nrg2640">Cordaux and Batzer 2009</a>). Like other parasites, these copies can themselves make copies, and thus pose an extreme threat to other genes and to the organism itself. Many mechanisms have therefore evolved to neutralize them <a href="https://doi.org/10.1186/s13100-016-0070-z">(Goodier, 2016)</a>. To illustrate: due to their activity over the last 150 million years, there are &gt;500,000 <a href="https://en.wikipedia.org/wiki/LINE1">LINE-1</a> elements in the human genome, but less than 100 copies are currently active, i.e., able to replicate within the genome (<a href="https://doi.org/10.1038/nrg2640">Cordaux and Batzer 2009</a>).</p>
<p>The emerging picture, then, is that over evolution, lineages of retrotransposons have expanded, enlarging the genome (see Figure&nbsp;3). Inserted elements that disrupted gene function were removed by <a href="https://en.wikipedia.org/wiki/Negative_selection_(natural_selection)">negative selection</a> (<a href="https://doi.org/10.1080/2159256X.2017.1280116">Rishishwar et al., 2017</a>). Others were suppressed by cellular mechanisms, and then began to degrade due to accumulating mutations, becoming what we now call junk DNA (<a href="https://doi.org/10.1080/2159256X.2017.1280116">Rishishwar et al., 2017</a>), although there is solid evidence that transposable elements have often been co-opted for the regulation of host genes (<a href="https://doi.org/10.1038/nrg.2016.139">Chuong et al.&nbsp;2017</a>). Some particularly ancient retrotransposons might have degraded so extensively that they are no longer easily recognized. One analysis estimated that perhaps up to 70% of the human genome comprises such repetitive elements <a href="https://doi.org/10.1371/journal.pgen.1002384">(Koning, Gu, Castoe, Batzer, &amp; Pollock, 2011)</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-aluexpansion" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/aluexpansion.png" class="img-fluid figure-img" width="632"></p>
<figcaption class="figure-caption">Figure&nbsp;3: The expansion of Alu elements in primates. The expansion of Alu subfamilies (Yc1, Ya5a2, Yb9, Yb8, Y, Sg1, Sx and J) is superimposed on a tree of primate evolution. The expansion of the various Alu subfamilies is colour coded to denote the times of peak amplification. The approximate copy numbers of each Alu subfamily are also noted. Mya, million years ago. Figure and caption from <a href="https://doi.org/10.1038/nrg798">Batzer and Deininger 2002</a>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="clue-3-which-was-misleading-only-1-2-of-dna-codes-for-protein" class="level2">
<h2 class="anchored" data-anchor-id="clue-3-which-was-misleading-only-1-2-of-dna-codes-for-protein">Clue #3 (which was misleading): only 1-2% of DNA codes for protein</h2>
<p>The genetic code was cracked in the 1960’s: triplets of nucleotides (A,C,G,T) code for specific amino acids, the building blocks of proteins. Only about 1-2% of the genome codes for proteins, however. It was therefore often reported that the remaining 98-99% of the genome was junk, even though it was known <a href="https://en.wikipedia.org/wiki/Lac_operon">as early as 1961</a> that some non-coding DNA regulated the expression of protein-coding DNA. By the early 2000’s, however, it was widely recognized that much non-coding DNA plays a critical regulatory role <a href="https://doi.org/10.1101/gr.6339607">(Gerstein et al., 2007)</a>.</p>
<p>Thus, more than 1-2% of the genome is functional, but how much more?</p>
</section>
<section id="clue-4-about-90-of-the-genome-shows-no-evidence-of-sequence-conservation" class="level2">
<h2 class="anchored" data-anchor-id="clue-4-about-90-of-the-genome-shows-no-evidence-of-sequence-conservation">Clue #4: about 90% of the genome shows no evidence of sequence conservation</h2>
<p>The human genome has about 3 billion nucleotides. Every time the genome is copied, each nucleotide has a small probability that it will be miscopied, i.e., will mutate. In humans, there are a few dozen such mutations with each birth (<a href="https://doi.org/doi:10.1038/nature24018">Jonsson et al., 2017</a>). Mutations that alter organism functions will undergo positive or negative selection. Because most such mutations are harmful — there are many more ways to break something than to improve it — they will typically disappear from the population via negative selection. A fertilized zygote with a mutation in a critical part of the genome might not even successfully develop. DNA sequences in which most mutations face negative selection are termed <em>conserved</em> or <em>constrained</em>.</p>
<p>Mutations that do not alter organism function, on the other hand, e.g., those that that occur in sequences with no influence on the phenotype, will not experience positive or negative selection and will therefore accumulate at a more-or-less constant rate. Junk DNA can therefore be distinguished from functional DNA by its lack of conservation across species.</p>
<p>Protein coding sequences exhibit a surprising degree of conservation. Yeast and humans diverged about a billion years ago, for example, yet 23% of yeast genes have homologs in humans (i.e., the genes derive from a common ancestor). Of these genes, the amino acid sequences overlap, on average, by about 32%. Even more remarkable, after replacing 414 critical yeast genes with their human homologs, 47% of the human genes functioned and enabled the yeast to survive <a href="https://doi.org/10.1126/science.aaa0769">(Kachroo et al.&nbsp;2015)</a>.</p>
<p>A disadvantage of methods that assess DNA functionality by comparing degrees of sequence conservation across species is that they cannot identify functional sequences that might be recently acquired in a particular species. There might be functional sequences of DNA in the human genome, for instance, that do not appear in the genomes of chimps or other primates.</p>
<p>To assess what fraction of the human genome has been subject to negative selection on both long and short timescales, i.e., is constrained and is therefore likely to be functional, <a href="http://dx.doi.org/10.1371/journal.pgen.1004525">Rand et al.&nbsp;(2014)</a> analyzed DNA sequences across the mammals in several functional classes (i.e., protein coding sequences vs.&nbsp;various types of regulatory sequences that might have been acquired recently). They found that 7.1– 9.2% of the human genome is presently constrained, fairly consistent with previous results that found that between 3% and 15% of the human genome was functional. As expected, protein coding sequences were highly constrained, whereas regulatory sequences experienced more rapid turnover (see Figure&nbsp;4). This implies, of course, that &gt;90% of human DNA is not functional, i.e., is junk (for similar recent estimates, see <a href="https://doi.org/10.1126/science.1225057">Ward and Kellis, 2012</a>; <a href="https://doi.org/10.1038/ng.3196">Gulko et al., 2015</a>; and references therein).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-conserved" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/journal.pgen.1004525.g004.png" class="img-fluid figure-img" width="1032"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Model-based inference of turnover by functional class [across the mammals]. Schematic summary of the fraction of constrained sequence that has been retained (saturated colours) or turned over (pastel colours) in the human lineage over time (X-axis, divergence time) and how it has been distributed across various categories of functional element. In addition to showing the reduced quantity of preserved constrained sequence with increasing divergence, we infer the reciprocal quantity of sequence that is assumed to have been gained over human lineage evolution. For consistency this approach requires mutually exclusive annotation sets, in contrast to those used in Figure 3, making the results not directly comparable. Overlaps between the major different annotations are shown in Figure S10. Figure and caption from <a href="http://dx.doi.org/10.1371/journal.pgen.1004525">Rands et al.&nbsp;2014</a>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-encode-controversy" class="level1">
<h1>The ENCODE controversy</h1>
<p><a href="https://www.encodeproject.org">ENCODE</a> is a large consortium of research groups whose <a href="https://www.encodeproject.org/help/project-overview/">goal</a> is to “build a comprehensive parts list of functional elements in the human genome, including elements that act at the protein and RNA levels, and regulatory elements that control cells and circumstances in which a gene is active.” Their methods for identifying function primarily involve detecting evidence that a nucleotide participates in a biochemical RNA- and/or chromatin-associated event.</p>
<p>In 2012, ENCODE <a href="https://doi.org/10.1038/nature11247">published</a> their first analysis of functionality across the entire human genome. This was an enormously important milestone, but one claim stood out:</p>
<blockquote class="blockquote">
<p>“These data enabled us to assign biochemical functions for 80% of the genome” (p.&nbsp;57).</p>
</blockquote>
<p>ENCODE appeared to be challenging all the evidence I’ve reviewed here that most of the genome is junk. Several news commentaries trumpeted the death of the junk DNA concept (see refs in <a href="https://doi.org/10.1093/gbe/evt028">Graur et al., 2013</a>).</p>
<p>Biting critiques soon followed (<a href="https://doi.org/10.1016/j.cub.2012.10.002">Eddy, 2012</a>; <a href="https://doi.org/10.1073/pnas.1221376110">Doolittle, 2013</a>; <a href="https://doi.org/10.1093/gbe/evt028">Graur et al., 2013</a>; <a href="10.1016/j.bbrc.2012.12.074">Niu &amp; Jiang, 2013</a>; and <a href="https://doi.org/10.1371/journal.pgen.1004351">Palazzo &amp; Gregory, 2014</a>). These researchers noted that ENCODE employed an unusually broad definition of “function” based on the <a href="https://www.iep.utm.edu/func-exp/">causal role</a> account, which assigns “functions” to biochemical effects of nucleotide sequences, regardless of whether those effects evolved by natural selection. By ENCODE standards, the thumping sound of the heart is a “function” of the heart because the heart causes those sounds as part of a larger “noise-making” system, and the disabling effects of dangerous genetic birth defects are also “functional” (e.g., <a href="https://doi.org/10.1093/gbe/evt028">Graur et al., 2013</a>). ENCODE’s approach does have some defenders, however (e.g., <a href="https://doi.org/10.1007/s10539-014-9441-3">Germain et al., 2014</a>).</p>
<p>Much of the ENCODE claim of functionality rests on evidence that a sequence is <a href="https://en.wikipedia.org/wiki/Transcription_(biology)">transcribed</a> into RNA. According to the critics, transcription is an inherently noisy process that occurs in most of the genome regardless of evolved functionality, and that most transcripts are probably junk (e.g., <a href="https://doi.org/10.3389/fgene.2015.00002">Palazzo and Lee, 2015</a>), although here, too, there is push back (e.g., <a href="https://doi.org/10.1016/j.tig.2017.08.002">Jandura and Krause, 2017</a>).</p>
<p>Although the ENCODE claim of 80% functionality has found some defenders, I favor a definition of “function” that is based on natural selection, and therefore remain skeptical that most of the genome is functional in this sense.</p>
</section>
<section id="why-is-junk-dna-ideal-for-revealing-ancestry" class="level1">
<h1>Why is junk DNA ideal for revealing ancestry?</h1>
<p>If most of the human genome is junk DNA, as it appears to be, then most genetic differences among individuals and populations are differences in junk DNA that have no biological significance. It turns out, though, that lack of biological significance is ideal for inferring ancestry.</p>
<p>Every person inherits half their DNA from each parent. Each parent, in turn, inherited half their DNA from each of their two parents, and so forth. Thus, each section of one’s DNA has its own unique lineage of ancestors. Due to random copying errors, a small number of changes in DNA sequence are introduced with each transmission from parent to offspring. Over generations each section of DNA will therefore acquire a unique “fingerprint” of variations. Sections of DNA that are inherited from a recent common ancestor will have very similar fingerprints, whereas those inherited from a more distant common ancestor will have more distinct fingerprints. By comparing an individual’s patterns of variations with a large database of such patterns across the entire genome, from individuals living around the world, it is possible to estimate which sections of DNA share recent common ancestors from which locations. Because random errors accumulate with each generation according to the mutation rate, the degree of similarity or difference also provides an estimate of the number of generations, and hence years, to those common ancestors.</p>
<p>To illustrate with my two daughters: They each inherited one chromosome 6 from me, and one from my wife. My dad has Norwegian ancestry and my mom has Ashkenazi Jewish ancestry. So, with 50-50 probability (and ignoring <a href="https://en.wikipedia.org/wiki/Genetic_recombination">recombination</a>), the chromosome 6 my daughters inherited from me might more closely resemble chromosome 6’s from Northern Europe or those from central European Jewish communities. My wife has Mexican American background, with a great-great grandparent with African background. So the chromosome 6 they inherited from her might more closely resemble those of Spanish, Portuguese, or other Europeans (with 90.6% probability), Native Americans (with 6.25% probability), or Africans (with 3.125% probability). See Figure&nbsp;5.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-globalancestry" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/globalancestry.png" class="img-fluid figure-img" width="505"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Global Ancestry. The green arrows symbolize migration of early human ancestors out of Africa. The color mosaic denotes global population diversity resulting from various subsequent inter- and intra-continental and regional migrations. The pedigree represents the complex network of intermediate and recent ancestors that is the subject of individual genetic genealogy testing. Figure and caption from <a href="https://doi.org/10.1016/j.ajhg.2010.03.011">Royal et al.&nbsp;2010</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Figure&nbsp;6 is the output of one popular computer program for determining ancestry from DNA sequences. Each thin vertical line is one individual, and the different colors represent the fractions of their DNA sequences that more closely match individuals from different regions. My daughters would be mostly green, with some purple and a dash of red. President Obama would (probably) have a line that is about half green and half red.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ancestry" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/ancestry.jpg" class="img-fluid figure-img" width="640"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Regional ancestry inferred with the frappe program at K = 7 (13) and plotted with the Distruct program (31). Each individual is represented by a vertical line partitioned into colored segments whose lengths correspond to his/her ancestry coefficients in up to seven inferred ancestral groups. Population labels were added only after each individual’s ancestry had been estimated; they were used to order the samples in plotting. Figure and caption from <a href="https://doi.org/10.1126/science.1153717">Li et al.&nbsp;2009</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Such inferences of ancestry for each section of DNA assume that the patterns of variation in those sections result only from descent with <em>random</em> copying errors due to the mutation rate. These assumptions hold for junk DNA. If there were processes that caused sequences with distant common ancestors to closely resemble each other, however, or sequences with recent common ancestors to sharply diverge from one another, a geneticist might mistakenly conclude that some sequences have more recent vs.&nbsp;more distant common ancestors than they actually do, and incorrectly infer ancestry. In functional DNA, this can occur due to positive, negative, or frequency dependent selection, i.e., factors related to the environment rather than ancestry. Conserved sequences – those under negative selection – will have fewer differences than expected given the mutation rate, for instance, and will therefore appear to have a more recent common ancestor than they actually do.</p>
<!-- To give one example, distantly related pastoralist populations in Africa and Europe independently evolved very similar sequence variants in the promoter region of the lactase gene on chromosome 2 that allow adults to digest lactose, a remarkable example of recent convergent evolution under very strong positive selection in humans ([Tishkoff et al. 2007](https://doi.org/10.1038/ng1946)). A naive analysis might mistakenly infer that some distantly related European and African individuals had a recent common ancestor for this section of chromosome 2. -->
<p>In short, in functional DNA, patterns of variation due to ancestry (and also to population history) are confounded with patterns of variation due to natural selection (e.g., <a href="https://doi.org/10.1371/journal.pbio.0020286">Akey et al.&nbsp;2004</a>, <a href="https://doi.org/10.1126/science.1124309">Sabeti et al.&nbsp;2006</a>, <a href="https://doi.org/10.1101/gr.088336.108">Nielsen et al.&nbsp;2009</a>).</p>
<p>Using pure junk DNA to infer ancestry would be ideal, and several studies have used <em>Alu</em> insertions to investigate human ancestry and demography (<a href="https://doi.org/10.1080/2159256X.2017.1280116">Rishishwar et al., 2017</a>). Functional and non-functional DNA are intimately intertwined in the genome, however, and it is not entirely clear which non-coding sequences are functional and which are not. Ancestry is therefore typically inferred using common genetic variants across the genome (for a readable introduction to inferring ancestry from genetic data, see <a href="https://doi.org/10.1016/j.ajhg.2010.03.011">Royal et al., 2010</a>). Given that most DNA is junk, most common genetic variants should be junk, but are they?</p>
<p>Many studies have attempted to determine the functional consequences, if any, of coding and noncoding variants. Because the human genome is so <a href="../../2018/06/25/the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/">poorly understood</a>, these studies typically combine diverse sources of sequence, evolutionary, and functional information using use neural network and other machine learning methods to classify the variants according to their functional effects. One effort, <a href="https://doi.org/10.1073/pnas.1216613110">Bromberg et al.&nbsp;(2013, p.&nbsp;14255)</a>, concluded that:</p>
<blockquote class="blockquote">
<p>[V]ariants in seemingly healthy individuals tend to be neutral or weakly disruptive for protein molecular function. These variant effects are predicted to be largely either experimentally undetectable or are not deemed significant enough to be published. This may suggest that nondisease phenotypes arise through combinations of many variants whose effects are weakly nonneutral (damaging or enhancing) to the molecular protein function but fall within the wild-type range of overall physiological function.</p>
</blockquote>
<p>A recent review of methods assessing phenotypic effects of noncoding variants, on the other hand, was skeptical of their performance, concluding “A significant disconnect is found to exist between the statistical modelling and biological performance of predictive approaches” (<a href="https://doi.org/10.1038/s41467-018-08270-y">Liu et al.&nbsp;2019</a>). Part of the problem is that the methods stumble with the severe class imbalance: the small number of noncoding variants with meaningful effects among a relatively large number without such effects.</p>
<p>In summary, evidence to date is consistent with the view that most human DNA sequences are junk and are evolving neutrally. Variants in these sequences are yielding a rich trove of information on human ancestry and population history, but don’t tell us much about our biology.</p>
<p>None of the foregoing calls into question the profound importance of <em>functional</em> DNA to human biology. I write about <a href="../../2018/06/25/the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/">that here</a>, highlighting a perspective on the genome that hasn’t gotten much press. And <a href="../../2018/03/03/while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists/">here I write about</a> the relative influences of positive natural selection vs.&nbsp;random genetic drift on the evolution of the human lineage.</p>
</section>
<section id="concluding-remarks" class="level1">
<h1>Concluding remarks</h1>
<p>Each of our many ancestors indisputably lived at certain times and in certain places, and it’s pretty amazing that we can now glean those hard facts from spit in a tube. Living in a certain time and place, however, in and of itself, says nothing about the biology of those ancestors.</p>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/index.html</guid>
  <pubDate>Sat, 27 Jul 2019 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2019-07-27-about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/globalancestry.png" medium="image" type="image/png" height="110" width="144"/>
</item>
<item>
  <title>Should scientific publishing move to Github and friends?</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2019-07-12-should-scientific-publishing-move-to-github-and-friends/index.html</link>
  <description><![CDATA[ 




<p><em>TL;DR: Open access publishing has very high administrative overhead and is therefore too expensive. Github and similar services have substantial and perhaps insurmountable technical and funding advantages as publishing platforms. Scientific publications should therefore be <a href="https://git-scm.com">git</a> repos, created by the researchers themselves, that contain the manuscript, data, and analysis code, and that are hosted on, e.g., <a href="https:github.com">github</a>, <a href="https:gitlab.com">gitlab</a>, <a href="https://bitbucket.org">bitbucket</a>, <a href="http://sourceforge.net/">sourceforge</a>, and a <a href="https://git.wiki.kernel.org/index.php/GitHosting">few others</a>. A ‘journal’ would just be a <a href="https://help.github.com/en/enterprise/2.16/admin/user-management/creating-organizations">managed collection</a> of repos. Reviews would be handled via <a href="https://help.github.com/en/articles/about-issues">issues</a>. Long-term archiving and minting of <a href="https://en.wikipedia.org/wiki/Digital_object_identifier">doi’s</a> would be handled by <a href="https://zenodo.org">zenodo</a> or equivalent data archiving services. Journal reputations would be based on the reputations of the editors, who are typically researchers themselves.</em></p>
<p><strong>July 17, 2019: Added links at the end to researchers and journals that are already publishing on Github.</strong></p>
<p>Elsevier, the world’s largest publisher of scientific articles, just <a href="https://www.latimes.com/business/hiltzik/la-fi-uc-elsevier-20190711-story.html">cut off access</a> to its journals by the University of California, one of the world’s largest producers of scientific articles, because UC objected to Elsevier’s increasingly exorbitant subscription fees. Meanwhile, many funders of scientific research, mostly in Europe but also including the Gates Foundation, have signed on to <a href="https://en.wikipedia.org/wiki/Plan_S">Plan S</a>, which stipulates that research that is funded with money from supporting institutions must be published in open access journals or platforms.</p>
<p>Open access journals are expensive, though, typically charging $1000 or more per article. The reason they are so expensive is that administration and software development is expensive. <a href="https://arxiv.org">arXiv.org</a>, the famous physics/math preprint server that hosts articles for free, has a relatively small <a href="https://arxiv.org/about/people/leadership_team">leadership team</a> of six people, yet salaries alone amount to more than <a href="https://confluence.cornell.edu/download/attachments/340896260/2019%20CY%20arXiv%20budget%20estimate.pdf?api=v2">$1.3 million/year</a>. Add in indirect costs, and the total is about $2 million/year, covered by grants, memberships, and Cornell. Their servers and misc expenses are less than 1/10 of the total.</p>
<p>PLOS, PeerJ, and other open access journals cover their substantial administrative and development costs with publication fees that range from $1000-$3000/article, which is about what traditional journal publishers like Elsevier charge for open access.</p>
<p>The <a href="https://cos.io">Center for Open Science (COS)</a> and <a href="http://osf.io">osf.io</a> offer free preprint, preregistration, and file hosting services (full disclosure: I use osf.io, and we received one of their $1000 preregistration awards). They currently have about 50 employees and are spending in the neighborhood of <a href="https://cos.io/about/our-finances/">$7 million/year</a>, which, as far as I can tell, comes mostly from <a href="https://cos.io/about/our-sponsors/">grants</a>. As COS itself <a href="https://docs.google.com/document/d/1sqz3appQ73vqa6fP1Gy8KK8HZpotoSGaiJC1XQuvREI/edit#heading=h.f1yiz05siagv">admits</a>, sustainability is a major concern, and will probably involve charging fees to stakeholder communities, e.g., universities.</p>
<p>In sum, the multiple open science initiatives each have their own admin teams, incurring high administrative overhead, and are chasing a relatively small pool of users, many of whom have little funding or incentive to contribute to these public goods.</p>
<section id="how-does-the-open-source-software-community-do-it-for-free" class="level1">
<h1>How does the open source software community do it for free?</h1>
<p>The open source software community, like the science community, wants to give its products away for free in exchange for prestige. Their efforts have <a href="https://en.wikipedia.org/wiki/WorldWideWeb">transformed the planet</a>. Unlike science, however, open source developers pay nothing to publish their highly technical “documents” (code). How do they do it? In a word, <a href="https://github.com">Github</a>.</p>
<p>If you don’t know what Github is I describe it in a bit more detail below. For now, think of it as an online service for collaborating on software development. The open source community is allowed to use Github for free because the tech industry benefits tremendously from open source code and the talent that produces it. Open source is therefore subsidized by the fees commercial firms pay to use Github, which has estimated annual revenues of $250 million, and was acquired last year by Microsoft for $7.5 billion. Microsoft’s annual revenue is $110 billion. Gitlab, a similar service, has $10.5 million in annual revenue, and recently received <a href="https://about.gitlab.com/2018/09/19/announcing-100m-series-d-funding/">$100 million in venture capital</a>. Atlassian, which owns Bitbucket, yet another such service, offers a number of commercial collaboration services and has about $1 billion in annual revenue.</p>
<p>As of this writing, Github alone has over <a href="https://octoverse.github.com">30 million users working on close to 100 million projects</a>. The technological and financial investment in these platforms and the economies of scale are orders of magnitude larger than those enjoyed by any open science initiative.</p>
</section>
<section id="could-scientific-publishing-move-to-github" class="level1">
<h1>Could scientific publishing move to Github?</h1>
<!-- I think [Github](http://github.com) and similar cloud-based services that facilitate global collaboration on open source software projects could be those open platforms.  -->
<!-- (I will use the term 'Github' to refer to Github and all similar services, e.g., Gitlab, Bitbucket.) -->
<p>In 2011, Marcio von Muhlen argued that academia needed a <a href="https://marciovm.com/i-want-a-github-of-science">Github of science</a>. He made three key points:</p>
<ul>
<li><p>Publishing is central to Academia, but its publishing system is outclassed by what Open Source software developers have in GitHub</p></li>
<li><p>GitHub’s success is not just about openness, but also a prestige economy that rewards valuable content producers with credit and attention</p></li>
<li><p>Open Science efforts like arXiv and PLoS ONE should follow GitHub’s lead and embrace the social web</p></li>
</ul>
<p>Each of these points is just as true today as it was then. The only thing I would add is that the Github of science should be…Github. The costs of hosting scientific articles on Github or similar services, such as Gitlab and Bitbucket, would be a rounding error.</p>
<p>Moreover, much of science’s computational infrastructure is already developed on Github and friends. This includes <a href="https://github.com/python/cpython">python</a> and <a href="https://github.com/scipy/scipy">scipy</a>, <a href="https://github.com/tensorflow/tensorflow">machine learning frameworks</a>, <a href="https://github.com/tidyverse/tidyverse">key r packages</a>, and <a href="https://github.com/topics/scientific-computing">much more</a>.</p>
<p>Just like it benefits from open source software, the business community benefits tremendously from science. Instead of researchers paying the <a href="https://doi.org/10.1371/journal.pone.0127502">scientific publishing oligopoly</a> hefty <a href="(https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science)">fees</a> to publish tax-funded research, commercial businesses would subsidize the (small) cost for researchers to publish their research on git hosting services.</p>
<p>Sounds fair to me.</p>
<p>This proposal is not without risk. Microsoft’s purchase of Github, for instance, immediately <a href="https://www.forbes.com/sites/washingtonbytes/2018/08/29/microsoft-and-github-jaw-dropping-price-tag-brings-competitive-concerns/#67b0b8e95312">raised concerns</a> that it would use its control over Github to harm competitors that rely on the platform. What would stop Microsoft or Atlassian from exploiting their control of a scientific publishing platform? It’s also not clear that any of the git hosting services, which are investing heavily in growth, are profitable yet.</p>
<p>While these risks shouldn’t be ignored, I think they are no larger (and are probably much smaller) than the risks of using platforms, such as osf.io, that have no long-term funding plan in place. Researchers would retain copyright over their publications that carry open source licenses. Because git repos are an open standard, it’s trivial to host them on multiple platforms and to archive them on multiple data archiving services. Furthermore, the fees that Github, Gitlab, and Bitbucket charge commercial users are pretty small. Some of the plans are as low as $25-$50/user/year. Gitlab has a completely open source version of its cloud platform.</p>
<p>In summary, there is substantial overlap between programming and the data analysis and modeling that is at the heart of much science. Github and similar hosting services are used by millions of programmers and thousands of researchers every day. These services provide all the features necessary to support scientific journals: online submission, review, revision, and publication. Their business models appear viable, at least judged by the venture capital they are attracting, they are investing heavily in their IT infrastructure, and they enjoy huge economies of scale. Researchers and universities should not use their limited funds to support a small scientific publishing oligopoly that provides little added value. Nor should they fund multiple administrative teams at various open science initiatives that are reinventing the wheel. Instead, the tech industry and broader business community that benefits so heavily from science can subsidize the relatively small costs of publishing scientific research on shared IT platforms like Github, Gitlab, and Bitbucket. Who knows, the synergies of hosting scientific publications might be valuable enough that these services would even compete to attract scientists by developing science-specific features.</p>
<p>Now down to brass tacks. How would this actually work?</p>
</section>
<section id="what-is-git" class="level1">
<h1>What is git?</h1>
<p><em>Skip this part if you already know what git is.</em></p>
<p>Computer code is just a bunch of text files in a directory. Collaborating on code requires some way to allow multiple programmers to access and edit these files, track changes to them, and revert back to previous versions, if necessary. The solution that has almost universally been adopted is a <a href="https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control">distributed version control system (DVCS)</a>, and one in particular: <a href="https://git-scm.com">git</a>.</p>
<p>The <a href="https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository">basic workflow</a> is as follows: a programmer installs git on her own computer, and then starts a new software project by creating one or more text files in directory. She then runs the git initialization command, which creates a hidden directory inside that project directory. That directory is now a git repository (a <em>repo</em>). She creates a new feature in her software by editing one or more text files in the directory on her own computer, and <em>commits</em> those changes using another git command. This tracks the changes she’s made to each file, stamps the changes with the time, date, and her identity, and stores the changes in the hidden directory.</p>
<p>The programmer and her collaborators can then use git and numerous third-party tools to inspect precisely what changes have been made to which files, when, and by whom. Think of it like track-changes in Word, but on steroids.</p>
</section>
<section id="why-is-a-git-repo-a-good-format-for-a-scientific-publication" class="level1">
<h1>Why is a git repo a good format for a scientific publication?</h1>
<p>A research publication is just a bunch of files in a directory. These include the manuscript itself, the figure files, supplementary information files, and sometimes data and data-processing code files. In some cases, such as writing a single-authored commentary in Word, git would provide few, if any, advantages to the researcher. In many other cases, however, such as working with collaborators on an empirical study that analyzes data using, e.g., python, R, or matlab, git would provide the same enormous advantages that it provides to software developers. The researchers can easily track who is making what changes to which files, when, and where. Thousands of researchers are already using git for exactly this purpose. In addition, the manuscript itself can be written using text-based formats like <a href="https://www.latex-project.org"><img src="https://latex.codecogs.com/png.latex?%5CLaTeX"></a> or <a href="https://en.wikipedia.org/wiki/Markdown">markdown</a>, and all the advantages of git when writing code also apply to these text-based documents.</p>
<p>The most important advantage of git, though, is that it is a open standard, based on open software, that is used by millions of software developers and researchers around the world, and there is a large and growing IT infrastructure that can ‘speak’ git. This means that researchers can conduct their analyses on their own computers and then <em>seamlessly</em> share them with the public via services such as Github.</p>
</section>
<section id="what-is-github" class="level1">
<h1>What is Github?</h1>
<p><em>Skip this part if you know what Github is</em></p>
<p>When the programmer or researcher is ready to share her work, she uploads her git repo to a hosting service, which allows others to view the code, copy it to their own computers using git (cloning), make their own commits to the code using git, and then share any improvements they’ve made using git. Think of git + git hosting as track-changes combined with dropbox, but on steroids.</p>
<p>The most popular git hosting service is <a href="https://github.com">Github.com</a>, a proprietary cloud service, recently purchased by Microsoft, that ‘speaks git.’ (For a somewhat rah rah version of the Github story, see <a href="https://medium.com/@hnshah/how-github-democratized-coding-built-a-2-billion-business-and-found-a-new-home-at-microsoft-bd94d2dea2a9">this</a>.) <a href="https://gitlab.com">Gitlab</a> is another up-and-comer that, unlike Github, provides a pretty full-featured <a href="https://gitlab.com/gitlab-org/gitlab-ce">open source version</a> of its platform.</p>
<p>These hosting services also offer an issue tracking feature, which is basically a discussion board where developers or users can report bugs and request new features (issues).</p>
<p>Oh, and just to repeat, all open source projects can use Github and similar platforms for free.</p>
</section>
<section id="creating-a-scientific-journal-on-top-of-github" class="level1">
<h1>Creating a scientific journal on top of Github</h1>
<p>Typically, a researcher submits her manuscript to a journal by using its clunky web interface to upload a manuscript file, such as a Word doc or PDF, one or more figure files, one or more supplementary information files, and perhaps even data and code files. Numerous forms must be filled out that duplicate information in the manuscript itself. The process can easily take the better part of an afternoon. Yuck.</p>
<p>If git were the standard format for a research manuscript, the researcher would simply organize all the relevant files in a git repo on her own computer, and then push it to Github with single command or click of the mouse. Github et al.&nbsp;are fully capable of providing both html and pdf versions of scientific articles, just as all scientific publishers do today (this blog is hosted on Github). As long as scientific publications use an <a href="https://opensource.org/licenses">open source license</a> (and why wouldn’t they?), hosting would be free.</p>
<p>But how to create a journal that would comprise hundreds or thousands of repos created by diverse researchers? Github, Gitlab, and Bitbucket have a feature that allows a group of individuals to manage multiple repositories. Github calls these ‘organizations’, Gitlab calls them ‘groups’, and Bitbucket calls them ‘teams.’ I’ll use the Github terminology. To create a new journal, an editor and her associate editors create an organization on Github.</p>
<p>To get the journal off the ground I think the editor would have to be a highly regarded researcher in her discipline, which would create immediate buzz and trust. <em>I suspect this is key to the whole idea.</em></p>
<p>To submit an article to the journal, a researcher uploads a repository with all her data, analysis scripts, and a final version of her paper in pdf or html format to her own github account. She also assigns it an <a href="https://opensource.org/licenses">open source license</a>. She then messages the editor to consider her repo for publication. The editor looks at the repo and decides if it is suitable for her journal. If so, she clones the repo into her organization.</p>
<p>At this point, the repo might be private (not accessible to the public). The Editor then recruits reviewers, who create issues on the issue tracker for the repo. Each issue is one comment/critique that the author(s) will have to address.</p>
<p>The authors make changes to their manuscript and code to address each issue, and then submit their revisions via, e.g., a <a href="https://help.github.com/en/articles/about-pull-requests">pull request</a>. If they are using a text-based format for their manuscript, Github will display the revisions similar to track-changes in Word.</p>
<p>Once the editor determines that an issue has been adequately addressed, she closes it. When all issues are closed, the editor decides if she wants to publish the study. If so, she gets a <code>doi</code> for it via, e.g., <a href="https://guides.github.com/activities/citable-code/">zenodo</a>, so the study is citable, and then makes the repo public.</p>
<p>Done!</p>
<p>Other researchers can <a href="https://help.github.com/en/articles/fork-a-repo">fork</a> the repo, or star it if they think its cool. Because the code is under an open source license, others can modify it and publish their own analysis (with proper attribution, of course).</p>
<p>There are many other possibilities for creating a scientific prestige economy on Github, but I’ll leave discussion of those for another time.</p>
</section>
<section id="researchers-and-journals-that-are-already-publishing-on-github" class="level1">
<h1>Researchers and journals that are already publishing on Github</h1>
<ul>
<li><p><a href="https://andrewgyork.github.io">andrewgyork.github.io</a></p></li>
<li><p><a href="http://rescience.github.io">http://rescience.github.io</a></p></li>
<li><p><a href="https://www.arfon.org/chatops-driven-publishing">https://www.arfon.org/chatops-driven-publishing</a></p></li>
<li><p><a href="https://manubot.org">https://manubot.org</a></p></li>
</ul>
<section id="publishing-with-jupyter-notebooks" class="level2">
<h2 class="anchored" data-anchor-id="publishing-with-jupyter-notebooks">Publishing with <a href="https://jupyter.org">Jupyter notebooks</a>:</h2>
<ul>
<li><p><a href="https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/">The Scientific Paper Is Obsolete (Atlantic)</a></p></li>
<li><p><a href="https://www.linuxjournal.com/content/jupyter-future-open-science">By Jupyter–Is This the Future of Open Science?</a></p></li>
<li><p><a href="https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks#reproducible-academic-publications">Reproducible academic publications</a></p></li>
</ul>


</section>
</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2019-07-12-should-scientific-publishing-move-to-github-and-friends/index.html</guid>
  <pubDate>Fri, 12 Jul 2019 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2019-07-12-should-scientific-publishing-move-to-github-and-friends/githubrepo.png" medium="image" type="image/png" height="123" width="144"/>
</item>
<item>
  <title>A theory of natural selection, 5th century BC</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2019-06-20-a-theory-of-natural-selection-5th-century-bc/index.html</link>
  <description><![CDATA[ 




<p><img src="https://blog.edhagen.net/posts/2019-06-20-a-theory-of-natural-selection-5th-century-bc/empedocles.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>How came the bodies of animals to be contrived with so much art, and for what ends were their several parts?</p>
<p>Isaac Newton, Opera Omnia, IV. 237.</p>
</blockquote>
<p>I’ve always been curious how far back in history the tool-like or machine-like properties of living things were recognized, and how these were explained.</p>
<p>It turns out that Darwin was scooped over 2000 years ago.</p>
<p>Plato clearly recognized that animals have functional traits that are usually, but not always, explained by the benefit they provide to the animal itself. Plato’s Protagoras, written c.&nbsp;390 BC, relates a version of the Prometheus creation myth in which various properties of animals are explained by their role in animal survival, e.g., an animal’s strength, speed, size, or weaponry is there to protect the animal. Thick hair or hard skins are there to protect against the seasons sent by Zeus. The animals are appointed different foods: some grass, others fruits. Those who eat other animals are few in number, whereas prey are bestowed with fertility so as to preserve the species.</p>
<p>Plato, however, did not limit beneficial “design” to living things, nor did animal traits always benefit the animal itself. In the Timaeus, written many years later, Plato proposed that a divine and supremely good Demiurge (craftsman) created the universe in precisely such a way that the universe as a whole, as well as its various parts, produce a vast number of good effects. He created the sun, moon, and stars to mark time, for instance, which itself came into being as an image of eternity (Zeyl and Sattler 2017). He created eyes for sight, “to the <em>end</em> that we might behold the courses of intelligence in the heaven, and apply them to the courses of our own intelligence which are akin to them,” that we “might imitate the absolutely unerring courses of God and regulate our own vagaries” (emphasis added).</p>
<p>Ancient atomists such as Democritus, a contemporary of Plato, eschewed such teleology. Instead, according to them, the universe is explained by the movements and interactions of a small number of indivisible particles in a void. The atomists offered ingenious arguments to explain many natural phenomena in terms of interactions of these indivisible particles – atoms – which have only a few intrinsic properties like size and shape, and strike against one another, rebounding and interlocking in an infinite void. Critically, there is no Demiurge. Causation is due only to blind necessity or chance (Berryman 2016).</p>
<p>Aristotle, perhaps writing around 330 BC, grappled with both the atomists and with Plato. To explain some phenomena, even those that benefited humanity, he invoked atomist arguments. Rain, for example, occurs of necessity, and itself has necessary and chance effects (Physics II 8):</p>
<blockquote class="blockquote">
<p>[W]hy should not nature work, not for the sake of something, nor because it is better so, but just as the sky rains, not in order to make the corn grow, but of necessity? What is drawn up must cool, and what has been cooled must become water and descend, the result of this being that the corn grows. Similarly if a man’s crop is spoiled on the threshing-floor, the rain did not fall for the sake of this – in order that the crop might be spoiled – but that result just followed.</p>
</blockquote>
<p>Parts of animals, though, according to Aristotle, cannot be explained (only) by blind necessity or chance. Teeth, for instance:</p>
<blockquote class="blockquote">
<p>…are admirably constructed for their general office, the front ones being sharp, so as to cut the food into bits, and the hinder ones broad and flat, so as to grind it to a pulp…. (Parts of Animals III 1).</p>
</blockquote>
<p>Because teeth grow this way in (almost) all humans, Aristotle goes on to argue, this pattern cannot be due to chance, contrary to the atomists. Instead, using a series of abductive arguments, Aristotle concludes that the parts of animals can only be explained by their purpose, a final cause (Ariew 2002). But no inference is made to a Platonic demiurge. Aristotle’s teleology, unlike Plato’s, is local, not global; it is immanent in the organism, not external to it (Ariew 2002; Schiefsky 2007).</p>
<p>How, though, did the atomists, who aimed to explain everything by blind necessity or chance, and certainly did not invoke final causes, explain the parts of animals? In a brief but remarkable passage, Aristotle refers to an argument by Empedocles, who lived in the 5th century BC:</p>
<blockquote class="blockquote">
<p>Wherever then all the parts [of animals] came about just what they would have been if they had come be for an end, such things survived, being organized spontaneously [i.e., by chance] in a fitting way; whereas those which grew otherwise perished and continue to perish, as Empedocles says his ‘man-faced ox-progeny’ did. (Physics II 8)</p>
</blockquote>
<p>When I read this, my heart skipped a beat. That is natural selection.</p>
<p>Could I have just made the remarkable discovery that Darwin was scooped by Empedocles in the 5th century BC? Uh, no. A quick google revealed that Darwin himself cited this passage in the preface to 4th edition of <em>Origin</em> as a historical forerunner to his theory (for details, see Gotthelf 2012). Even the Wikipedia <a href="https://en.wikipedia.org/wiki/Natural_selection">article on natural selection</a> mentions it. Dang!</p>
<p>It was Empedocles who claimed that everything is composed of exactly four elements – fire, air, earth, and water – which are moved by two opposing forces, Love and Strife. The four elements combine under the force of Love, and separate under the force of Strife (Perry 2016). Empedocles set forth his philosophy in poetry, only fragments of which survive. The lines describing the origins of animal parts are pretty trippy (Perry 2016):</p>
<blockquote class="blockquote">
<p>Here sprang up many faces without necks, arms wandered without shoulders, unattached, and eyes strayed alone, in need of foreheads (B 57).</p>
</blockquote>
<p>Under the force of Love, these parts randomly combine:</p>
<blockquote class="blockquote">
<p>Many creatures were born with faces and breasts on both sides, man-faced ox-progeny, while others again sprang forth as ox-headed offspring of man, creatures compounded partly of male, partly of the nature of female, and fitted with shadowy parts. (B 61)</p>
</blockquote>
<p>It is these random creatures that differentially survive if, by chance, they were organized in a “fitting way.”</p>
<p>This left me wondering: in a materialist account of the universe, which would only arise again in the West in full force following Galileo and Newton, is the idea of natural selection, in some sense, inevitable?</p>
<section id="references" class="level1">
<h1>References</h1>
<p>Ariew, A. (2002). Platonic and Aristotelian roots of teleological arguments. Functions: New readings in the philosophy of psychology and biology, 7-32.</p>
<p>Berryman, Sylvia, “Ancient Atomism”, The Stanford Encyclopedia of Philosophy (Winter 2016 Edition), Edward N. Zalta (ed.). https://plato.stanford.edu/archives/win2016/entries/atomism-ancient/</p>
<p>Gotthelf, A. (2012). Teleology, First Principles, and Scientific Method in Aristotle’s Biology. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199287956.001.0001</p>
<p>Parry, Richard, “Empedocles”, The Stanford Encyclopedia of Philosophy (Fall 2016 Edition), Edward N. Zalta (ed.), URL = <a href="https://plato.stanford.edu/archives/fall2016/entries/empedocles/" class="uri">https://plato.stanford.edu/archives/fall2016/entries/empedocles/</a>.</p>
<p>Schiefsky, M. (2007). Galen’s teleology and functional explanation. Oxford Studies in Ancient Philosophy, 33, 369-400.</p>
<p>Zeyl, Donald and Sattler, Barbara, “Plato’s Timaeus”, The Stanford Encyclopedia of Philosophy (Winter 2017 Edition), Edward N. Zalta (ed.). https://plato.stanford.edu/archives/win2017/entries/plato-timaeus/.</p>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2019-06-20-a-theory-of-natural-selection-5th-century-bc/index.html</guid>
  <pubDate>Thu, 20 Jun 2019 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2019-06-20-a-theory-of-natural-selection-5th-century-bc/empedocles.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Measles, mothers, leadership, and the evolution of big brains</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2019-03-21-measles-mothers-leadership-and-the-evolution-of-big-brains/index.html</link>
  <description><![CDATA[ 




<p><a href="https://en.wikipedia.org/wiki/Nancy_Pelosi">Nancy Pelosi</a> recently won a major conflict with Trump over border wall funding, and her victory flipped the media narrative. Instead of the insider who was out-of-step with both mainstream Americans and the progressive wing of her party, Pelosi was now seen as a masterful leader. The source of Pelosi’s moxie, according to many articles that appeared at the time, is that she’s a <a href="https://www.washingtonpost.com/lifestyle/style/makes-going-to-work-look-easy-how-being-a-full-time-mom-prepared-nancy-pelosi-for-this-moment/2019/02/12/416cd85e-28bc-11e9-984d-9b8fba003e81_story.html">mother of five</a>, and the daughter of another <a href="https://baltimorepostexaminer.com/nancy-pelosi-home-schooled-in-the-art-of-politics-by-her-mother-big-nancy/2019/01/06">powerful women who raised six kids</a>. Mothering and leadership, it seems, go together. What’s the link?</p>
<p>My grad student <a href="https://anthro.vancouver.wsu.edu/people/zgarfield/">Zach Garfield</a> and I believe we might have the answer. Despite the fact that almost all leaders in all societies are men, natural selection for leadership abilities might have been strongest in women, at least initially (<a href="https://doi.org/10.31219/osf.io/9bcdk">preprint</a>). I started thinking about this problem almost 20 years ago when the New Yorker and W.W. Norton published an article and book by Patrick Tierney that tried to profit from a measles vaccine scare, similar to the efforts of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3136032/">Andrew Wakefield</a> and <a href="https://en.wikipedia.org/wiki/Jenny_McCarthy#Activism">Jenny McCarthy</a> (the latter two have been depressingly successful – there is a <a href="https://www.clark.wa.gov/public-health/measles-investigation">measles outbreak</a> near our campus in southwest Washington).</p>
<p>Here’s the story of how an attempt to make a buck off a vaccine scare unearthed an important but virtually unknown theory by one of the fathers of American genetics, <a href="https://en.wikipedia.org/wiki/James_V._Neel">James Neel</a>.</p>
<p>Late in the summer of 2000, an email spread like, well, measles, through the anthropological community. Sent by two credulous anthropologists, it advertised an upcoming book and New Yorker article by Patrick Tierney that accused James Neel, an acclaimed geneticist, and Nap Chagnon, a well-known but controversial anthropologist, of deliberately administering a dangerous measles vaccine to native South Americans. This vaccine could supposedly cause or exacerbate a deadly measles epidemic, allowing Neel and Chagnon to study the effects of the disease in an indigenous population so as to test Neel’s sinister eugenics theory.</p>
<p>Prior to this I was vaguely aware of Neel’s work on the genetics of Native South Americans. Chagnon, on the other hand, I knew well. He was my MA thesis adviser. Our department chair therefore asked me and Michael Price, another grad student who had worked with Chagnon, to investigate. Along with John Tooby, a colleague of Chagnon (and chair of my PhD committee), we starting retrieving all the documents cited in Tierney’s meticulously referenced book.</p>
<p>The vaccine story crumbled almost immediately. Tierney had deliberately misquoted <em>all</em> of his sources, each and every one of which documented the safety and effectiveness of the vaccine. You can read our report <a href="../../pdf/ucsbpreliminaryreport.pdf">here</a>. Neel and Chagnon’s vaccination program probably saved hundreds of lives.</p>
<p>But Neel’s sinister theory intrigued me. It had something to do with the evolution of human intelligence, but I had never seen it cited in any of the countless papers on the topic. Once I got hold of Neel’s publications and figured out what he was actually saying, as opposed to Tierney’s mangled version, I realized it was a damn good idea. Neel’s research in the early 1960’s had found that in Amazonian populations, headmen had more wives and children than other men, a pattern that has now been seen in <a href="https://doi.org/10.1073/pnas.1606800113">many other populations</a>. Neel reasoned that if this pattern characterized humans societies during our evolution, there would have been tremendous sexual selection for whatever trait(s) predisposed men to become leaders.</p>
<p><a href="https://en.wikipedia.org/wiki/Sexual_selection">Sexual selection</a> often results in exaggerated traits. In gorillas, for example, a single adult male typically has a harem of several females. This means that several other adult males do not have mates. Males therefore physically compete with other males for access to females. As a consequence, male gorillas are about twice as large as female gorillas, and have much larger canine teeth. Chimpanzee males are modesty larger than females, and also have much larger canines (<a href="10.1002/ajpa.10011">Plavcan 2001</a>).</p>
<p>Human males, on the other hand, are only 15% larger than females and their canines are only slightly larger (<a href="10.1002/ajpa.10011">Plavcan 2001</a>). What human trait might have become exaggerated due to sexual selection operating on headmen and other leaders? Human brains are about 3 times bigger than chimp or gorilla brains. Neel proposed that headmen become headmen <a href="https://doi.org/10.1353/pbm.1980.0050">because they’re smart</a>. The dramatic increase in brain size in humans compared to other apes, according to Neel, was due to sexual selection for <em>intelligent</em> leaders.</p>
<p>Neel only briefly sketched his theory. He didn’t explain how intelligence predisposes men to become leaders, or why leaders would attract more mates than other men.</p>
<p>I gave these problems a bit of thought. First, what defines a “leader”? It seemed to me that leaders in small-scale societies are those that develop a reputation for making good decisions for the group. But why did this require exceptional intelligence? Making a decision that is good for oneself involves finding the option that maximizes an individual payoff. Making a decision that is good for the group, though, would involve searching over combinations of <em>everyone’s</em> options and payoffs. This could result in <a href="https://en.wikipedia.org/wiki/Combinatorial_explosion">combinatorial explosion</a>, a problem that might require a substantial increase in computational resources, i.e., a much bigger brain.</p>
<p>There was a problem with Neel’s theory, though. It seemed to predict that, just like the sex difference in body size in gorillas, there should be a sex difference in human intelligence, and there isn’t. I decided to put this project aside for awhile, but resolved to pick it up again at some point in the future.</p>
<p>Fast forward a decade. My new grad student Zach Garfield took up the project and dug into the ethnographic and theoretical literature on leadership. Leaders in traditional societies were indeed often seen as knowledgeable and intelligent. Existing evolutionary theories of leadership, though, could either account for leaders attracting followers, or leaders attracting mates, but not both.</p>
<p>Our key insight came from old-school anthropology. Human societies have a nested social structure. Human families are nested within residential groups (e.g., hunter-gatherer bands), which are nested within larger, multi-community alliances and ethnic groups:</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2019-03-21-measles-mothers-leadership-and-the-evolution-of-big-brains/parent_offspring_conflict.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Typical social structure of a hunter-gatherer society. An adult male and female cooperate to raise their children in a family. A small number of families coooperate within a band to hunt and gather food and raise their children. Multiple bands form an alliance to buffer variation in food and water supplies, and to defend territory. Figure modified from <a href="https://doi.org/10.1098/rstb.2001.0950">Parker et al.&nbsp;2002</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>This social structure seems to derive from several traits that distinguished ancestral humans from chimps and other apes. In hunter-gatherer societies, males and females typically form long-term pair-bonds to raise their joint offspring in families. These families cooperate to raise their kids (<a href="https://en.wikipedia.org/wiki/Alloparenting">alloparenting</a>), and to hunt and gather food in a band. Bands cooperate to buffer variation in access to resources and to defend territory.</p>
<p>Notice that in Figure @ref(fig:nested), half the group members are kids. Humans, unlike chimps and gorillas, have short interbirth intervals combined with an exceptionally long juvenile period. In natural fertility populations (no modern birth control), women typically have 5 or 6 six kids or more, all of whom will simultaneously depend on her for up to twenty years. Although there is a high child mortality rate, the majority of family members, and therefore group members, are usually kids, ranging from infants to teenagers. And who is making good decisions for this motley crew, day in, day out, morning to night? Their mothers.</p>
<p>Zach and I realized that mothers might be the archetypal leaders in ancestral human societies. Raising human children involves twenty years or more of cooperation between the mother and father. Given the nested social structure of human societies, the cognitive abilities that would be required to lead the family would also be required to lead the band. Almost all the literature on leadership has remarked on the huge male bias in leadership, completely missing the fact that in every society women, just like Nancy Pelosi, routinely lead their families.</p>
<p>In summary, Zach and I propose that during human evolution there was sexual selection on both males and females for cognitive traits that resulted in high-quality decision making for the group, be it the family, band, or larger political group. Men preferred women as mates who displayed evidence of high quality decision-making because their families would do better, and women preferred men who displayed the same. Women, who in natural fertility populations are giving birth every few years, would primarily lead at the family level, but would often transition to community leadership roles when they were older. Men with exceptional decision-making skills would rise to leadership positions in the community. Zach, in his research on leadership among the Chabu (a recently settled group of former hunter-gatherers), has found that men and women both occupy community leadership roles. Consistent with our reworking of Neel’s theory, male and female leaders tend to be married to each other.</p>
<p>This is the abstract of our paper (preprint <a href="https://doi.org/10.31219/osf.io/9bcdk">here</a>). Comments and criticisms welcome!</p>
<blockquote class="blockquote">
<p>Long before the term Machiavellian Intelligence was coined, James Neel was pondering the role of ‘princes’ in the evolution of exceptional human intelligence. The two cornerstones of Neel’s theory – leaders’ superior skills, knowledge, and intelligence (at least as judged by others), and their greater reproductive success – have been amply confirmed by subsequent research. Neither Neel nor later theorists, however, have adequately explained why knowledgeable, intelligent leaders are attractive both to followers and to mates. We aim to fill this gap by operationalizing leaders as individuals who regularly make decisions that benefit most members of the group. Because human nuclear families comprise two unrelated individuals who cooperate for twenty years or more to raise their joint offspring, and because families are nested within subsistence groups, which, in turn, are nested within larger security and political groups, good decision-making skills will provide large benefits to mates as well as to members of one’s subsistence group or larger security and political groups. We further argue that decision-making that benefits others as well as oneself (joint utility optimization – JUO) can be especially computationally complex, and therefore that sexual selection and biological market forces favoring these skills would favor increased brain size. Finally, because parents must make decisions for their cognitively immature offspring, good JUO and other leadership abilities might have initially undergone strong selection in mothers, who provide most of the childcare in natural fertility populations.</p>
<p>Decision-making that benefits others is one example of a valuable computational service. Other important examples include threat and opportunity detection, gossip and information sharing, cultural transmission, story telling, medicinal knowledge, and advice and counsel. Providing computational services in exchange for a variety of benefits would have helped subsidize a large, energetically expensive brain. Individuals who provided particularly valuable services gained prestige, i.e., additional benefits from fellow group members.</p>
</blockquote>



 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2019-03-21-measles-mothers-leadership-and-the-evolution-of-big-brains/index.html</guid>
  <pubDate>Thu, 21 Mar 2019 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2019-03-21-measles-mothers-leadership-and-the-evolution-of-big-brains/parent_offspring_conflict.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Seven reasons why most Major Depression is probably not a brain disorder</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/index.html</link>
  <description><![CDATA[ 




<p>Virtually all mental health researchers accept that Major Depression (MD) is a mental disorder, i.e., a brain dysfunction. I argue that this widespread belief should instead be treated as an untested <em>hypothesis</em>, and further, that this hypothesis is probably false. Instead, most MD in the general population is probably severe but normal sadness or grief. Here are seven reasons why:</p>
<section id="most-major-depression-is-caused-by-adversity" class="level1">
<h1>Most Major Depression is caused by adversity</h1>
<p>Ordinary sadness and grief are caused by adverse events. I suspect that a common view about MD is that it fundamentally different, striking without cause, out of the blue. Most studies of MD do not even bother to measure recent negative life events. There is a consensus, however, that MD, too, is caused in large part by adverse events, and that events of higher severity increase the risk of MD. Many early studies found that about 80% of cases of MD had evidence of at least one adverse event (compared to a much lower rate among non-cases). See Figure&nbsp;1.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mazure" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/mazure.png" class="img-fluid figure-img" width="558"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Life events and onset of major depression. Figure and caption from <a href="https://doi.org/10.1111/j.1468-2850.1998.tb00151.x">Mazure (1998)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>More recent studies using twin designs have found similar results, and additionally show the interaction between adversity and vulnerability factors such as female sex and neuroticism (see Figure&nbsp;2).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-kendler2004" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/kendler2004.png" class="img-fluid figure-img" width="632"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Figure from <a href="https://doi.org/10.1176/appi.ajp.161.4.631">Kendler et al.&nbsp;(2004)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>The stressful life events in <a href="https://doi.org/10.1176/appi.ajp.161.4.631">Kendler et al.&nbsp;(2004)</a> included:</p>
<ul>
<li>assault (assault, rape, or mugging)</li>
<li>divorce/separation (divorce, marital separation, broken engagement, or breakup of other romantic relationship),</li>
<li>major financial problem</li>
<li>serious housing problems</li>
<li>serious illness or injury</li>
<li>job loss (laid off from a job or fired)</li>
<li>legal problems (trouble with police or other legal trouble)</li>
<li>loss of confidant (separation from other loved one or close friend other than a spouse or partner)</li>
<li>serious marital problems (involving a marital or marriage-like intimate, cohabiting relation- ship)</li>
<li>robbed</li>
<li>serious difficulties at work</li>
<li>serious trouble getting along with a close social partner</li>
<li>serious personal crisis of a close social partner</li>
<li>death or illness of a close social partner</li>
</ul>
<p>Most of us hit by such adverse events would also experience low mood, sadness, loss of interest, insomnia, and other symptoms of MD. In fact, the study design of <a href="https://doi.org/10.1176/appi.ajp.161.4.631">Kendler et al.&nbsp;(2004)</a> instructed interviewers to rate the severity of the events as “what most people would be expected to feel about an event in a particular set of circumstances and biography….”</p>
<p>The causal effect of adversity on depression is most convincingly demonstrated by the finding that independent adverse events — those, like death of a loved one, that could not be caused by the depressed individual — are powerful predictors of MD.</p>
</section>
<section id="diagnostic-criteria-for-major-depression-were-not-developed-to-distinguish-the-ill-from-the-healthy-but-instead-to-distinguish-md-from-other-psychiatric-disturbances" class="level1">
<h1>Diagnostic criteria for Major Depression were not developed to distinguish the ill from the healthy but instead to distinguish MD from other psychiatric disturbances</h1>
<p>Almost all research on Major Depression (MD) diagnoses it using either the <a href="https://www.psychiatry.org/psychiatrists/practice/dsm">Diagnostic and Statistical Manual</a> (DSM) criteria, or the very similar <a href="https://www.who.int/classifications/icd/en/">International Classification of Diseases</a> (IDC) criteria. The current DSM-V criteria are basically the same as those in DSM-III, which initiated the modern era of depression research. These criteria are listed in the right-most column in Figure&nbsp;3.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-historicalorigins" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/historicalorigins.png" class="img-fluid figure-img" width="1017"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Historical origins of the symptomatic criteria for Major Depression: Criteria proposed 1950-1980. Table and caption from <a href="https://doi.org/10.1176/appi.ajp.2009.09081155">Kendler et al.&nbsp;2010</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>At some point in their lives, everyone will experience at least one of these symptoms, and most of us will probably experience most of them. <em>Prima facie</em>, none indicate brain dysfunction. To be diagnosed with MD under the DSM criteria, a person must be experiencing 5 or more symptoms most of the day for at least two weeks, and at least one symptom must be sad or depressed mood (dysphoric mood) or loss of interest or pleasure.</p>
<p>Where did these criteria come from? You might think they came from studies designed to distinguish mental illness from normal sadness and grief. If so, you would be wrong. Instead, they come from studies that were conducted among groups of individuals who had <em>already been determined</em> to suffer from a variety of severe psychiatric disturbances (or physical illnesses). The goal of these studies was to develop criteria that would enable different psychiatrists to reliably provide the same mentally ill patient with the same diagnosis, such as bipolar disorder or schizophrenia, not to distinguish the mentally ill from the healthy.</p>
<p>Specifically, the DSM-III criteria can be traced to Stone and Burris (1950), which was a clinical study of 50 selected cases; Cassidy et al.&nbsp;(1957), which was a quantitative study of one hundred manic-depressive patients compared to fifty medically sick controls; Feighner et al.&nbsp;(1972), which was a study of 314 psychiatric emergency room patients and 87 psychiatric inpatients. And Spitzer et al.&nbsp;(1975), which tested the reliability of the <a href="https://en.wikipedia.org/wiki/Research_Diagnostic_Criteria">Research Diagnostic Criteria</a> (RDC) with 218 psychiatric inpatients. See Figure&nbsp;3.</p>
<p>None of the studies that <em>defined</em> MD as we understand it today included any healthy participants, nor any identified as experiencing only ordinary sorrow, sadness, or grief. Hence, there is no reason to believe that, when applied to the general population, the criteria developed in these studies would effectively distinguish the tiny minority of individuals with a genuine mental illness from the much larger number of individuals who were suffering ordinary low mood, sadness, or grief.</p>
<p>As Kenneth Kendler, one of the world’s preeminent depression researchers admits, “most of the diagnostic categories and the diagnostic criteria they contain have been accepted for historical rather than strictly empirical reasons” <a href="https://doi.org/10.1017/S0033291709992157">(Lux and Kendler 2010)</a>.</p>
</section>
<section id="dsm-criteria-misapplied-to-community-populations-generated-massive-prevalence-rates" class="level1">
<h1>DSM criteria (mis)applied to community populations generated massive prevalence rates</h1>
<p>It is no surprise, then, that when DSM criteria were first applied to the general population they generated implausibly high prevalence rates of mental illness. Over a quarter of the population (28.5%) was identified as suffering a mental illness in the last year, and nearly half the population (48%) as having suffered a mental illness in their lifetimes. For MD, up to 10% were identified to have suffered an episode in the last year, and 17% to have suffered MD in their lifetime. See Figure&nbsp;4.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-highprevalence" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/highprevalence.png" class="img-fluid figure-img" width="331"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Table from <a href="https://doi.org/10.1001/archpsyc.55.2.109">Regier et al.&nbsp;1998</a></figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://doi.org/10.1001/archpsyc.55.2.109">Regier et al.&nbsp;1998</a> acknowledged that these high prevalence rates called into question the validity of “diagnoses” based on DSM criteria in community populations:</p>
<blockquote class="blockquote">
<p>Although it is possible that all of these community-based disorders are simply milder cases of essentially the same disorders seen in clinical settings, there are other possibilities as well. Based on the high prevalence rates identified in both the ECA and the NCS, it is reasonable to hypothesize that some syndromes in the community represent transient homeostatic responses to internal or external stimuli that do not represent true psychopathologic disorders. The human organism has a limited repertoire of response patterns to various physical, biological, and emotional stresses. Transient changes in blood pressure, pulse rate, body temperature, anxiety, or mood are not always indicators of pathology but of appropriate adaptive responses. It is possible that many people with currently defined mental syndromes (in particular among the affective and anxiety disorders) not brought to clinical attention may be having appropriate homeostatic responses that are neither pathologic nor in need of treatment — eg, other equivalents of grief reactions that meet clinical criteria but are not considered pathologic if they are time-limited.</p>
</blockquote>
<p>Such eminently reasonable interpretations of MD in community populations have virtually disappeared from the scientific literature, and high prevalence rates are now reported without a bat of the eye. In the US, for example, the government <a href="https://www.nimh.nih.gov/health/statistics/major-depression.shtml">reports</a> that about 1 in 5 adolescent women (19.4%) suffered MD in the past year, i.e., putatively suffered a major disorder of the brain.</p>
<p>Really?</p>
<p>Regier, first author of the above quote, went on to co-chair the DSM-5 Task Force, which, ironically, was widely criticized for further medicalizing normal reactions to common life experiences. The most prominent critic was Regier’s predecessor, Allen Frances, chair of the DSV-IV Task Force. See, for instance, <a href="https://www.amazon.com/Saving-Normal-Out-Control-Medicalization-ebook/dp/B009NFMITE/">his book</a>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-frances" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/FrancesSavingNormal.png" class="img-fluid figure-img" width="253"></p>
<figcaption class="figure-caption">Figure&nbsp;5: <strong>?(caption)</strong></figcaption>
</figure>
</div>
</div>
</div>
<p>Robert Spitzer, chair of the DSM-III Task Force, expressed similar worries:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/trFs_d1dqhw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>Regier and colleagues <a href="http://www.psychiatrictimes.com/dsm-5/setting-record-straight-response-frances-commentary-dsm-v">shot back</a> that Frances’ and Spitzer’s criticisms were motivated by the loss of royalties from sales of DSM-IV products. Frances <a href="https://www.wired.com/2010/12/ff_dsmv/">scoffed</a> that these royalties were a relative pittance.</p>
</section>
<section id="depression-is-a-continuum" class="level1">
<h1>Depression is a continuum</h1>
<p>If depression were a major brain disorder that could be identified by counting up symptoms that are common experiences, you might expect that folks with MD would stand apart from everyone else in the distribution of their symptoms. But they don’t. Although there is some debate, most studies have found that depression is dimensional, i.e., that it is “a quantitative elevation on a continuum of depression-relevant features found in all people” <a href="https://doi.org/10.1037/0021-843X.114.4.71">(Prisciandaro and Roberts 2005)</a>. As can be seen in Figure&nbsp;6, there is no natural separation between those with lower depression scores and those with higher.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-continuum" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/depressionscores.png" class="img-fluid figure-img" width="838"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Distribution of scores from the Patient Health Questionnaire (PHQ-9), with a conventional threshold of 10. Nationally representative US data from NHANES 2011-2012.</figcaption>
</figure>
</div>
</div>
</div>
<p>When Cassidy, developer of one of the historical antecedents to the DSM-III MD criteria (see Figure&nbsp;3), was asked how he decided on the threshold, he replied, “It sounded about right” <a href="https://doi.org/10.1176/appi.ajp.2009.09081155">(Kendler et al., 2010)</a>.</p>
<p>There is no principled reason to conclude that higher scores indicate brain disorder instead of more severe sadness.</p>
</section>
<section id="major-depression-usually-remits-in-a-few-months" class="level1">
<h1>Major Depression usually remits in a few months</h1>
<p>Many articles on MD emphasize that it is a chronic disease. This is not true for the majority of cases. The median duration of MD in a recent study of a nationally representative community sample was 6 months, and about 75% of cases remitted within a year. See Figure&nbsp;7.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-remission" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/remission.png" class="img-fluid figure-img" width="466"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Survival curves of a cohort (n = 393) with newly originated (first or recurrent) depressive episodes in the general population; +, censored cases. MinDD: minor depressive disorder. MDD: major depressive disorder. Figure and caption from <a href="https://doi.org/10.1111/acps.12753">ten Have et al.&nbsp;(2017)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>In addition, the majority of individuals who suffer MD will have a single episode in their lifetimes. A recent study based on a large, nationally representative sample found that, among individuals in remission from MD at baseline, the cumulative recurrence rate was 13.4% at 10 years, and 27.1% at 20 years <a href="https://doi.org/10.1111/acps.12874">(Ten Have 2018)</a>.</p>
</section>
<section id="onset-of-major-depression-is-common-at-all-adult-ages" class="level1">
<h1>Onset of Major Depression is common at all adult ages</h1>
<p>If MD were a genuine brain disorder, its epidemiology might resemble that of other genuine brain disorders, such as the epidemiology of developmental brain disorders, which occur early in life, or the epidemiology of brain disorders related to aging, i.e., those that occur late in life.</p>
<p>To compare MD with such brain disorders, I used the Institute for Health Metrics and Evaluation <a href="http://www.healthdata.org/results/data-visualizations">data visualization website</a> to display results from the 2017 Global Burden of Disease Study. Here are the results for MD compared to three common developmental brain disorders:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-developmental" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/developmentaldisorders.png" class="img-fluid figure-img" width="712"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Major depression incidence compared to epidemiology of brain disorders that appear to be due to developmental disruption. Data from the Global Burden of Disease study 2017 and <a href="http://www.healthdata.org/results/data-visualizations">healthdata.org</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>As you can see, new cases of MD are common starting in adolescence and throughout adulthood. In comparison, autism spectrum disorders are relatively rare and present at birth (hence prevalence rather than incidence is reported). Bipolar disorder and schizophrenia are also relatively rare, with peaks in incidence rates in late adolescence and early adulthood.</p>
<p>Similarly, although incidence of MD increases with age, it does not resemble other brain disorders related to aging, such as dementia, Parkinson’s or stroke, which are exceedingly rare until after the age of 40 or 50:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-aging" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/agingdisorders.png" class="img-fluid figure-img" width="675"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Major depression incidence compared to epidemiology of brain disorders that appear to be due to aging. Data from the Global Burden of Disease study 2017 and <a href="http://www.healthdata.org/results/data-visualizations">healthdata.org</a>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="neurophysiological-differences-associated-with-md-do-not-necessarily-indicate-brain-deficits" class="level1">
<h1>Neurophysiological differences associated with MD do not necessarily indicate brain deficits</h1>
<p>MD’s status as a “real” illness is often justified by pointing to biological differences associated with depression. The Mayo Clinic, for example, on its <a href="https://www.mayoclinic.org/diseases-conditions/depression/symptoms-causes/syc-20356007">info page for MD</a>, only lists biological factors as causes of MD, such as physical changes in the brain, brain chemistry, hormones, and genetics (adversity, in contrast, is a “risk factor”). Several biological differences associated with MD are depicted in Figure&nbsp;10:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-neurophysiology" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/depressionneurophysiology.png" class="img-fluid figure-img" width="431"></p>
<figcaption class="figure-caption">Figure&nbsp;10: <strong>Biological systems involved in the pathophysiology of MDD.</strong> Clinical studies in major depressive disorder (MDD) and relevant animal models have identified pathophysiological features in the central nervous system, as well as the major stress response systems, such as the hypothalamic–pituitary–adrenal (HPA) axis, the autonomic nervous system and the immune system. In the central nervous system, altered neurotransmission and reduced plasticity are evident. These could underlie functional changes in relevant brain circuits (for example, cognitive control and affective–salience networks), smaller regional brain volumes (for example, in the hippocampus) and neuroinflammation, as confirmed in neuroimaging studies. Beyond the central nervous system, chronic hyperactivity impairs feedback regulation of the HPA axis, which is one of the most consistently reported biological features of MDD. Within the immune system, substantial evidence supports increased levels of circulating cytokines and low-grade chronic activation of innate immune cells, including monocytes. However, other aspects of immunity seem to be impaired as exemplified by reduced natural killer (NK) cell cytotoxicity and T cell proliferative capacity. Once it becomes chronic, both HPA axis hyperactivity and inflammation might converge with alterations in the autonomic nervous system to contribute to central nervous system pathobiology as well as cardiovascular and metabolic disease, which often co-occur with MDD. The sequence of events leading to changes in these interconnected systems and their exact relationship is not known. However, mechanistic studies in animals have shown that alterations in stress response systems can directly and indirectly affect the central nervous system (BOX 3). Conversely, chronic stress and associated changes in behaviour can reproduce many of the stress system alterations, including HPA feedback impairment and inflammation, which suggests a bidirectional link between central and peripheral biological features of MDD. ACTH, adrenocorticotropin; CRH, corticotropin-releasing hormone; TNF, tumour necrosis factor. Figure and caption from <a href="http://dx.doi.org/10.1038/nrdp.2016.65">Otte et al.&nbsp;(2016)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>The brain, however, is a biochemical machine. It is not surprising that individuals in different emotional states, such as depressed vs.&nbsp;non-depressed, have differences in brain neurophysiology. <em>All</em> brain functions involve neurophysiological changes in the brain. Your brain is undergoing countless chemical changes as you read this post. If you remember anything you’ve read, for example, your brain has undergone some <a href="https://en.wikipedia.org/wiki/Long-term_potentiation">long-term chemical changes in synaptic connections between neurons</a>. Differences in subjective experiences must be caused by physical differences in the brain. Indeed, if there weren’t biochemical and neurophysiological changes underlying MD this would be a shocking finding that would shake our materialist conception of the brain to its core.</p>
<p>Moreover, none of the studies I’ve seen of neurophysiological and biochemical differences in those with MD could distinguish differences from deficits, even in principle. Every study I’ve looked at has the following design: a group of participants that meet diagnostic criteria for MD are compared to a group of “healthy” controls, i.e., individuals without MD. But most of the individuals with MD are (1) experiencing sadness or low mood (one of two necessary symptoms), and (2) have suffered recent adversity. Most members of the control group, in contrast, are not experiencing sadness or low mood, and have not suffered recent adversity. Hence, MD is almost completely confounded with sadness and recent adversity.</p>
<p>All of the neurophysiological and other differences in Figure&nbsp;10 that are identified as “impairments” or “pathophysiological features” are simply differences whose implications are currently unknown. They could easily be some of the biological bases of normal sadness and other <em>functional</em> responses to adversity.</p>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>MD is caused by adversity, such as loss of a loved one; it is characterized by symptoms such as sadness, low mood, and loss of interest, which most people experience when they experience adversity; it is diagnosed when the count of such common symptoms exceeds an arbitrary threshold; it is common among adolescents and adults of every age in the general population; it usually lasts for no more than a year; and most people will experience at most one episode in their lifetimes. Taken together, these facts provide considerable evidence for the hypothesis that most MD in the general population is simply severe sadness or grief.</p>
<p>I am far from the only one to make this argument. Horwitz and Wakefield wrote a book on it (note the Forward by Robert Spitzer, chair of the DSM-III effort):</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-lossofsadness" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/lossofsadness.png" class="img-fluid figure-img" width="228"></p>
<figcaption class="figure-caption">Figure&nbsp;11: The Loss of Sadness. Horwitz and Wakefield.</figcaption>
</figure>
</div>
</div>
</div>
<p>If these arguments are correct, why do mental health researchers cling to the axiom that MD is a serious brain disorder, instead of treating this as a hypothesis? Here are a few possible reasons:</p>
<ol type="1">
<li>Many psychiatrists form their initial intuitions about MD by working with inpatients. MD in these clinical populations can look quite different from MD in the general population. Because these individuals refer themselves, or are referred by family members, for psychiatric treatment, their MD tends to be chronic, recurring, and have little connection to recent adverse events, making it seem much less like “normal” sadness or grief. Such rarer forms of MD are better candidates for a genuine disorder.</li>
<li>$$$. The NIH budget for depression research is approaching half a billion dollars annually (<a href="https://report.nih.gov/categorical_spending.aspx">$466 billion in 2018</a>). Sales of antidepressants are generating revenues of around $11.6 billion annually. And Big Pharma <a href="https://www.nytimes.com/2018/09/14/opinion/jose-baselga-research-disclosure-bias.html">kicks back a lot of bucks</a> to “thought leaders” in medicine, including psychiatry. The flow of all these dollars depends on MD being a serious illness rather than ordinary sadness.</li>
<li><a href="https://en.wikipedia.org/wiki/Thomas_Szasz">Szasz</a> was right: psychiatry aims to control undesirable behavior, and severe sadness and grief are aversive to sufferers and often inconvenient for social partners and employers.</li>
<li>It’s politically incorrect to question the illness axiom, perhaps because it runs counter to the laudable effort to reduce the stigma of mental illness.</li>
</ol>
<p>Regarding #4, viewing mental illness as an ‘illness like any other’ and promoting biogenetic causes have been thought to reduce stigma. <a href="https://doi.org/10.1111/inm.12390">Larkings and Brown (2018)</a> conducted a systematic review of the impact of biogenetic beliefs regarding mental illness on stigma. They found, on the contrary, that among the public:</p>
<blockquote class="blockquote">
<p>Overall, these reviews suggest that there are mixed ramifications associated with public endorsement of biogenetic causes. While biogenetic causes might help reduce blame, they might also contribute to negative consequences, such as increased perceived dangerousness, social distance, and pessimism around prognosis.</p>
</blockquote>
<p>Among the mentally ill and mental health professionals, things were even worse:</p>
<blockquote class="blockquote">
<p>The present review indicates that the endorsement of biogenetic causes does not reduce stigma in people with mental illness and in mental health professionals, and might actually increase stigma and negative attitudes towards mental illness.</p>
</blockquote>
<p>Finally, even if most MD is normal sadness and grief sufferers will often still need help, sometimes from professionals. Much of my research and that of my grad students explores the possibility that some aspects of MD function to signal need to social partners. Treatment, though, would focus on solving real-life problems rather than altering brain chemistry.</p>
<p>You can find papers on my evolutionary approach to depression here:</p>
<p>https://anthro.vancouver.wsu.edu/people/hagen/depression-and-other-mental-health-issues-in-evolutionary-perspective/</p>
<p><em>Addendum (2018/12/21)</em></p>
<p>If most MD, as it is currently diagnosed, is not disorder, should we keep calling it Major Depression? Wakefield’s answer, and I think it’s a good one, is no. The term Major Depression should be reserved for genuine disorder, leaving many, if not most, cases of MD in the community as false positives (e.g., <a href="https://doi.org/10.1002/wps.20015">Wakefield and Schmitz 2013</a>; <a href="https://doi.org/10.1146/annurev-clinpsy-032814-112800">Wakefield 2016</a>). That is, the criteria in Figure&nbsp;3 are insufficient to distinguish functional responses to adversity, such as sadness and grief, from disordered responses. Additional criteria that might reduce false positives include MD-levels of symptoms in the absence of adversity, that the severity of the response is disproportionate to the severity of the adverse event, persistence of symptoms well past the adverse event (e.g., more than a year), or a high rate of recurrence.</p>
<ul>
<li>2019/09/22: rearranged order of sections; minor edits for clarity</li>
<li>2022/05/22: updated epidemiology plots</li>
</ul>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/index.html</guid>
  <pubDate>Sun, 16 Dec 2018 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-12-16-seven-reasons-why-most-major-depression-is-probably-not-a-brain-disorder/developmentaldisorders.png" medium="image" type="image/png" height="76" width="144"/>
</item>
<item>
  <title>Suicide and #MeToo</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-10-09-suicide-and-metoo/index.html</link>
  <description><![CDATA[ 




<p>What single recent event in a woman’s life is most strongly associated with her subsequent suicide attempt? A sexual assault.</p>
<p>In a large, <a href="https://doi.org/10.1016/j.jad.2013.08.035">nationally representive study</a> in France, for instance, the odds that a woman would attempt suicide were 17 times higher if she had experienced a sexual assault in the last year than if she had not, the most potent risk factor among those examined. In fact, although sexual assault is associated with many poor mental health outcomes, such as depression, anxiety, and PTSD, it is most powerfully <a href="https://doi.org/10.1016/j.cpr.2017.06.002">associated with suicidality</a>.</p>
<p>Sexual assault often causes suicidal behavior, my graduate student <a href="http://anthro.vancouver.wsu.edu/grads/syme/">Kristen Syme</a> and I <a href="http://anthro.vancouver.wsu.edu/media/PDF/syme_garfield_hagen2015.pdf">argue</a>, precisely because women who report sexual assault are frequently <a href="https://www.cnn.com/2018/10/06/politics/collins-sotu-kavanaugh-cnntv/index.html">not believed</a>. An assault victim’s suicidal behavior is a last-ditch effort to convince others that she is telling the truth.</p>
<p>Our hypothesis is based on <a href="https://en.wikipedia.org/wiki/Signalling_(economics)"><em>costly signaling theory</em></a>: When individuals have conflicts of interest and incentives to lie, costly signals can still be trusted.</p>
<p>To illustrate: Imagine that Molly is sexually assaulted by her mother’s boyfriend, Mike, but there are no witnesses. Molly tells her mother about the assault, but her mother doesn’t believe her. Molly blamed Mike for her parents’ divorce. The mother suspects Molly is falsely accusing Mike of sexual assault to force her to break up with him and spend more time with Molly.</p>
<p>Molly, on the other hand, knows that Mike will probably attack her again. She is already traumatized, and if she gets pregnant by Mike, her life will be ruined. If she can convince her mother that she is telling the truth, she hopes her mother will put her daughter’s welfare first, and break up with Mike.</p>
<p>Molly swallows a bottle of pills shortly before her mother gets home from work. Molly’s suicide attempt, <a href="http://anthro.vancouver.wsu.edu/media/PDF/syme_garfield_hagen2015.pdf">we argue</a>, is a costly signal to her mother that she is telling the truth.</p>
<p>The logic is as follows. For Molly, the cost of a suicide attempt is low: if her mother doesn’t get rid of Mike, Molly’s life is probably ruined anyway. Her future is dim, and she is indifferent between being raped again and dying.</p>
<p>But if Molly were lying, if she had not been attacked and did not face any risk of being attacked, then the cost of a suicide attempt would be high: Molly is a young healthy women who, yes, isn’t getting as much attention from her mother as she would like, but her future is bright. A suicide attempt is too costly for her.</p>
<p>The fact that Molly would only attempt suicide if she faced a real risk of future attack by Mike convinces her mother that she is telling the truth. Her mother breaks up with Mike.</p>
<p>Our hypothesis requires that attempts are much more common than completions. The costly signal only succeeds if the victim survives her attempt and her social partners consequently make changes that benefit her. Attempts are indeed vastly more common than completions, especially among young women:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-attempts" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-10-09-suicide-and-metoo/cdcsuicideattempts.png" class="img-fluid figure-img" width="1800"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Population rates of suicide attempts and completions in the US, 2001-2011. Note the especially high rate of attempts during the years of highest reproductive value: late adolescence to the mid forties. Data from CDC (2014). Non-fatal self-harm based on data from hospital emergency departments on confirmed or suspected injury or poisoning resulting from a deliberate violent act inflicted on oneself with the intent to take one’s own life or with the intent to harm oneself. Mortality data come from the National Center for Heath Statistics. Figure and caption from <a href="http://anthro.vancouver.wsu.edu/media/PDF/syme_garfield_hagen2015.pdf">Syme et al.&nbsp;2016</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Our theory is far from proved. You can read more about it and supporting evidence in <a href="http://anthro.vancouver.wsu.edu/media/PDF/syme_garfield_hagen2015.pdf">this paper</a> and in an <a href="http://anthro.vancouver.wsu.edu/media/PDF/Hagen_et_al_2008_Gestures_of_despair_and_hope.pdf">earlier paper</a> on self harm. But, despite over half a century of research, the mainstream view that suicidality is a type of psychopathology, that victims’ brains are dysfunctioning and must be fixed with drugs or therapy, has also not come close to being proved.</p>
<p>If we are correct, there is nothing wrong with the victim. Instead, there is a profound problem in her social environment. The most effective response to her suicidal behavior would be to substantially improve her life.</p>
<p>In particular, victims of physical or sexual assault — perhaps the strongest risk factors for suicidal behavior — need those closest to them to believe them and protect them. Therapy can be enormously helpful, not because it fixes a broken brain, but because it provides exactly the understanding and support that victims desperately need.</p>
<p>It is time to ask: does the mainstream model of suicide, by focusing on the putative psychopathology of the victim, help silence her cry for help?</p>



 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2018-10-09-suicide-and-metoo/index.html</guid>
  <pubDate>Tue, 09 Oct 2018 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-10-09-suicide-and-metoo/cdcsuicideattempts.png" medium="image" type="image/png" height="72" width="144"/>
</item>
<item>
  <title>Most shooters are suicidal. Would arming teachers deter them?</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-08-23-most-shooters-are-suicidal-would-arming-teachers-deter-them/index.html</link>
  <description><![CDATA[ 




<!-- Today, the New York Times [reported](https://www.nytimes.com/2018/08/23/us/politics/devos-guns-in-schools.html) that Betsy DeVos wants to use federal education grants to put guns in schools: -->
<!-- > WASHINGTON — The Education Department is considering whether to allow states to access federal funding set aside for academic enrichment and student services to purchase guns for educators, according to multiple people with knowledge of the plan. -->
<!-- The goal, presumably, would be to deter and respond to active shooters. Although there are many arguments against arming teachers, I want put forward three more. -->
<!-- ## Most shooters are suicidal. Would arming teachers deter them? -->
<p>The FBI recently released a <a href="https://www.fbi.gov/file-repository/pre-attack-behaviors-of-active-shooters-in-us-2000-2013.pdf">report</a> on pre-attack behaviors of active shooters. The report analyzes the 63 shooters between 2000 and 2013 who had case files, which contain interviews with friends, family members and other background information. The case files were used to identify behaviors and characteristics that might help identify potential shooters before they strike.</p>
<p>The statistic that jumped out at my grad student, <a href="http://anthro.vancouver.wsu.edu/grads/syme/">Kristen Syme</a>, and me was this: many, perhaps most, shooters were suicidal. Of the 35 shooters for whom a determination could be made, 30 had suicidal ideation or engaged in suicide-related behavior prior to the attack (there was no information for the other 28 shooters). Shooters’ circumstances matched those of other suicidal young people, including many cases in the ethnographic record: they were in conflict with powerful others <a href="https://doi.org/10.1016/j.evolhumbehav.2015.10.005">(Syme, Garfield and Hagen, 2016)</a>. The FBI report found that most shooters were <em>not</em> motivated by ideology or hatred of a group but instead had strong personal grievances, such as being subjected to disciplinary actions at school or interpersonal conflicts.</p>
<p>Although <a href="https://twitter.com/realDonaldTrump/status/966657362789568512">President Trump</a> and others have argued that arming teachers would deter shooters, it’s hard to deter an individual who seeks death.</p>
<section id="could-arming-teachers-encourage-suicidal-shooters" class="level2">
<h2 class="anchored" data-anchor-id="could-arming-teachers-encourage-suicidal-shooters">Could arming teachers <em>encourage</em> suicidal shooters?</h2>
<p>A second key statistic from a different set of studies is that many police shootings are “suicide by cop.” That is, a suicidal person who can’t take his or her own life deliberately provokes a police officer to use lethal force against them, usually by threatening the officer with a loaded gun or other weapon. The typical victim of suicide-by-cop is a young adult white male with romantic relationship conflicts. Estimates of the percentage of police killings that are suicide-by-cop vary widely, from 10% to almost 50%, with several estimates in the 30-40% range <a href="http://dx.doi.org/10.1016/j.avb.2016.03.003">(Patton and Fremouw)</a>.</p>
<p>Arming teachers means millions of teenagers who would only rarely interact with armed police would now regularly interact with armed teachers with whom they might be in conflict. Suicidality is not rare among teenagers. Of the <a href="https://nces.ed.gov/fastfacts/display.asp?id=372">7.5 million boys in high school</a>, about 10% have seriously considered suicide or made a plan, and 5% have attempted suicide <a href="https://doi.org/10.1016/j.jadohealth.2013.07.024">(Lowry et al.&nbsp;2014)</a>. Thus, arming teachers would dramatically increase the opportunities to commit suicide-by-cop, except in this case it would be suicide-by-teacher. If even a tiny fraction of suicidal male teenagers provoked shootouts with teachers and staff at their schools, or simply tried to obtain their guns, it would substantially increase the number of school shootings and deaths.</p>
</section>
<section id="would-arming-teachers-begin-to-create-an-informal-institution-of-the-active-shooting" class="level2">
<h2 class="anchored" data-anchor-id="would-arming-teachers-begin-to-create-an-informal-institution-of-the-active-shooting">Would arming teachers begin to create an informal institution of the active shooting?</h2>
<p>A more important consideration, perhaps, is the implication of arming teachers for our institutions of conflict resolution. The FBI <a href="https://www.fbi.gov/file-repository/pre-attack-behaviors-of-active-shooters-in-us-2000-2013.pdf">report</a> and Kristen’s work on suicide <a href="https://doi.org/10.1016/j.evolhumbehav.2015.10.005">(Syme, Garfield and Hagen, 2016)</a> both indicate that shooters in particular, and suicidal individuals more generally, are engaged in interpersonal conflict.</p>
<p>Anthropologists have documented numerous examples of cultural institutions that aim to resolve personal conflicts, and prevent them from devolving into blood feuds that engulf entire communities. These institutions often involve personal combat.</p>
<p>The Yanomamo, for example, have a graded series of mechanisms to resolve conflict between two parties, ranging from side-slapping to club fights to ax fights. Phillip Walker <a href="https://doi.org/10.1002/ajpa.1330800305">documented</a> healed depressed cranial fractures in prehistoric skeletal remains from the Channel Islands off the coast of southern California that could be evidence of club fighting similar to that observed among the Yanomamo.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-08-23-most-shooters-are-suicidal-would-arming-teachers-deter-them/clubfightscars.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Scars from club fighting in a Yanomamo man.</figcaption>
</figure>
</div>
<p>In Europe and the United States, <a href="https://en.wikipedia.org/wiki/Duel">dueling</a> with swords or pistols historically served to resolve personal conflicts. Though frequently outlawed, dueling persisted for centuries in Europe and was popular in the US, especially the South, up until the Civil War. The toll was substantial. According to <a href="https://www.smithsonianmag.com/history/duel-104161025/">Drake (2004)</a>, “between 1798 and the Civil War, the [US] Navy lost two-thirds as many officers to dueling as it did to more than 60 years of combat at sea. Many of those killed and maimed were teenage midshipmen and barely older junior officers, casualties of their own reckless judgment….”</p>
<p>Even today, personal combat to resolve conflicts and restore personal honor is common in US teenagers. Most American males have witnessed, and probably participated in, clandestine fist fights arranged to take place after school. The key point is that aggrieved individuals will attempt to resolve their conflicts using the institutions provided by their culture. An angry Yanomamo would not think to challenge an opponent to rapiers at dawn, nor would a Renaissance nobleman have thought to challenge his opponent to a club fight. Instead, they, and we, choose from the options our cultures provide us.</p>
<p>Semi-automatic weapons expand the scope of such conflict resolution strategies, enabling aggrieved individuals to effectively attack entire ingroups (school shootings?) or, perhaps as a way to increase one’s ingroup status, kill many members of an outgroup.</p>
<p>My concern is that arming teachers would not only fail to deter suicidal shooters and dramatically increase the exposure of suicidal teenagers to folks with loaded firearms, it would also be fateful step towards creating and advertising a new informal institution of conflict resolution that is similar to, but much more deadly than a duel: the active shooting.</p>
<p><em>Edited Aug 24, 2018 to add high school suicide stats, Aug 25, 2018 to add subheadings and a bit more detail on dueling, and Aug 4, 2019 to add note on active shooting to resolve conflicts between individuals and groups. Edited Sep 9, 2021 to tweak title.</em></p>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2018-08-23-most-shooters-are-suicidal-would-arming-teachers-deter-them/index.html</guid>
  <pubDate>Thu, 23 Aug 2018 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-08-23-most-shooters-are-suicidal-would-arming-teachers-deter-them/clubfightscars.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The universal genetic program and the custom-built phenotype: implications for race and sex</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/index.html</link>
  <description><![CDATA[ 




<p>The human genome, for many, represents differences, <em>essential</em> differences. The real spectre that such differences fuel <a href="https://en.wikipedia.org/wiki/Biological_determinism">racism, sexism, and eugenics</a> has lead much of academia to downplay or even deny a role for the genome in human affairs.</p>
<p>Geneticist David Reich confronted this spectre in his recent <a href="https://www.nytimes.com/2018/03/23/opinion/sunday/genetics-race.html">New York Times Op-Ed</a> where he raised the alarm that scientists are on the verge of discovering genetic differences in intelligence, cognition, and behavior among the races:</p>
<blockquote class="blockquote">
<p>So how should we prepare for the likelihood that in the coming years, genetic studies will show that many traits are influenced by genetic variations, and that these traits will differ on average across human populations? It will be impossible — indeed, anti-scientific, foolish and absurd — to deny those differences.</p>
</blockquote>
<p>I agree. A study of a large European sample, just published in Nature Genetics, found numerous genetic variants associated with intelligence (<a href="https://doi.org/10.1038/s41588-018-0152-6">Savage et al.&nbsp;2018</a>). Another just-published study found that social mobility was associated with education-linked genetic variants (<a href="https://doi.org/10.1073/pnas.1801238115">Belsky et al.&nbsp;2018</a>). It is not hard to imagine that similar studies using global samples might find even more such variants, and that the distribution of these variants might differ across populations.<sup>1</sup></p>
<p>Reich suggests we can avoid the racist implications of such discoveries by learning from the example of the biological differences between males and females:</p>
<blockquote class="blockquote">
<p>The differences between the sexes are far more profound than those that exist among human populations, reflecting more than 100 million years of evolution and adaptation. Males and females differ by huge tracts of genetic material — a Y chromosome that males have and that females don’t, and a second X chromosome that females have and males don’t.</p>
</blockquote>
<blockquote class="blockquote">
<p>…</p>
</blockquote>
<blockquote class="blockquote">
<p>How do we accommodate the biological differences between men and women? I think the answer is obvious: We should both recognize that genetic differences between males and females exist and we should accord each sex the same freedoms and opportunities regardless of those differences.</p>
</blockquote>
<p>According to Reich, although we’re learning more about our genetic differences every day, when it comes to freedoms and opportunities we should just ignore all these new discoveries.</p>
<p>I’m skeptical this approach will keep sexists and racists at bay.</p>
<p>One problem with Reich’s attempt at an analogy between sex and race is that his account of genetic differences between the sexes is deeply misleading. More importantly, Reich, though rightly drawing our attention to new and perhaps unsettling discoveries about the genome, is making the same fatal error many of us academics have made. By downplaying or ignoring the profound role of the genome in human affairs specifically, we have left a scientific vacuum that will be filled with racist and sexist claptrap.</p>
<p>Here I want to sketch the scientific model of the genome that should fill that vacuum. Many of the key features of this model emerged from research on sea urchin development, which began in the 1840’s, more than a decade before Darwin published <em>On the Origin of Species</em>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-urchin" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/journal.pbio.1000029.g007.png" class="img-fluid figure-img" width="392"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Sea urchin development. Blue color indicates distribution of mRNA transcripts of activinB, a key signaling protein. Figure from <a href="https://doi.org/10.1371/journal.pbio.1000029.g007">Sethi et al.&nbsp;2009</a>.</figcaption>
</figure>
</div>
</div>
</div>
<!-- Spoiler alert: human genetic similarities vastly outweigh genetic differences (and when it comes to sex, there are basically no genetic differences).  -->
<p>Before tackling the genetics of sex and sea urchin development, though, let’s first get a handle on Reich’s scientific perspective on the genetic basis of race.</p>
<!-- If men are innately better at cave man things, and women at cave women things, why should I hire women to do cave man things? And if that logic holds for sex, why not race? -->
<section id="human-genetic-differences" class="level1">
<h1>Human genetic differences</h1>
<p>Richard Lewontin famously <a href="https://doi.org/10.1007/978-1-4684-9063-3_14">argued</a> that because the vast majority of human genetic variation is within populations and not between them, racial classification is of no “genetic or taxonomic significance.”</p>
<p>I used to teach this, but it’s wrong.</p>
<p><a href="https://doi.org/10.1002/bies.10315">Edwards (2003)</a>, citing earlier analyses that Lewontin should have known about (and probably did), including those of Cavalli-Sforza and himself in the 1960’s and stretching back to Fisher in the 1920’s, noted that Lewontin had made a profound mistake:</p>
<blockquote class="blockquote">
<p>[Lewontin’s] conclusions are based on the old statistical fallacy of analysing data on the assumption that it contains no information beyond that revealed on a locus-by-locus analysis, and then drawing conclusions solely on the results of such an analysis. The ‘taxonomic significance’ of genetic data in fact often arises from correlations amongst the different loci, for it is these that may contain the information which enables a stable classification to be uncovered.</p>
</blockquote>
<p>Correlations among genetic loci show clear, unmistakable population structure that more or less corresponds to what most Westerners think of when they think of race (e.g., African, Asian, and European):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-pca" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/F2.large.jpg" class="img-fluid figure-img" width="640"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Principal components analysis of population structure in 554 individuals. First two principal components (PCs) are shown here. Each individual is represented by one dot and the color label corresponding to their self-identified population origin. The percentage of the variation in genetic distances explained by each PC is shown on the axes. Figure and caption from <a href="https://doi.org/10.1101/gr.085589.108">Xing et al.&nbsp;2009</a>.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ancestry" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/ancestry.jpg" class="img-fluid figure-img" width="640"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Regional ancestry inferred with the frappe program at K = 7 (13) and plotted with the Distruct program (31). Each individual is represented by a vertical line partitioned into colored segments whose lengths correspond to his/her ancestry coefficients in up to seven inferred ancestral groups. Population labels were added only after each individual’s ancestry had been estimated; they were used to order the samples in plotting. Figure and caption from <a href="https://doi.org/10.1126/science.1153717">Li et al.&nbsp;2009</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Discerning population structure from genetic variation works best, however, when analyses are restricted to variation that is not under selection, the &gt;90% of the genome that is “junk,” i.e., has no influence on the phenotype (<em>non-functional</em> DNA). The genetic basis of “Race,” in this case, cannot have anything to do with racial traits (and there are critiques of the genetic clustering algorithms, e.g., <a href="https://doi.org/10.1101/066431">Lawson et al.&nbsp;2018</a>). I <a href="../../2019/07/27/about-90-of-the-genome-is-junk-which-is-very-informative-about-ancestry-but-says-little-about-biology/">blog about this here</a>.</p>
<p>There are also population differences, though, in the fraction of the genome that actually does something (<em>functional</em> DNA, currently estimated at about 8.2% of the entire genome; <a href="https://doi.org/10.1371/journal.pgen.1004525">Rands et al.&nbsp;2014</a>). Some of those differences represent adaptations to local environmental conditions:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-adaptations" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/Fan2016.png" class="img-fluid figure-img" width="1085"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Examples of human local adaptations, each labeled by the phenotype and/or selection pressure, and the genetic loci under selection. Figure and caption from <a href="https://doi.org/10.1126/science.aaf5098">Fan et al.&nbsp;(2016)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>And some differences reflect population-specific disease risk: the dramatic population expansions that have occurred since modern humans left Africa have resulted in large number of rare, and probably somewhat deleterious, mutations that tend to be population-specific (<a href="https://doi.org/10.1126/science.1217283">Keinan and Clark 2012</a>).</p>
<p>Despite their disagreements, Lewontin, Edwards, Cavalli-Sforza, and Reich all focus on genetic <em>differences</em>, the 4-5 million variant sites that we now know exist in each human genome:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-variants" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/variantsites.png" class="img-fluid figure-img" width="703"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Variant sites per genome, relative to the reference human genome. Each symbol is one genome. Organized by population, and sorted by the number of variants. Figure from <a href="https://doi.org/10.1038/nature15393">The 1000 Genomes Project Consortium, 2015</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Population differences in functional DNA, in particular, are the basis of Reich’s warning that, if it hasn’t already, science will eventually produce evidence of “substantial biological differences among human populations.”</p>
<p>The question is, substantial relative to what?</p>
</section>
<section id="human-genetic-similarities" class="level1">
<h1>Human genetic similarities</h1>
<p>Four-to-five million variants in each human genome sounds like a lot, until you realize that the human genome has about 3 billion nucleotides (bases), each of which could vary. Thus (somewhat naively) only about 0.0013–0.0016 of each genome varies. (The story is complicated by structural variants. See this footnote<sup>2</sup>.)</p>
<p>This means that all the genetic information about “race” — the population differences in demography, history, and adaptive and maladaptive differences — as well as individual differences, comes from a very small fraction of the genome, represented here by the orange square:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-waffle" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/index_files/figure-html/fig-waffle-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6: The fraction of the genome that differs between any two individuals. Different parts of the genome vary in different individuals, of course, and these differences are distributed across the genome.</figcaption>
</figure>
</div>
</div>
</div>
<p>What is striking, at least to me, is not our “substantial biological differences” but our substantial biological similarities. Reich can only conclude that our differences are substantial by ignoring all the green squares.</p>
<p>There is a good reason, though, why Reich and many other geneticists have ignored all the green squares and focused on the orange one: it’s much easier to analyze. In science, to determine if X is a <em>cause</em> of Y, which typically requires that we change X and see if Y changes, we instead often start by determining if differences in X <em>correlate</em> with differences in Y. This, of course, requires that there are differences in X and Y to begin with.</p>
<p>When it comes to the orange square, nature has already set up the experiment for us. We simply need to match the 4-5 million genetic differences that already exist, to the geographical or heritable phenotypic differences that already exist. In practice this is not so simple (far from it), but the rapidly expanding number of complete genome sequences from populations around the world have rapidly expanded our ability to match genetic variants to heritable phenotypic variants such as differences in eye, hair, and skin color.</p>
<p>Deciphering the biological “meaning” of all the green squares, on the other hand, faces immense conceptual and technical challenges. How does one determine which of the hundreds of millions of bases in functional DNA that don’t vary are responsible for the different functional parts of phenotype, such as hearts, livers, and lungs, that also don’t vary? <em>A priori</em>, any of the green squares could be involved in the development and functioning of any part (or all) of the phenotype.</p>
<p>Where to start?</p>
<p>The headlines about exciting discoveries in the orange square and the near absence of the same regarding each and every green square, have led the public, and many scientists too, to equate the orange square with the genome, and all but ignore the green squares. This imbalance, evident in Reich’s own op-ed, will “invite the racist misuse of genetics” that Reich rightly fears.</p>
<p>Here I want to give a small taste of the science to decode the green squares that has been slow-cooking for decades, but hasn’t generated sexy headline after sexy headline because it involves, e.g., embryonic development in critters like sea urchins, fruit flies, frogs, nematodes, and mice, or arcane cellular functions like the xenobiotic induction of cytochrome P450 enzymes via nuclear PXR and CAR receptor activation in hepatocytes.</p>
<!-- Because "racial" differences in the brain and behavior are some of the most radioactive topics in all of science, the genome itself has become something of a pariah. Rather than dancing around the influence of genes on behavior (and everything else), however, there is a good scientific case to be made to *identify* the essence of the human species with the quarter of a billion nucleotides that have phenotypic effects[^2], to go all in on the genome. -->
<!-- [^2]: Of the 3 billion nucleotides in the human genome, it is currently estimated that 8.2%, or 246 million nucleotides, are conserved, i.e., have an effect on the phenotype and are therefore subject to purifying natural selection [(Rands et al. 2014)](https://doi.org/10.1371/journal.pgen.1004525). -->
</section>
<section id="the-genetic-program-the-green-squares" class="level1">
<h1>The genetic program (the green squares)</h1>
<p>It has been recognized since antiquity that a seed autonomously develops into the same type of plant that produced the seed, and an egg into the same type of animal that produced the egg. We now know that seeds and eggs are single cells that contain an entire genome. Because adaptations evolve by the natural selection of DNA sequence variants, the functionality of an organism — it’s heart, liver, lungs, bones, muscles, etc. — is somehow encoded in its genome, and that functionality is “constructed” during development.</p>
<p>As the organism develops via cell division, the entire genome is copied into each daughter cell; hence, every cell (with a few exceptions) contains a complete and identical copy of the genome. During development, daughter cells begin to differentiate into different types. Since the genome has not changed, yet encodes the functionality of, e.g., neural vs.&nbsp;epithelial cells, it must be the case that different parts of the genome, and different combinations of those parts, are involved in the development of the different cell types.</p>
<p><a href="https://doi.org/10.1016/B978-0-12-460482-7.50042-7">Jacob and Monad’s (1961)</a> Nobel prize winning discovery that a protein produced by one gene could regulate the expression of a different gene was a key breakthrough in understanding how different parts of the genome encoded different cellular functions. Moreover, this regulatory effect depended on environmental signals. Specifically, Jacob and Monad discovered a genetically encoded regulatory “circuit” in the bacteria <em>E. coli</em>, the <a href="https://en.wikipedia.org/wiki/Lac_operon"><em>lac</em> operon</a>, which produced an enzyme to metabolize lactose, a less valuable food, only if (1) lactose was present and (2) glucose, a more valuable food, was not. It turned out that such regulatory effects aren’t rare. Instead, they’re the whole enchilada.</p>
<p>Based on this discovery, and the insight that similar regulatory mechanisms were operating during the development of the organism, <a href="https://doi.org/10.1016/B978-0-12-460482-7.50042-7">Jacob and Monad (1961)</a> and <a href="https://www.jstor.org/stable/1707986">Mayr (1961)</a> independently introduced the “genetic program” model, which proposes that the functional genome is something like a computer program that, starting from a single cell, creates an adult organism (for the history of this model, see <a href="https://doi.org/10.1016/j.cub.2010.06.027">Gann 2010</a> and <a href="https://doi.org/10.1534/genetics.115.178418">Peluffo 2015</a>). The genetic program comprises a large number of what are now usually called <em>gene regulatory networks</em> (GRNs; <a href="https://doi.org/10.1073/pnas.0408031102">Levine and Davidson 2005</a>):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-grn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/REGNET.png" class="img-fluid figure-img" width="483"></p>
<figcaption class="figure-caption">Figure&nbsp;7: A gene regulatory network. Top: Schematic GRN mechanism. Bottom: Functional representation. Figures from <a href="https://genomicscience.energy.gov/">Genomes to Life Program Roadmap, April 2001, DOE/SC-0036, U.S. Department of Energy Office of Science</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>A GRN is set of genes (protein coding sequences) and non-coding DNA sequences that influence the transcription of those genes to RNA and the translation of RNA to protein. These genetic elements interact in a circuit-like fashion to provide some cellular function, often in response to some environmental signal.</p>
<p>Deciphering the GRNs that control development of the organism from zygote to adult is extraordinarily difficult. To validate that regulatory element X controls gene Y to provide cellular function Z at time <em>t</em>, one must first identify, out of hundreds of millions of nucleotides, candidates for all the regulatory genetic elements and targets. This is typically done by determining which genes are expressed in which cells and when, as seen for activinB in Figure @ref(fig:urchin). One must then show that perturbing regulatory element X changes expression of gene Y and thus changes cellular function Z at time <em>t</em>. Such perturbations cannot be done with human embryos (except, in some jurisdictions, at a very early developmental stage; see <a href="https://doi.org/10.1126/science.aas9302">Rossant and Tam 2018</a>), so almost all the work in this area uses model organisms.</p>
<p>Sea urchins have been especially important model organisms for the study of embryonic development since the middle of the 19th century because their eggs and embryos are relatively transparent, fertilization is external, and embryogenesis is rapid, allowing the early developmental process to be easily observed under a microscope (<a href="https://doi.org/10.1093/icb/37.3.250">Ernst 1997</a>).</p>
<p>Reich’s claim that sex differences in phenotypes are due to “huge tracts of genetic material” possessed by one sex and not the other was disproved over 100 years ago by classic experiments that found that sea urchin eggs with only a sperm nucleus or only a female pronucleus developed relatively normally, demonstrating that chromosomes from the female and male are developmentally and genetically equivalent (<a href="https://doi.org/10.1093/icb/37.3.250">Ernst 1997</a>).</p>
<p>We now know that in most mammals, including humans, sex is determined by the presence or absence of a single gene on the Y-chromosome, SRY, which is only possessed by males. A single gene cannot encode all the functional differences between males and females (e.g,. ovaries vs.&nbsp;testes), and furthermore, the Y-chromosome is very small, containing fewer than 100 genes (<a href="https://doi.org/10.1038/nrg.2017.36">Jobling and Tyler-Smith 2017</a>). Hence, SRY is simply a switch. Most of the sex-specific functionality of male and females comprises GRNs encoded in the autosomes, which are the chromosomes that are present in <em>both males and females</em>.</p>
<p>SRY activates SOX9 on chromosome 17 (an autosome), which initiates development of the testes:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-sry" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/sry.png" class="img-fluid figure-img" width="626"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Overview of sex determination in mice. Chronological flow of early mouse sex differentiation; the grey area indicates the period of sex determination. During mouse embryogenesis, bi-potential gonads (yellow) arise from the genital ridges by 10.5 days post coitum (dpc). In somatic cells of XY genital ridges, Sry expression (shown in dark blue beneath the schematic) starts at 10.5 dpc, reaches a peak at 11.5 dpc and then wanes by 12.5 dpc. A few hours later, Sox9 expression (shown in light blue beneath the schematic) is upregulated to induce differentiation of Sertoli cells. Sox9 expression peaks at 11.5-12.5 dpc, continues to be expressed postnatally and is supported by several positive-feedback loops (including FGF9, prostaglandin D2 and SOX9 itself), and SOX9 subsequently activates many male-specific genes, including Amh. At 12.5 dpc, testis cords have formed, and morphological differences between testis (blue) and ovary (pink) are evident. In the absence of SRY, genes such as Wnt4, Rspo1 and Foxl2 are expressed in a female-specific manner and induce ovarian development, as characterized by the expression of follistatin and many other ovary-specific genes. Abbreviations: Amh, anti-Müllerian hormone; dpc, days post coitum; FGF9, fibroblast growth factor 9; FOXL2, forkhead box L2; PGD2, prostaglandin D2; RSPO1, R-spondin 1; SOX9, SRY box containing gene 9; SRY, sex-determining region on the chromosome Y; WNT4, wingless-type MMTV integration site family, member 4. Figure and caption from <a href="https://doi.org/10.1242/dev.048983">Kashimada and Koopman 2010</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Sry is only active for a very short period of time, just enough to activate a GRN containing SOX9, which has feedback mechanisms to maintain expression levels of SOX9 even after Sry is no longer expressed.</p>
<p>Some of the functional differences between males and females, such as testes and ovaries, develop early in gestation, as pictured here, whereas others, such as (in humans) upper body musculature, breasts, and pelvic changes, develop much later, during puberty.</p>
<p>Thus, sex differences in the phenotype are mostly due to huge tracts of genetic material encoding GRNs on the autosomes (reminder: possessed by both sexes) that are activated differently depending the presence or absence of a single genetic switch, SRY. In fact, there are <a href="https://en.wikipedia.org/wiki/XY_gonadal_dysgenesis">XY individuals</a> who develop as (mostly) normal women due to a mutation in SRY that prevents it from initiating testicular development. Although most XY women do not have functioning ovaries, there is one case of an XY individual who developed as a completely normal woman, with a uterus and histologically normal ovaries, due to a loss-of-function mutation in an autosomal gene that itself activates SRY (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2680992/">Biason-Lauber et al.&nbsp;2009</a>). There are also <a href="https://en.wikipedia.org/wiki/XX_male_syndrome">XX men</a>. These examples prove that most of the functional differences between males and females are encoded in GRNs on the autosomes and the X-chromosome, and that SRY is just a genetic switch.<sup>3</sup></p>
<p>In some species, the sex-determination switch is environmental, not genetic. In many reptiles, for example, male developmental pathways are triggered at one temperature and female pathways at another. A key molecular component in temperature-dependent sex determination in red-eared slider turtles has just been found, in fact (<a href="https://doi.org/10.1126/science.aap8328">Ge et al.&nbsp;2018</a>).</p>
<p>Conceptually, then, there isn’t much difference between a genetic switch, such as SRY, and an environmental one, such as a temperature threshold: they both serve as inputs to GRNs that then generate sexually distinct phenotypes. Sex differences aren’t explained by genetic differences; instead, the universal genetic program has gotten different information (the presence or absence of a switch) and built different phenotypes.</p>
<p>Based on studies of their roles in sea urchin embryo development, GRNs are often modeled as Boolean circuits:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-subcircuits" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/subcircuits.png" class="img-fluid figure-img" width="970"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Structure and function of different types of subcircuit. (A) Positive feedback subcircuit. (B) Community-effect subcircuit. (C) Coherent feedforward subcircuit. (D) Incoherent feedforward subcircuit. (E) Mutual-repression subcircuit. (F) Double-negative gate subcircuit. All except the subcircuit in D are examples from the sea urchin endomesoderm GRN. (Left) The topologies of regulatory interactions in each subcircuit. (Right) The expression of each gene in the subcircuit under each condition, as determined by Boolean modeling. The indicated time steps do not represent real time. Blue, expression; gray, no expression. DN, double-negative gate; D/N, Delta/Notch signaling; Mat., maternal; Skel., skeletogenic; Ubi, ubiquitous activator. Figure and caption from <a href="https://doi.org/10.1073/pnas.1610616114">Peter and Davidson 2017</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Here is the network of such genetic subcircuits involved in the early development of the sea urchin embryo (different colors indicate the different subcircuits):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-endomesoderm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/endomesodermGRN.png" class="img-fluid figure-img" width="1048"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Distribution of subcircuits in the endomesoderm GRN. Subcircuits of each type identified in the endomesoderm GRN model are color-coded as follows: pink, double-negative gate; dark blue, coherent feedforward subcircuit; light blue, community-effect subcircuit; yellow, positive feedback subcircuit; green, signaling interaction; red, toggle switch circuitry; and brown, mutual-repression subcircuit. For recent updates of the endomesoderm GRN model, see http://grns.biotapestry.org/SpEndomes/. Figure and caption text from <a href="https://doi.org/10.1073/pnas.1610616114">Peter and Davidson 2017</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice that the network takes inputs from the mother (upper left), in the form of maternal mRNA sequestered in the egg. More importantly, notice the complexity of the GRN governing early development in the sea urchin.</p>
</section>
<section id="the-custom-built-phenotype" class="level1">
<h1>The custom-built phenotype</h1>
<p>These examples motivate the genetic program model. The genome is an extraordinarily complex developmental program that is identical in all humans, including males and females and all populations, and which comprises a very large number of GRNs. These GRNs evolved by natural selection, and are therefore adaptations (for an excellent review of GRNs in evolutionary context, see <a href="https://doi.org/10.1146/annurev-genom-091212-153423">Rebeiz et al.&nbsp;2015</a>). GRNs, which are often modeled as Boolean or continuous circuits (e.g., <a href="https://doi.org/10.1038/nrm2503">Karlebach and Shamir 2008</a>), govern development of the zygote from a single cell to an adult, and could be active throughout life. Many GRNs take environmental cues as inputs, including environmental factors like temperature, chemical gradients within and between cells, inter- and intracellular signaling molecules, DNA methylation, and interactions among elements of the GRN mediated by, e.g., transcription factors and RNA, that then alter developmental trajectories in ways that would have increased fitness in the ancestral environment of that GRN (for an interpretation of this model in terms of evolutionary game theory, see <a href="http://anthro.vancouver.wsu.edu/media/PDF/Hagen_and_Hammerstein_2005_Evo_Devo.pdf">Hagen and Hammerstein, 2005</a>). Individuals who grow up in different language communities might have brains that differ in some respects, for example (e.g., <a href="https://doi.org/10.1111/1467-8624.00118">Geary and Bjorklund 2000</a>), as might those who grow up in different family environments (e.g., <a href="https://doi.org/10.1016/S1090-5138(03)00039-4">Quinlan 2003</a>).</p>
<p>Here is a dramatic example in water fleas. These two individuals are genetic clones. The morph on the left was exposed to a chemical cue from a predatory fish and therefore developed a protective (but “expensive”) helmet and long tail; the one on the right was not exposed to the cue, and could therefore divert helmet-building resources to other uses:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-daphnia" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/Daphnia.jpg" class="img-fluid figure-img" width="900"></p>
<figcaption class="figure-caption">Figure&nbsp;11: Two individuals of a single clone of the Asian and African water flea, Daphnia lumholtzi. The individual on the left was exposed to chemical cues from predaceous fish (induced); the individual on the right was not (control). The sharp helmet and extended tail spine of the induced morph protectD. lumholtzi from fish predators. The uninduced form was formerly described as a different species (D. monacha Brehm 1912). Green (83), in an accurate and prophetic study, related the occurrence of both morphs to differences in fish predation. The induction of this morphological defense has now been implicated as a key factor in the success of D. lumholtzi invading North America (84). Figure and caption from <a href="https://doi.org/10.1126/science.1060701">Agrawal 2001</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Some GRNs might also take as inputs the presence or absence of genetic elements that are under, e.g., frequency-dependent or local selection, interpretable as genetic switches, cues, or randomization devices; SRY is a clear example. Speculatively, there might be additional genetic switches or cues in humans that would generate distinct (possibly behavioral) phenotypes, as there are in some other species (e.g., <a href="https://doi.org/10.1086/680982">Le Rouzic et al.&nbsp;2015</a>).</p>
<p>The point here is that such genetic elements, whose states vary among individuals, are often best interpreted as serving the same role as environmental cues: as information about upcoming selective conditions that serve as inputs for various universal GRNs (<a href="https://doi.org/10.1086/499566">Leimar et al.&nbsp;2006</a>). The genetic program then builds a phenotype customized to “do well” in those selective conditions.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-geneticprogram" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/geneticprogram.png" class="img-fluid figure-img" width="1129"></p>
<figcaption class="figure-caption">Figure&nbsp;12: The genetic program model of the genome. A universal genetic program comprising thousands of GRNs (green squares) reads many different types of inputs and to produce a phenotype that is custom-built for (its best guess about) the upcoming selective environmental conditions.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="implications-for-sex-and-race" class="level1">
<h1>Implications for sex and race</h1>
<p>How does the genetic program model help us think about sex differences and racial differences? Regarding sex differences, the presence or absence of SRY is very important, yes, but for any individual woman or man, all the other inputs to the developmental program — the epigenetic switches, environmental cues, and perhaps other frequency dependent switches — are also very important. The genetic program determines a person’s phenotype using <em>all</em> its inputs, not just SRY. The same goes for race. Some parts of the orange square will have some influence on the phenotype, true, but all of the vastly greater number of green squares and their associated inputs will each have an important influence too. This is the critical background that is utterly missing from Reich’s op-ed.</p>
<p>There are therefore at least two better answers to Reich’s question: “How do we accommodate the biological differences between men and women,” and by extension, the different races? First, at the genetic level, the extraordinarily rich circuits encoded in the GRNs of the human genome are essentially identical in all humans, and, if the complexity of the GRN governing early development of the sea urchin is any guide, their informational content will vastly outweigh that contained in genetic differences. The weight of genetic evidence points to biological similarity, not difference.</p>
<p>Second, at the phenotype level, we all develop with a unique combination of inputs to those GRNs, and so each of our phenotypes is a unique variation on the human theme, custom-built by the universal genetic program to function “well” in our unique environmental circumstances. We could choose to discriminate on the basis of one such input, e.g., SRY, but then why not another, e.g., whether our parents were separated when we were young (<a href="https://doi.org/10.1016/S1090-5138(03)00039-4">Quinlan 2003</a>)? If the genetic program model is correct, there are many possible biological distinctions that could be the basis of discrimination, each a consequence of environmental circumstance, and any one of us could find ourselves on the wrong side of the divide. If water fleas were as in-groupy/out-groupy as humans, the unhelmeted fleas could discriminate against those helmeted heathens, not realizing that their own offspring would also develop helmets should predatory fish appear. Rawl’s <a href="https://plato.stanford.edu/entries/original-position/">veil of ignorance</a> is one approach to a just society of unique individuals.</p>
<!-- Critically, there are likely so many inputs to the universal genetic program that any individual will develop with a unique combination of them. Every phenotype will therefore be unique.  -->
<!-- Reich argues that we shouldn't discriminate on the basis of race for the same reason we shouldn't discriminate on the basis of sex. And that reason is, uh, he doesn't say. The genetic program model tells us that different phenotypes are created by different combinations of genetic and environmental switches and cues. There is evidence, for example, that parental separation might cause changes in girls' sexual development (e.g., [Quinlan 2003](https://doi.org/10.1016/S1090-5138(03)00039-4)), perhaps because parental investment is an input to various GRNs governing female sexual development. Should we therefore discriminate for or against women whose parents separated when they were children? The same question would be raised for every other differential input to our universal genetic program, of which there are likely hundreds, perhaps thousands. This is a pretty strong clue that discrimination based on any genetic difference is motivated by something other than its phenotypic effects. -->
<p>I do take Reich’s larger point, though, that it has been an enormous mistake on the part of many scientists and scholars to downplay, ignore, or deny the utterly central role of the genome in who we humans are. Perhaps this is because, today, we understand more about our relatively few genetic differences than we do about our overwhelming genetic similarities. Given that we still don’t fully understand the GRNs involved in sea urchin embryonic development, a system that has been intensively studied for years, it will almost certainly be many decades before we have even a rudimentary understanding of the human genetic program.</p>
<p>Nevertheless, the genetic program, or something like it, will eventually constitute the “meaning” of the functional genome as the product of three and a half billion years of evolution of the human lineage. The orange square will take its place mostly as a combination of the randomness inherent in evolution and as a record of the final few moments of our evolution, the last hundred thousand years since modern humans exploded out of Africa. It is therefore perhaps time that instead of fearing it, we consider <em>embracing</em> the human genetic program, including all of its inputs, as our common biological heritage, because it’s pretty clear that’s where the science is going to end up.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Regarding the construct “intelligence,” my views correspond pretty closely to Cosma Shalizi’s, see, e.g., <a href="http://bactra.org/weblog/494.html">here</a>, <a href="http://bactra.org/weblog/495.html">here</a>, <a href="http://bactra.org/weblog/520.html">here</a>, and <a href="http://bactra.org/weblog/523.html">here</a>. A taste: “If we must argue about the mind in terms of early-twentieth-century psychometric models, I’d suggest that Thomson’s is a lot closer than the factor-analytical ones to what’s suggested by the evidence from cognitive psychology, neuropsychology, functional brain imaging, general evolutionary considerations and, yes, evolutionary psychology (which I think well of, when it’s done right): that there are lots of mental modules, which are highly specialized in their information-processing, and that almost any meaningful task calls on many of them, their pattern of interaction shifting from task to task.”↩︎</p></li>
<li id="fn2"><p>More than 99.9% of the 4-5 million variants are <em>single nucleotide polymorphisms</em> (SNPs) and short insertions or deletions. However, it has recently been discovered that larger variable chunks of DNA, termed <a href="https://en.wikipedia.org/wiki/Structural_variation">structural variants</a> (SVs), though very few in number (the typical genome has a few thousand), affect more bases. See <a href="https://doi.org/10.1038/nature15394">Sudmant et al.&nbsp;2015</a> and <a href="https://doi.org/10.1038/nature15393">The 1000 Genomes Project Consortium, 2015</a>. According to <a href="https://doi.org/10.1038/nature15394">Sudmant et al.&nbsp;2015</a>, when collapsing mCNV (multi allelic copy-number variants) sites “carrying multiple copies as well as homozygous SVs onto the haploid reference assembly, a median of 8.9Mbp of sequence are affected by SVs, compared to 3.6 Mbp for SNPs.” Most bases affected by SVs are either due to deletions or copy number variants. There is evidence of purifying selection against deletions in functional regions of the genome, but less so for copy number variants, indicating relaxed constraints on the latter. Common SVs are shared across continents whereas rare ones tend to be continent-specific.↩︎</p></li>
<li id="fn3"><p>The Y-chromosome has a very complex structure, including <em>pseudoautosomal</em> regions that recombine with the X-chromosome. There are some genes in the male-specific region of the Y-chromosome other than SRY that do play critical roles in the male phenotype, however. Hence, some of the male genetic program is encoded on the Y-chromosome, and not on the autosomes or X-chromosome. For review, see <a href="https://doi.org/10.1038/nrg.2017.36">Jobling and Tyler-Smith 2017</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/index.html</guid>
  <pubDate>Mon, 25 Jun 2018 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-06-25-the-universal-genetic-program-and-the-custom-built-phenotype-implications-for-race-and-sex/Daphnia.card.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>While it may be true that Evolutionary Anthropologists consider themselves scientists…</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/index.html</link>
  <description><![CDATA[ 




<p><a href="https://caseyroulette.weebly.com">Casey Roulette</a>, a former PhD student of mine who is now an assistant professor at San Diego State University, recently received an <a href="RouletteEmail.pdf">email</a> from a member of the <a href="http://www.bio.sdsu.edu/faculty/faculty.html">Biology Department</a> who was irate that Casey’s evolutionary anthropology course, <em>Evolution of Human Nature</em>, was being considered to fulfill “Natural Sciences” GE reqs. She informed him that she had complained to her Chair, who in turn complained to the Dean of the College of Sciences, and that “Both will be preparing a letter to be sent to the GE committee indicating that the College of Sciences does not support this course as a GE course.” The <a href="RouletteEmail.pdf">email concluded</a>:</p>
<blockquote class="blockquote">
<p>While it may be true that Evolutionary Anthropologists consider themselves scientists and use the terms evolution and evolutionary, the “Evolutionary Biology” represented in this course does not reflect or represent modern Evolutionary Biology as defined by Evolutionary Biologists.</p>
</blockquote>
<blockquote class="blockquote">
<p>In our meeting with the Instructor, who I know is an Assistant Professor, I thought it was not collegial to point out that his views on “evolutionary anthropology” are not considered accurate by those of us trained in Evolutionary Biology.</p>
</blockquote>
<blockquote class="blockquote">
<p>…</p>
</blockquote>
<blockquote class="blockquote">
<p>It is deeply concerning that students could leave this campus with such an erroneous understanding of such a fundamental scientific process.</p>
</blockquote>
<p>She attached <a href="Evaluation.pdf">an evaluation from the SDSU Department of Biology</a>. The first part argued that, on programmatic grounds, the course did a good job fulfilling the Social Science reqs. I agree.</p>
<p>The second part, however, echoed the email, arguing on <em>scientific</em> grounds that the course did not qualify as a GE course in the Natural Sciences because it presented a view of biology that was incomplete, biased and incorrect.</p>
<p>That’s odd. If true, Casey’s course shouldn’t qualify for GE in either the Social or Natural Sciences. In fact, his course shouldn’t be taught at all.</p>
<p>SDSU biologists’ first concern was that Casey presents evolution as synonymous with adaptation:</p>
<blockquote class="blockquote">
<p>The “Evolutionary” approach presented in this class seems to present biological evolution as synonymous with adaptation via natural selection. Natural selection is but one of the five evolutionary forces that determine patterns of variation within and among species. For example, no information is provided on the very important role of Random Genetic Drift in shaping genetic variation.</p>
</blockquote>
<blockquote class="blockquote">
<p>The practice of interpreting biological patterns only through the lens of adaptation has been labeled the “Adaptionist program”. For four decades, biologists have recognized the folly of this approach. The phrase “The Fallacy of Intuitive Evolutionary Thinking” has also been used to describe the assumption that every biological feature has been optimized by selection. Evolutionary biologists accept the power of Darwinian natural selection but we do so understanding that natural selection is a complex process.</p>
</blockquote>
<p>Their second concern was that Casey does not discuss genetic drift, and its role in human evolution:</p>
<blockquote class="blockquote">
<p>There is no discussion of the Neutral and Nearly Neutral models of Evolution, which have been the dominant models of molecular evolution for 50 years.</p>
</blockquote>
<blockquote class="blockquote">
<p>It is also well established that Homo sapiens has an effective population size (Ne) of approximately 10,000. With such a small effective population size it is widely understood (among evolutionary biologists) that selection is inefficient in H. sapiens. Because of this evolutionary biologists would expect to see high levels of both fixed and segregating neutral and nearly neutral (slightly deleterious) alleles within and between human populations. Our most current understanding of genetic variation in does not fit in to the pan selectionist approach presented in this class.</p>
</blockquote>
<p>By “the pan selectionist approach” I suppose they are referring to the focus of Casey’s course, <a href="https://en.wikipedia.org/wiki/Human_behavioral_ecology">Human Behavioral Ecology (HBE)</a>.</p>
<p>The <a href="https://doi.org/10.1007/s10539-016-9557-8">debate</a> over adaptationism, however, is an ongoing <a href="https://plato.stanford.edu/entries/adaptationism/"><em>debate</em></a>, one that began more than a century ago. Each side has involved towering figures in evolutionary biology like Fisher, Wright, Williams, Hamilton, Maynard Smith, Gould, Lewontin, and Kimura.</p>
<p>The neutralist–selectionist debate — are patterns of genetic variation primarily explained by random genetic drift or natural selection? — is, again, a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1513187/"><em>debate</em></a>.</p>
<p>Does Casey’s <a href="ANTHProposal.pdf">syllabus</a> present both sides of these debates?</p>
<p>The assigned reading in Week 2 of the course is Stephen Jay Gould’s <a href="http://www.stephenjaygould.org/library/gould_art-of-story-telling.pdf"><em>Sociobiology: the art of storytelling</em></a>. It was Gould, of course, who with co-author Richard Lewontin, introduced the phrase “Adaptationist Programme” in their hugely influential article <a href="http://rspb.royalsocietypublishing.org/content/royprsb/205/1161/581.full.pdf"><em>The spandrels of San Marco and the Panglossian paradigm: a critique of the adaptationist programme</em></a>. One of Gould’s key points is the important role of genetic drift.</p>
<p>More importantly, one of two required books for the course is Laland and Brown’s <a href="https://books.google.com/books?id=2KcbFVBSxWYC&amp;lpg=PP2&amp;ots=0paM-7Ti3_&amp;dq=%22Sense%20and%20nonsense%3A%20Evolutionary%20perspectives%20on%20human%20behaviour%22&amp;lr&amp;pg=PA1#v=onepage&amp;q&amp;f=false"><em>Sense and nonsense: Evolutionary perspectives on human behaviour</em></a>. I would count Laland as a consistent critic of the adaptationist program (in favor of his alternative, <a href="https://doi.org/10.1017/S0140525X00002417">niche construction</a>, developed in collaboration with eminent population geneticist <a href="http://www-evo.stanford.edu/Feldman-cv.pdf">Marcus Feldman</a>) whose book is a good-faith effort to describe the controversies as they apply to human evolution. Laland and Brown do discuss neutral theory, drift and molecular evolution, especially their intriguing parallels with cultural evolution. Casey also assigned chapter 7 of <a href="https://global.oup.com/ushe/product/evolution-of-human-behavior-9780195333589">Evolution of Human Behavior</a>, by Agustin Fuentes, who I would also count as a <a href="https://doi.org/10.1017/S0140525X0235009X">critic of adaptationism</a>.</p>
<p>Although Casey’s course focuses on the evolution of the human behavioral phenotype and not molecular evolution, I see no evidence that the course, which also assigns Wrangham’s <a href="https://books.google.com/books/about/Demonic_Males.html?id=fP0c4b3jbMYC"><em>Demonic males</em></a>, is giving students a biased overview of the <a href="https://books.google.com/books/about/Defenders_of_the_Truth.html?id=uar4qh_ELuEC">debates</a> over adaptationism and neutralism vs.&nbsp;selectionism.</p>
<p>And it’s not quite true that neutral models “have been the dominant models of molecular evolution for 50 years.” Instead, the intense debate has perhaps resulted in a consensus. According to evolutionary geneticists <a href="http://dx.doi.org/10.1038/hdy.2016.55">Charlesworth and Charlesworth</a>, “From the late 1980s, the neutral theory came increasingly to be used as a null hypothesis, against which alternative hypotheses could be tested, including the models of the effects of selection on neutral or nearly neutral variability at linked sites….”, a point also made by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1513187/">Masatoshi Nei</a> and Kimura himself.</p>
<p>At this point I should admit that I’m an unreconstructed <a href="http://www.nybooks.com/articles/1997/06/12/darwinian-fundamentalism/">ultra-Darwinian Fundamentalist</a> who, each night, reads his daughters passages from the Selfish Gene. <a href="http://anthro.vancouver.wsu.edu/media/PDF/Hagen_1999_The_functions_of_postpartum_depression.pdf">Depression is an adaptation!</a> <a href="https://dx.doi.org/10.3389%2Ffpsyt.2013.00142">Drug use is an adaptation!</a> This was my logo for the first iteration of this blog:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/pangloss.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Pangloss</figcaption>
</figure>
</div>
<p>Casey, what’s with the balanced overview? Did I teach you nothing?</p>
<p>In my view, critics of adaptationism have things backwards. For adaptationists, the question is not, do constraints and noise play an important role in organism structure? The question is, why don’t constraints and noise dominate organism structure? Constraints and noise permeate physical processes, yet organisms — intricate machines that surpass all human technology — somehow manage to make precise copies of themselves in hostile environments. It is exactly this <a href="https://archive.org/details/WhatIsLife-EdwardSchrodinger">problem</a>, as I discuss in a bit <a href="http://anthro.vancouver.wsu.edu/media/PDF/Buss2.2.pdf">more detail here</a>, that adaptationists are trying to solve.</p>
<!-- Calling on the [second law of thermodynamics](https://en.wikipedia.org/wiki/Second_law_of_thermodynamics), Schrödinger [pointed out](https://archive.org/details/WhatIsLife-EdwardSchrodinger) that: -->
<!-- >It is by avoiding the rapid decay into the inert state of ‘equilibrium’ that an organism appears so enigmatic; so much so, that from the earliest times of human thought some special non-physical or supernatural force (vis viva, entelechy) was claimed to be operative in the organism, and in some quarters is still claimed. -->
<!-- Drift and constraints only come into play if organisms survive and reproduce, and it is exactly this enormously difficult problem – how organisms survive and reproduce in a particular physical, biological, and social environment – that adaptationists are trying to solve. I discuss this a bit more [here](http://anthro.vancouver.wsu.edu/media/PDF/Buss2.2.pdf). -->
<p>The population genetics folks have it right: random genetic variation, and more generally, noise, by-products, constraints, and thermodynamically favored physics and chemistry, should always be the null hypotheses that an adaptationist hypothesis needs to beat.</p>
<p>Course approval at SDSU is a pretty trivial topic, but the evidence for noise vs.&nbsp;selection in the human genome is not. I therefore thought I would use this post as an opportunity to learn a bit more about it. It’s not meant to be a comprehensive review, just a taste of some major issues. I’m not a genetics guy — far from it — so if I make any mistakes, let me know in the comments.</p>
<section id="population-genetics-101" class="level3">
<h3 class="anchored" data-anchor-id="population-genetics-101">Population genetics 101</h3>
<p>The SDSU biologists’ argument that, due to a small effective population size (<img src="https://latex.codecogs.com/png.latex?N_e">), selection is “inefficient” in <em>H. sapiens</em> rests on a classic result from population genetics. Each generation is a sample of alleles from the previous generation. A particular allele might decrease the probability that individuals with the allele reproduce (negative selection), increase the probability (positive selection), or have no effect (neutral). This effect is quantified by the selection coefficient, <img src="https://latex.codecogs.com/png.latex?s">, which is the difference in fitness, <img src="https://latex.codecogs.com/png.latex?W">, between two alleles, the wild type, A, and a mutant type, B:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0As%20=%20W_B%20-%20W_A%0A"></p>
<p>Even when <img src="https://latex.codecogs.com/png.latex?s=0">, the frequencies of A and B will change at least a little bit from generation to generation due to random differences in the survival and reproduction of individuals with A vs.&nbsp;B. On average, however, the frequency of a neutral mutant allele in a new generation is, under some strong simplifying assumptions, simply the frequency of the allele in the original generation.</p>
<p>If the population is small, however, then the “sample size” is small. Just as we learn in statistics, the smaller the sample size, the larger the variance in the “sample estimate.” Thus, in small populations, the frequency of a neutral allele will bounce around from generation to generation more than it would in large populations, eventually going to either 0 (lost) or 1 (fixed). In particular, the frequency of a new mutation is small, so there’s a good chance that it won’t be “sampled,” and will thus be lost.</p>
<p>But what if the allele isn’t neutral? Naively, if an allele has a negative effect on fitness, <img src="https://latex.codecogs.com/png.latex?s%3C0">, then its frequency should go to 0, and if it has a positive effect on fitness, <img src="https://latex.codecogs.com/png.latex?s%3E0">, then its frequency should go to 1. Again, though, allele frequencies fluctuate randomly. If these fluctuations are often larger than the systematic effects of selection, then a deleterious allele can become fixed, and a beneficial allele can be lost. This is much more likely to happen when a population has a small effective population size (for review of the <img src="https://latex.codecogs.com/png.latex?N_e"> concept, see <a href="http://dx.doi.org/10.1038/nrg2526">Charlesworth 2009</a>). Generally, only when the magnitude of <img src="https://latex.codecogs.com/png.latex?s"> is greater than twice the reciprocal of effective population size will the fate of an allele will be dominated by its fitness effects:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7Cs%7C%20%3E%20%5Cfrac%7B1%7D%7B2N_e%7D%0A"></p>
<p>Otherwise, its fate will be dominated by drift. This is what SDSU biologists were referring to: as <img src="https://latex.codecogs.com/png.latex?N_e"> decreases, the fate of alleles will increasingly be dominated by drift.</p>
<p>The importance of selection also depends on <img src="https://latex.codecogs.com/png.latex?s">, however, the fitness of a new allele relative to an existing allele, a fact that the SDSU biologists failed to mention.</p>
<!-- The rate of evolution depends on the rate of production of new mutations, which is proportional to the mutation rate, $\mu$, the census population size, $N_c$ (because bigger populations will produce more mutations), and the probability that a mutation spreads and becomes fixed ([Lanfear et al. 2014](http://dx.doi.org/10.1016/j.tree.2013.09.009)): -->
<!-- $$ -->
<!-- R = 2N_c \mu P -->
<!-- $$ -->
<!-- The probability of fixation, in turn, depends on the selection coefficient of a mutation.  -->
<p>Figure&nbsp;1, from <a href="http://dx.doi.org/10.1016/j.tree.2013.09.009">Lanfear et al.&nbsp;2014</a>, illustrates the relationship between <img src="https://latex.codecogs.com/png.latex?N_e">, <img src="https://latex.codecogs.com/png.latex?s">, and the rate of evolution — the substitution rate vs.&nbsp;the mutation rate — conveniently using parameters that approximate those for ancestral <em>Homo</em>. The top panels illustrate positive selection, and the bottom panels negative selection. The left-hand panels show that the substitution rate increases not only as <img src="https://latex.codecogs.com/png.latex?N_e"> increases, but also as <img src="https://latex.codecogs.com/png.latex?s"> increases. The right-hand panels depict the relationship between the ratio of substitution rate to the mutation rate (on the y-axis) and <img src="https://latex.codecogs.com/png.latex?N_es">. For <img src="https://latex.codecogs.com/png.latex?N_es%20%3C%201"> (to the left of the dotted line), the substitution rate is approximately the mutation rate (drift). For <img src="https://latex.codecogs.com/png.latex?N_es%20%3E%201"> (to the right of the dotted line), the substitution rate either begins to skyrocket beyond the mutation rate (positive selection) or drop to 0 (negative selection).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-subrate" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/Lanfear2014.png" class="img-fluid figure-img" width="1010"></p>
<figcaption class="figure-caption">Figure&nbsp;1: The relationship between substitution rate (in substitutions per site per year) and effective population size (<img src="https://latex.codecogs.com/png.latex?N_e">) under genetic drift and natural selection (the <img src="https://latex.codecogs.com/png.latex?N_eRR">) [8]. These relationships were calculated assuming a mutation rate of <img src="https://latex.codecogs.com/png.latex?1%20%5Ctimes%2010%5E%7B-9%7D"> mutations per site per year, approximately that found in humans. (A,B) show the substitution rate of mutations for a range of positive (A) and negative (B) selection coefficients (denoted ‘s’). (C,D) show the same data, but in this case the y-axis shows the substitution rate relative to the mutation rate, and the x-axis shows the product of <img src="https://latex.codecogs.com/png.latex?N_e"> and the selection coefficient for positive (C) and negative (D) mutations respectively. A dashed line highlights where <img src="https://latex.codecogs.com/png.latex?N_es%20=%201">, below which mutations are often considered ‘effectively neutral’. Note that genetic drift predicts a flat <img src="https://latex.codecogs.com/png.latex?N_eRR"> for neutral mutations, where <img src="https://latex.codecogs.com/png.latex?s%20=%200.00"> in (A,B). In (C,D), this is reflected by the substitution rate equaling the mutation rate, giving a value of 1 on the y-axis, when <img src="https://latex.codecogs.com/png.latex?N_es%20=%200">. Figure and Caption from <a href="http://dx.doi.org/10.1016/j.tree.2013.09.009">Lanfear et al.&nbsp;2014</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>So, for humans, we need two pieces of evidence, (1) <img src="https://latex.codecogs.com/png.latex?N_e">, and (2) the plausible range of values that <img src="https://latex.codecogs.com/png.latex?s"> might take, referred to as the distribution of fitness effects (DFE) for new alleles.<sup>1</sup></p>
</section>
<section id="empirical-estimates-of-effective-population-size-n_e" class="level3">
<h3 class="anchored" data-anchor-id="empirical-estimates-of-effective-population-size-n_e">Empirical estimates of effective population size (<img src="https://latex.codecogs.com/png.latex?N_e">)</h3>
<p>Like all other lineages, the human lineage extends back to the origin of life, <img src="https://latex.codecogs.com/png.latex?%3E3"> billion years ago. It is therefore informative to consider the <img src="https://latex.codecogs.com/png.latex?N_e"> of our lineage over different periods of our evolution. Here is a relatively recent estimate of divergence times and <img src="https://latex.codecogs.com/png.latex?N_e">’s for the great apes, including humans, from <a href="http://dx.doi.org/10.1038/nature12228">Prado-Martinez et al.&nbsp;(2013)</a>:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-apedivergence" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/nature12228-f2.2.jpg" class="img-fluid figure-img" width="463"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Population splits and effective population sizes (<img src="https://latex.codecogs.com/png.latex?N_e">) during great ape evolution. Split times (dark brown) and divergence times (light brown) are plotted as a function of divergence (d) on the bottom and time on top. Time is estimated using a single mutation rate (μ) of <img src="https://latex.codecogs.com/png.latex?1%20%5Ctimes%2010%5E%7B-9%7D"> <img src="https://latex.codecogs.com/png.latex?mut"> <img src="https://latex.codecogs.com/png.latex?bp%5E%7B%E2%88%921%7D"> <img src="https://latex.codecogs.com/png.latex?year%5E%7B%E2%88%921%7D">. The ancestral and current effective population sizes are also estimated using this mutation rate. The results from several methods used to estimate <img src="https://latex.codecogs.com/png.latex?N_e"> (COALHMM, ILS COALHMM, PSMC and ABC) are coloured in orange, purple, blue and green, respectively. The chimpanzee split times are estimated using the ABC method. The x axis is rescaled for divergences larger than <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%2010%5E%7B-3%7D"> to provide more resolution in recent splits. All the values used in this figure can be found in Supplementary Table 5. The terminal <img src="https://latex.codecogs.com/png.latex?N_e"> correspond to the effective population size after the last split event. Figure and caption from <a href="http://dx.doi.org/10.1038/nature12228">Prado-Martinez et al.&nbsp;(2013)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>And here is a recent estimate of <img src="https://latex.codecogs.com/png.latex?N_e"> for modern <em>H. sapiens</em> from about 200,000 years ago to the present, from <a href="https://dx.doi.org/10.1038%2Fng.3015">Schiffels and Durbin (2014)</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ne" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/NeAB.png" class="img-fluid figure-img" width="392"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Estimates of <img src="https://latex.codecogs.com/png.latex?N_e"> for humans. The blue colors are African populations, and the other colors are non-African populations. The top panel used different data that included Native American haplotypes, with better resolution for older population changes than the bottom panel, but less resolution for more recent changes. Figure from <a href="https://dx.doi.org/10.1038%2Fng.3015">Schiffels and Durbin (2014)</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Thus, based on estimated <img src="https://latex.codecogs.com/png.latex?N_e">, and assuming a fixed DFE, the rate of evolution should have been relatively high when the great apes diverged from other apes about 20 million years ago, slowed when hominins diverged from chimpanzees at the end of the Miocene, slowed again, perhaps with the appearance of <em>Homo</em> around the beginning of the Pleistocene, and then very recently accelerated in the late Pleistocene and Holocene.</p>
</section>
<section id="the-distribution-of-fitness-effects-dfe" class="level3">
<h3 class="anchored" data-anchor-id="the-distribution-of-fitness-effects-dfe">The distribution of fitness effects (DFE)</h3>
<p>The DFE of new mutations is not necessarily fixed, however, but could have changed at different points in human evolution. Generally, deleterious mutations are expected to greatly outnumber beneficial ones because there are more ways to break things than improve them, especially if a population is well-adapted to its environmental niche. That means the DFE will generally be shifted toward negative values.</p>
<p>If a population is moving into a new environmental niche, however (point A in Figure&nbsp;4), the fitness of existing alleles might drop, pushing the distribution of fitness effects of new alleles to higher, often positive, values (distributions on the left). As the population adapts and reaches a fitness maximum (point B), new mutations will again almost always be detrimental (distributions on the right).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-DFE" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/Lanfear2014.2.png" class="img-fluid figure-img" width="686"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Fitness landscapes and the distribution of fitness effects. Hypothetical distributions of fitness effects for populations of different sizes at different positions on a simple fitness landscape. A population far from the optimum (A) has a certain proportion of mutations that confer increases in fitness. However, a population at the hypothetical optimum of the landscape (B) cannot increase it fitness, so all mutations are deleterious. In both cases, the proportion of mutations that fall into different categories (Box 2, main text) changes depending on the effective population size. Note that, for simplicity, we have drawn a fitness landscape that varies along a single dimension, but the distributions we have drawn are more similar to those that would come from higher-dimensional fitness landscapes. Furthermore, it is unlikely that any natural population sits at the precise optimum of any fitness landscape. The selection coefficients are shown on natural scales, not log-transformed scales. Figure and caption from <a href="http://dx.doi.org/10.1016/j.tree.2013.09.009">Lanfear et al.&nbsp;2014</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>There are good reasons to believe that our lineage has undergone multiple niche changes, e.g., when hominins diverged from the chimpanzee lineage toward the end of the Miocene, when <em>Homo</em> diverged from other hominins around the beginning of the Pleistocene, when modern humans left Africa c.&nbsp;50-100,000 years ago, and when transitioning to agriculture at the end of the Pleistocene and beginning of the Holocene c.&nbsp;10,000 years ago. During these changes, the DFE could have been shifted to higher values, resulting in a higher rate of evolution despite small <img src="https://latex.codecogs.com/png.latex?N_e">.</p>
<p>Several other mechanisms have been proposed that might either change or stabilize the DFE in different species with different <img src="https://latex.codecogs.com/png.latex?N_e"> and different levels of organism complexity (Figure&nbsp;5).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-DFEmodels" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/DFE_models.png" class="img-fluid figure-img" width="676"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Overview of the main predictions of five theoretical models regarding DFE differences between two species. Here, E[s] is the average selection coefficient of a new mutation, and <img src="https://latex.codecogs.com/png.latex?N_e"> is the effective population size. Figure and caption from <a href="https://doi.org/10.1073/pnas.1619508114">Huber et al.&nbsp;2017</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://doi.org/10.1073/pnas.1619508114">Huber et al.&nbsp;2017</a>, for example, found that polymorphism data from humans, <em>Drosophila</em>, mice, and yeast best supported Fisher’s Geometrical Model, which represents phenotypes as points in a multidimensional phenotype space, whose dimensionality is termed “complexity.” Fitness is a decreasing function of the distance from the optimal phenotype. Because mutations in complex organisms are more likely to disrupt functionality, the average selection coefficient should be more negative in complex vs.&nbsp;simple organisms, a prediction supported by their data (Figure&nbsp;6, panel A):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-FGM" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/FGM.png" class="img-fluid figure-img" width="668"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Empirical support for FGM. (A) Both under the gamma DFE and the Lourenço et al.&nbsp;DFE, estimated average deleteriousness of mutations increases as a function of organismal complexity. (B) The shape parameter of the gamma DFE depends on the breadth of gene expression. Tissue-specific genes have a smaller shape parameter (α) than broadly expressed genes, supporting FGM. This pattern is consistent across overall expression levels. (C and D) By fitting the DFE of Lourenço et al., we can model slightly beneficial mutations in the DFE (green) that are thought to compensate for fixed deleterious mutations in species with small population size. We find support for a larger proportion of slightly beneficial mutations in the DFE of (C) humans than in (D) Drosophila. Figure and caption from <a href="https://doi.org/10.1073/pnas.1619508114">Huber et al.&nbsp;2017</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://doi.org/10.1371/journal.pgen.1004697">Racimo and Schraiber (2014)</a> criticize empirical studies of DFE that rely on fitting the data to a single probability distribution, however, such as normal or gamma. They found, instead, that in humans the DFE (for deleterious mutations only) had a bimodal distribution, with a large peak centered on <img src="https://latex.codecogs.com/png.latex?s%20%5Csim%200"> (neutrality), and smaller peak between <img src="https://latex.codecogs.com/png.latex?-10%5E%7B-5%7D"> and <img src="https://latex.codecogs.com/png.latex?-10%5E%7B-4%7D">:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-racimo" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/journal.pgen.1004697.g002.png" class="img-fluid figure-img" width="1430"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Distribution of fitness effects among YRI polymorphisms in the Complete Genomics dataset, partitioned by the genomic consequence of the mutated site. The right panels show a zoomed-in version of the distributions in the left panels, after removing neutral polymorphisms and log-scaling the x-axis. A) DFE obtained from the genome-wide mapping. B) Zoomed-in version of panel A. C) DFE obtained from the exome-wide mapping. D) Zoomed-in version of panel C. E) DFEs for exonic sites (nonsynonymous, synonymous, splice sites) obtained from the exome-wide mapping and DFEs for non-exonic sites (intergenic, UTR, regulatory) obtained from the genome-wide mapping. F) Zoomed-in version of panel E. Consequences were determined using the Ensembl Variant Effect Predictor (v.2.5). Codon and degeneracy information was obtained from snpEff. If more than one consequence existed for a given SNP, that SNP was assigned to the most severe of the predicted categories, following the VEP’s hierarchy of consequences. NonSyn = nonsynonymous. Syn = synonymous. Syn to unpref. codon = synonymous change from a preferred to an unpreferred codon. Syn to pref. codon = synonymous change from an unpreferred to a preferred codon. Syn no pref. = synonymous change from an unpreferred codon to a codon that is also unpreferred. Splice = splice site. Figure and caption from <a href="https://doi.org/10.1371/journal.pgen.1004697">Racimo and Schraiber (2014)</a>. https://doi.org/10.1371/journal.pgen.1004697.g002</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://doi.org/10.1371/journal.pgen.1004697">Racimo and Schraiber (2014)</a> speculate that the absence of mutations with <img src="https://latex.codecogs.com/png.latex?s%20%3C%20-10%5E%7B-4%7D"> might indicate a cutoff between weakly deleterious mutations that segregate in human populations and highly deleterious mutations that are quickly eliminated by negative selection.</p>
<p>In summary, the rate of evolution depends on both the DFE and <img src="https://latex.codecogs.com/png.latex?N_e">, and involves both negative (purifying) and positive selection; the DFE likely depends on changes to the environment, organism complexity, and perhaps other other factors like robustness and back mutations. The human DFE is an active area of research.</p>
</section>
<section id="standing-variation-and-soft-sweeps" class="level3">
<h3 class="anchored" data-anchor-id="standing-variation-and-soft-sweeps">Standing variation and soft sweeps</h3>
<p>An important further consideration is that the stochastic effects of drift on the fate of beneficial alleles apply mainly to new mutations, because they are initially at very low frequency. Species harbor a large number of neutral, or nearly neutral, alleles, however, termed standing variation, which, because they are already at high frequency, are much less likely to be lost via drift. Moreover, these alleles already exist, so there is no waiting time for new beneficial mutations to appear. When a population moves into a new niche, these formerly neutral alleles can become either deleterious or beneficial and will respond quickly to selection, resulting in a soft sweep <a href="https://doi.org/10.1534/genetics.104.036947">(Hermisson and Pennings 2005)</a>.</p>
<p>Figure&nbsp;8, from <a href="https://doi.org/10.1016/j.tree.2007.09.008">Barrett and Schluter 2008</a>, illustrates that, for smaller values of <img src="https://latex.codecogs.com/png.latex?%5Calpha_b%20=%202N_es_b"> (where the <img src="https://latex.codecogs.com/png.latex?b"> subscript indicates “beneficial”), beneficial standing variants (solid line) have a very high fixation probability relative to new mutations (dashed line):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-softsweep" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/Barrett2008.jpg" class="img-fluid figure-img" width="194"></p>
<figcaption class="figure-caption">Figure&nbsp;8: The probability of fixation of a single new mutation (dashed curve) compared with that of a polymorphic allele that arose in a single mutational event (solid curve). <img src="https://latex.codecogs.com/png.latex?%5Calpha_b%20=%202N_es_b">, where <img src="https://latex.codecogs.com/png.latex?N_e"> is the effective population size and <img src="https://latex.codecogs.com/png.latex?s_b"> is the homozygous fitness advantage. The form of the curve for standing variation in this example assumes that <img src="https://latex.codecogs.com/png.latex?N%20=%20N_e%20=%2025,000">, the dominance coefficient (h) = 0.5 and that beneficial alleles were previously neutral. <img src="https://latex.codecogs.com/png.latex?%5Calpha_b"> is plotted on a logarithmic scale. Figure and caption from <a href="https://doi.org/10.1016/j.tree.2007.09.008">Barrett and Schluter 2008</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>In a study that used a novel machine learning technique to identify hard sweeps (new mutations that go to fixation under positive selection) and soft sweeps across the human genome, <a href="https://doi.org/10.1093/molbev/msx154">Schrider and Kern (2017)</a> found that the vast majority, over 90%, were soft sweeps. In addition, patterns of variation in perhaps half the genome has been affected by a nearby sweep:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-hardsoft" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/msx154f2.png" class="img-fluid figure-img" width="313"></p>
<figcaption class="figure-caption">Figure&nbsp;9: The number of windows assigned to each class by S/HIC in each population.</figcaption>
</figure>
</div>
</div>
</div>
<p>This is a new technique based on simulated training data. Schrider and Kern acknowledge that their results</p>
<blockquote class="blockquote">
<p>may be surprising given the apparently small effective population size and low nucleotide diversity levels in humans. However, if the mutational target for the trait to be selected on is fairly large, then the probability of a population harboring a mutation affecting that trait may be appreciable.</p>
</blockquote>
<p><em>Variance</em> in <img src="https://latex.codecogs.com/png.latex?N_e"> can also be important in determining the relative importance of hard vs.&nbsp;soft sweeps (<a href="https://doi.org/10.1016/j.tree.2013.08.003">Messer and Petrov 2013</a>). <img src="https://latex.codecogs.com/png.latex?N_e"> estimated from sequence data can be dominated by short phases during which <img src="https://latex.codecogs.com/png.latex?N_e"> was small, even though <img src="https://latex.codecogs.com/png.latex?N_e"> was large for long periods during which adaptation by positive selection was much more likely.</p>
<p>In summary, human adaptation by natural selection was often via soft sweeps, in which <img src="https://latex.codecogs.com/png.latex?N_e"> plays a much smaller role.</p>
</section>
<section id="the-effects-of-population-structure-on-the-substitution-rate" class="level3">
<h3 class="anchored" data-anchor-id="the-effects-of-population-structure-on-the-substitution-rate">The effects of population structure on the substitution rate</h3>
<p>Another consideration is that the population genetics models of the effects of <img src="https://latex.codecogs.com/png.latex?N_e"> and <img src="https://latex.codecogs.com/png.latex?s"> on substitution rates make simplifying assumptions, such as random mating (i.e., a lack of population structure), that might easily be violated in real populations. Recent theoretical work has found that population structure can either suppress or amplify the effects of selection (e.g., <a href="http://dx.doi.org/10.1098/rspb.2013.0211">Frean et al.&nbsp;2013</a>).</p>
</section>
<section id="phenotypic-evidence-for-human-evolution" class="level3">
<h3 class="anchored" data-anchor-id="phenotypic-evidence-for-human-evolution">Phenotypic evidence for human evolution</h3>
<p>The final piece of background information to keep in mind is the physiological, morphological, and behavioral evidence for human evolution that has informed the studies of evolutionary biologists from Charles Darwin in the 19th century to <a href="http://ecologyandevolution.cornell.edu/faculty">entire departments</a> of evolutionary biologists in the 21st.</p>
<p>Perhaps the two most dramatic phenotypic examples of human-specific adaptations are (1) bipedalism, and (2) the substantial increase in brain size in humans relative to hominin ancestors and extant apes, most of which occurred since the first appearance of <em>Homo</em> over 2 million years ago (Figure&nbsp;10):</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-brainsize" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/brainsize.png" class="img-fluid figure-img" width="756"></p>
<figcaption class="figure-caption">Figure&nbsp;10: The evolution of primate cranial capacity. Each dot is a fossil specimen. The x-axis is on a log scale. From <a href="http://dx.doi.org/10.1002/9781118332344.ch8">Schoenemann (2013)</a></figcaption>
</figure>
</div>
</div>
</div>
<p>Two recent studies of variation in cranial dimensions in apes and humans (<a href="http://dx.doi.org/10.1098/rspb.2015.1519">Weaver and Stringer 2015</a>; <a href="http://dx.doi.org/10.1111/evo.13361">Schroeder and von Cramon-Taubadel 2017</a>) found that, whereas great ape cranial evolution was largely characterized by strong stabilizing selection, the divergence of <em>Homo</em> from its last common ancestor with chimpanzees was explained by strong directional selection.</p>
<p>The ability to learn language is a widely accepted cognitive difference between humans and chimpanzees that is probably rooted in human encephalization, as might be the cognitive abilities underlying cumulative culture, which is arguably a uniquely human trait (for a review of the evidence for cumulative culture in humans and other animals, see <a href="http://dx.doi.org/10.1111/brv.12053">Dean et al.&nbsp;2013</a>).</p>
<p>The key point here is that there is overwhelming phenotypic evidence that human psychology did evolve under positive natural selection.</p>
<p>Detailed comparisons of other important aspects of human and great ape phenotypes are available in the <a href="https://carta.anthropogeny.org/moca/domains">Matrix of Comparative Anthropogeny (MOCA)</a> of the Center for Academic Training and Research in Anthropogeny (CARTA).</p>
</section>
<section id="empirical-evidence-that-links-genetic-evolution-with-phenotype-evolution" class="level2">
<h2 class="anchored" data-anchor-id="empirical-evidence-that-links-genetic-evolution-with-phenotype-evolution">Empirical evidence that links genetic evolution with phenotype evolution</h2>
<p>We are only at the beginning of very long quest to link phenotypes, including the evolved <a href="https://carta.anthropogeny.org/moca/domains/behavior">behavioral</a> and <a href="https://carta.anthropogeny.org/moca/domains/culture">cultural</a> phenotypes that are the topic of Casey’s course, to the genome, the focus of the SDSU biologists’ letter. Nevertheless, we know a lot more today than we knew 10 or even 5 years ago.</p>
<section id="functional-vs.-junk-dna" class="level3">
<h3 class="anchored" data-anchor-id="functional-vs.-junk-dna">Functional vs.&nbsp;junk DNA</h3>
<p>Genomes can be divided into two parts: functional DNA, which plays a profound role in the phenotype, and “junk” DNA, which plays no role in the phenotype. Functional DNA comprises protein coding regions and non-coding regulatory regions. We now have a pretty good understanding of which DNA sequences code for protein. It is much more difficult, however, to distinguish regulatory DNA from “junk” DNA, and hence to determine the fraction of the genome that is functional, and therefore subject to evolution by natural selectione.</p>
<p>Most attempts to distinguish functional from junk DNA involve identifying sequences that are conserved across species, and are therefore presumed to be under purifying selection (constrained sequences) and thus functional, vs.&nbsp;those that are not conserved across species and so presumably have not been under purifying selection and are therefore likely non-functional “junk” (c.f., <a href="http://blogs.nature.com/news/2012/09/fighting-about-encode-and-junk.html">ENCODE</a>).</p>
<p>A recent estimate (<a href="https://doi.org/10.1371/journal.pgen.1004525">Rands et al.&nbsp;2014</a>) is that 8.2% (7.1–9.2%) of the human genome is functional (constrained). Protein coding sequences comprise about 1% of the genome, and are highly conserved across the mammals (Figure @ref(fig:cvalue), red). Non-coding regulatory sequences have much higher rates of turnover (turnover refers to the loss or gain of purifying selection at a particular locus of the genome caused by changes in the physical or genetic environment, or mutations at the locus itself, that switch it from being functional to being non-functional or vice versa). See Figure&nbsp;11:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cvalue" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/journal.pgen.1004525.g004.png" class="img-fluid figure-img" width="1032"></p>
<figcaption class="figure-caption">Figure&nbsp;11: Schematic summary of the fraction of constrained sequence that has been retained (saturated colours) or turned over (pastel colours) in the human lineage over time (X-axis, divergence time) and how it has been distributed across various categories of functional element. In addition to showing the reduced quantity of preserved constrained sequence with increasing divergence, we infer the reciprocal quantity of sequence that is assumed to have been gained over human lineage evolution. Figure and caption from <a href="https://doi.org/10.1371/journal.pgen.1004525">Rands et al.&nbsp;2014</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Because <img src="https://latex.codecogs.com/png.latex?%3E90%5C%25"> of the human genome appears to be non-functional, sequence variation in this portion should closely follow the neutral model. Our focus, then, is on the evolution of the <img src="https://latex.codecogs.com/png.latex?%5Csim%208%5C%25"> of the genome that is functional.</p>
</section>
<section id="conserved-traits" class="level3">
<h3 class="anchored" data-anchor-id="conserved-traits">Conserved traits</h3>
<p>Perhaps the most important point is that evolutionary anthropologists are keenly interested in the adaptations we <em>share</em> with primates, mammals, vertebrates, and so on. Examples include <a href="http://dx.doi.org/10.1002/evan.20289">lacation</a>, the <a href="http://dx.doi.org/10.1002/ajhb.21092">immune system</a>, <a href="http://dx.doi.org/10.1002/evan.20195">vision</a> and bitter taste and other plant toxin defense mechanisms that are central to <a href="(https://doi.org/10.3389/fpsyt.2013.00142)">Casey’s</a> <a href="https://doi.org/10.1016/j.jep.2018.01.022">research</a>. The major features of these adaptations evolved long before the appearance of <em>Homo</em>, with its small <img src="https://latex.codecogs.com/png.latex?N_e">, but would need to have been maintained by purifying selection during the evolution of <em>Homo</em>.</p>
<p>Much of the genetic basis of adaptations we share with other mammals and primates almost certainly lies in the <img src="https://latex.codecogs.com/png.latex?%5Csim%202%5C%25"> of constrained sequence we share with all other mammals and the <img src="https://latex.codecogs.com/png.latex?%5Csim%206-7%5C%25"> we share with other primates (out of 8.2% total; Figure @ref(fig:cvalue)).</p>
<p>Moreover, many complex adaptations have evolved features that enable them to adjust ontogenetically to local environmental conditions, an ability that I and many others have <a href="http://anthro.vancouver.wsu.edu/media/PDF/Hagen_and_Hammerstein_2005_Evo_Devo.pdf">framed in strategic terms</a>. Examples include the immune system and <a href="https://www.ncbi.nlm.nih.gov/pubmed/18288955">induction of xenobiotic metabolizing enzymes</a>. Humans would not be doing too horribly in a wide range of environments even if there were no human-specific adaptations.</p>
</section>
<section id="human-specific-selection-in-regulatory-sequences" class="level3">
<h3 class="anchored" data-anchor-id="human-specific-selection-in-regulatory-sequences">Human-specific selection in regulatory sequences</h3>
<p>Despite the low <img src="https://latex.codecogs.com/png.latex?N_e"> in <em>Homo</em>, there is increasing genetic evidence for positive natural selection in the human lineage since our divergence from chimpanzees. Given that protein-coding sequences are highly conserved across the mammals, and that most functional DNA comprises regulatory sequences, most human-specific adaptations should be grounded in changes to regulatory sequences.</p>
<p>Human accelerated regions (HARs) are short, evolutionarily conserved DNA sequences that have acquired significantly more DNA substitutions than expected in the human lineage since divergence from chimpanzees. HARs are often, but not always, the product of positive natural selection (other mechanisms include relaxation of constraint, which allows a region to acquire more mutations than it would under purifying selection, and GC-biased gene conversion; <a href="http://doi.org/10.1186/s12915-017-0428-9">Franchini and Pollard 2017</a>).</p>
<p><a href="http://doi.org/10.1186/s12915-017-0428-9">Franchini and Pollard 2017</a> summarized multiple studies that attempted to discover HARs, which differed in the number of species considered to determine “conserved” (which ranged from a few primate species to multiple primate, mammalian and vertebrate species), sequence filtering criteria (e.g., including or excluding coding sequences), and statistical tests for acceleration. Although each study identified a large number of HARs, there was only limited overlap in the identified regions. See Figure&nbsp;12:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-HAR" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/HAR.png" class="img-fluid figure-img" width="593"></p>
<figcaption class="figure-caption">Figure&nbsp;12: Identification of human accelerated elements. Top: the four different approaches used to identify human accelerated regions. Some key differences include (i) the conserved elements used as candidates to identify HARs (which depend on multiple sequence alignments, methods to detect conservation, and whether human was masked in the alignments), (ii) bioinformatics filters that aim to restrict to non-coding elements and/or remove assembly or alignment artifacts, and (iii) tests used to detect acceleration. Bottom: overlap of the different datasets of human accelerated regions. Abbreviations: ANC accelerated conserved non-coding sequences [20]; HACNS human accelerated conserved non-coding sequences [23]; HTBE human terminal branch elements [21]. HARs include the original HARs [19] and the second generation HARs or 2xHARs [100]. Figure and caption from <a href="http://doi.org/10.1186/s12915-017-0428-9">Franchini and Pollard 2017</a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>Most studies of HARs used only sequence data. Some recent studies, though, also incorporated expression data. <a href="http://doi.org/10.1101/gr.192591.115">Gittelman et al.&nbsp;2015</a>, for example, used maps of <a href="https://en.wikipedia.org/wiki/DNase_I_hypersensitive_site">DNase I hypersensitive sites (DHSs)</a> from <a href="https://www.encodeproject.org">ENCODE</a> and the <a href="http://www.roadmapepigenomics.org">Roadmap Epigenomics Projects</a>. DHSs are regions of <a href="https://en.wikipedia.org/wiki/Chromatin">chromatin</a> that serve as markers of regulatory DNA. Of 2,093,197 DHS loci, 113,577 exhibited significant constraint across the primates. DHSs active in fetal cell types, especially fetal brain cells, showed the highest levels of conservation in non-human primates. Of the conserved loci, 524 were accelerated in human evolution (haDHSs), evolving at approximately four times the neutral rate in the human lineage, mostly but not exclusively under positive selection, while other primate lineages evolved at less than half of the neutral rate. Gittelman et al.&nbsp;found that haDHSs tend to target developmentally and neuronally important genes relative to conserved DHSs, which themselves are already highly enriched for these categories.</p>
<p>In another review of several previous studies of HARs, <a href="http://doi.org/10.1093/gbe/evx240">Levchenko et al.&nbsp;2018</a> noted that of the 3500 candidates identified so far, most are in non-coding regions, estimates of the fraction under positive selection range from 15%-85%, many are active in the brain, consistent with this major phenotypic difference between humans and chimpanzees, and about 7-8% are not shared with Neanderthals or Denisovans, consistent with the time of their divergence from the modern human lineage.</p>
</section>
<section id="recent-human-evolution" class="level3">
<h3 class="anchored" data-anchor-id="recent-human-evolution">Recent human evolution</h3>
<p>Human <img src="https://latex.codecogs.com/png.latex?N_e"> started a dramatic increase some 40-50,000 years ago as humans entered multiple new environments. <a href="https://doi.org/10.1073/pnas.0707650104">Hawks et al.&nbsp;(2007)</a> predicted and found that “selection has accelerated greatly during the last 40,000 years.” Co-authors Cochran and Harpending followed up with a book, <em>The 10,000 year explosion: How civilization accelerated human evolution</em> (you can find <a href="http://anthro.vancouver.wsu.edu/media/PDF/Hagen_2009_Human_natures_--_A_review_of_the_10000_year_explosion.pdf">my review of it here</a>). <a href="https://doi.org/10.1126/science.aaf5098">Fan et al.&nbsp;(2016)</a> review many examples of recent, population-specific human adaptations to local environments, such as the arctic, tropical rainforests, and high altitude:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-recentlocal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/Fan2016.png" class="img-fluid figure-img" width="1085"></p>
<figcaption class="figure-caption">Figure&nbsp;13: Examples of human local adaptations, each labeled by the phenotype and/or selection pressure, and the genetic loci under selection. Figure and caption from <a href="https://doi.org/10.1126/science.aaf5098">Fan et al.&nbsp;(2016)</a>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="wrap-up" class="level2">
<h2 class="anchored" data-anchor-id="wrap-up">Wrap up</h2>
<p>Evolutionary anthropologists and human behavioral ecologists investigate the relationships between human environments and humans’ intricate molecular, cellular, anatomical, and behavioral phenotypes, most of which we inherited from primate, mammalian and earlier ancestors that evolved long before our lineage experienced a low <img src="https://latex.codecogs.com/png.latex?N_e">. The extent to which a small <img src="https://latex.codecogs.com/png.latex?N_e"> limited human-specific evolution is still under investigation. It certainly didn’t reduce it to zero, and there are many other factors that might have accelerated it. There is abundant phenotypic evidence for human-specific adaptations, after all, and there is increasing genetic evidence that positive selection played an important role in our evolutionary history, especially selection on standing variation, which is not limited by low <img src="https://latex.codecogs.com/png.latex?N_e">.</p>
<p>Reading through the papers I discussed here, I was encouraged that folks studying human genetic variation seemed interested in, not hostile to, the many adaptationist hypotheses put forward by evolutionary anthropologists and behavioral ecologists. <a href="http://dx.doi.org/10.1038/hdy.2016.55">Charlesworth and Charlesworth</a>, for instance, highlight the importance of kin selection and evolutionary game theory, two theoretical foundations of behavioral ecology. <a href="https://dx.doi.org/10.1038%2Fnrg3336">O’Bleness et al.&nbsp;(2012)</a> give a nod to Lieberman’s endurance running hypothesizes and many other phenotypic comparisons of humans and non-human primates.</p>
<p>So what’s up with the SDSU biologists? The debates over adaptationism and neutralism vs.&nbsp;selectionism have all the hallmarks of a sectarian conflict. Contrary to our rhetoric, academics are among the most ethnocentric of an infamously ethnocentric species. Perhaps — dare I say it? — ethnocentrism is part of <a href="ANTHProposal.pdf">human nature</a>. If so, it’s true of us all.</p>
<p>But, among the primates, our species also evolved a unique ability for <a href="https://doi.org/10.1086/203952">group alliances</a>. The SDSU biologists are doing <a href="http://www.bio.sdsu.edu/faculty/faculty.html">cool stuff</a>. Casey is doing <a href="https://scholar.google.com/citations?user=Oln60WcAAAAJ&amp;hl=en&amp;oi=ao">cool stuff</a>. Knowing Casey as I do, he doesn’t need my advice, but I’ll give it anyway: I doubt the SDSU biologists speak with one voice. There is as much diversity of opinion within groups as there is between them, maybe more. You are one of the very few SDSU social scientists who has a professional interest in what the SDSU biologists are doing. I suspect many of them recognize that.</p>
<p><em>2018/7/15: minor edits to this post to improve clarity.</em></p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>There is debate about the human mutation rate. See <a href="(http://dx.doi.org/10.1038/nrg3295)">Scally and Durbin 2012</a> and <a href="http://dx.doi.org/10.1016/j.gde.2016.07.008">Scally 2016</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/index.html</guid>
  <pubDate>Sat, 03 Mar 2018 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-03-03-while-it-may-be-true-that-evolutionary-anthropologists-consider-themselves-scientists-and-use-the-terms-evolution-and-evolutionary/pangloss.png" medium="image" type="image/png" height="62" width="144"/>
</item>
<item>
  <title>Our statistics don’t suck, our theories do</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/index.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p><em>Every genuine test of a theory is an attempt to falsify it, or to refute it.</em> Karl Popper, 1963.</p>
</blockquote>
<!-- >Arthur: *Brother Maynard! Bring up the Holy Hand Grenade!....How does it, um-- how does it work?* -->
<!-- >Second Brother: *And the Lord spake, saying, "First shalt thou take out the Holy Pin. Then, shalt thou count to three. No more. No less. Three shalt be the number thou shalt count, and the number of the counting shall be three. Four shalt thou not count, nor either count thou two, excepting that thou then proceed to three. Five is right out."*  -->
<!-- > [Monty Python and the Holy Grail](https://www.youtube.com/watch?v=xOrgLj9lOwk) -->
<p>Most social scientists test a substantive hypothesis, which we will call <img src="https://latex.codecogs.com/png.latex?H_1">, by instead testing a null hypothesis, <img src="https://latex.codecogs.com/png.latex?H_0">, which is usually something like “the mean of X equals 0” or “the correlation of X and Y equals 0.” If the probability of the data<sup>1</sup> under <img src="https://latex.codecogs.com/png.latex?H_0"> is low (e.g., <img src="https://latex.codecogs.com/png.latex?p%20%3C%200.05">), the researcher rejects <img src="https://latex.codecogs.com/png.latex?H_0">, which is taken as evidence in favor of <img src="https://latex.codecogs.com/png.latex?H_1">.</p>
<p>This approach, termed <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">null hypothesis significance testing</a> (NHST), has been subjected to scathing criticism. In the social sciences, for example, we know <img src="https://latex.codecogs.com/png.latex?H_0"> is false before we collect a single data point — the mean of X is never exactly 0, the correlation of two variables is never exactly 0, and so forth. Hence, the rejection of such a null, which <a href="http://dx.doi.org/10.1037/0003-066X.49.12.997">Cohen (1994)</a> termed a “nil” hypothesis, just depends on sample size:</p>
<blockquote class="blockquote">
<p><em>Thus far, I have been considering <img src="https://latex.codecogs.com/png.latex?H_0">’s in their most general sense–as propositions about the state of affairs in a population, more particularly, as some specified value of a population parameter. Thus, “the population mean difference is 4” may be an <img src="https://latex.codecogs.com/png.latex?H_0">, as may be “the proportion of males in this population is .75” and “the correlation in this population is .20.” But as almost universally used, the null in <img src="https://latex.codecogs.com/png.latex?H_0"> is taken to mean nil, zero….My work in power analysis led me to realize that the nil hypothesis is always false.</em></p>
</blockquote>
<p>Further, the rejection of a nil <img src="https://latex.codecogs.com/png.latex?H_0"> (which we already know to be false) is exceedingly weak evidence in favor of our pet hypothesis, <img src="https://latex.codecogs.com/png.latex?H_1">. First, rejection of a nil is also probably consistent with many other hypotheses. Worse, if <img src="https://latex.codecogs.com/png.latex?H_1"> predicts, e.g., the mean of X is greater than 0, the chance of being right is 50-50. Even with this incredibly weak standard, lots of social science studies <a href="http://science.sciencemag.org/content/349/6251/aac4716">don’t replicate</a>.</p>
<p>We social scientists might be forgiven for concluding that NHST is deeply flawed. We would be wrong. The problem, instead, is our weak theories.</p>
<p>In the natural sciences, such as physics and chemistry, theories typically predict numerical values for various parameters. Sometimes the predicted value might be 0. Under Einstein’s theory of <a href="https://en.wikipedia.org/wiki/Special_relativity">special relativity</a>, for instance, the speed of light in the direction of the earth’s motion <a href="https://en.wikipedia.org/wiki/Michelson–Morley_experiment">will not differ</a> from the speed of light perpendicular to the earth’s motion. Other times, the predicted values are different from 0. Einstein’s theory of <a href="">general relativity</a>, for example, predicts that the sun will bend star light by a <a href="https://en.wikipedia.org/wiki/Tests_of_general_relativity">specific (non-zero) amount</a>. In either case, the predicted value is a substantive <img src="https://latex.codecogs.com/png.latex?H_0"> (not a nil) that can be meaningfully tested with NHST.</p>
<p>Unlike rejecting a nil, which social scientists usually take as evidence supporting their theory, rejecting a substantive <img src="https://latex.codecogs.com/png.latex?H_0"> <em>rejects</em> the theory! If the difference of the speed of light in one direction vs.&nbsp;another is greater than 0 <img src="https://latex.codecogs.com/png.latex?(p%20%3C%203%20%5Ctimes%2010%5E%7B-7%7D)">, then special relativity is wrong!<sup>2</sup> If the sun bends light more or less than the predicted amount <img src="https://latex.codecogs.com/png.latex?(p%20%3C%203%20%5Ctimes%2010%5E%7B-7%7D)"> then general relativity is wrong!<sup>3</sup> In the natural sciences, NHST is often a powerful tool to <em>challenge</em> theories, not support them (see Figure 1).</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/index_files/figure-html/NHST-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Testing nils vs.&nbsp;substantive nulls. Black vertical line: null. Red vertical line: mean of data. <strong>A</strong>: Rejecting the nil that the mean = 0 is taken as support for a theory predicting that the mean has some value &gt; 0. <strong>B</strong>: Rejecting the substantive null that the mean = 0 rejects the theory. <strong>C</strong>: Failing to reject the substantive null that the mean = 3 fails to reject the theory. All data simulated.</figcaption>
</figure>
</div>
</div>
</div>
<p>Falsifying a theory is an essential step toward developing a better theory.</p>
<p>This critical difference in the use of NHST in the natural vs.&nbsp;social sciences was pointed out by Paul Meehl in <a href="https://doi.org/10.1086/288135">1967</a>:</p>
<blockquote class="blockquote">
<p><em>Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1⁄2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by “success” is very weak, and becomes weaker with increased precision. “Statistical significance” plays a logical role in psychology precisely the reverse of its role in physics.</em></p>
</blockquote>
<p>Most theories in the social sciences, including my own, are so weak that they can only predict that a value will be positive or negative, nothing more (e.g., Figure 1A). Such vague predictions make it harder to falsify these theories, therefore impeding development of better theories.</p>
<p>Yet it is certainly possible to develop social science theories that predict specific values, and thus expose themselves to meaningful challenges with NHST.</p>
<p>My graduate student Aaron Lightner and I, for example, recently missed an opportunity to do better science by following standard practice and testing a nil, when we now realize we should have also tested a substantive null. We conducted a classic framing effect study in which we predicted that participants would make different monetary offers in an ultimatum game if it was framed as a currency exchange than if it was “unframed.” We set up our statistical test in the standard social science way. <img src="https://latex.codecogs.com/png.latex?H_0"> was a “nil”: <em>no difference in mean offers in the framed vs.&nbsp;unframed condition</em>.</p>
<p>We found a huge effect size (<img src="https://latex.codecogs.com/png.latex?d%5Csim2">; see Figure @ref(fig:effectsize)), and our p-value was very small <img src="https://latex.codecogs.com/png.latex?(p%20=%201.8%20%5Ctimes%2010%5E%7B-31%7D)">. We therefore rejected the nil and concluded that there was a difference in mean offers. <a href="http://dx.doi.org/10.1098/rsos.170543">Publication</a>! <img src="https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/rsos170543f13.jpg" class="img-fluid" alt="Effect sizes (absolute values of Cohen’s d) from this study (denoted by ’**’) and a representative sample of previous framing studies. Colours represent game type and bars indicate 95% CI. From Lightner et al.&nbsp;2017: http://dx.doi.org/10.1098/rsos.170543"></p>
<p>We could have put our theory to a much more severe test, however, by proposing a substantive <img src="https://latex.codecogs.com/png.latex?H_0">. In our study, participants self-reported what they thought was a fair offer, and they also made actual monetary offers. Our scientific (not statistical) hypothesis was that actual offers would match self-reported fair offers. These, in turn, would match a cultural norm for offers in currency exchange that differed from offers usually seen in the ultimatum game. If a participant reported that 3% was a fair offer, for instance, then he or she should have offered 3%.</p>
<p>As our substantive <img src="https://latex.codecogs.com/png.latex?H_0">, we therefore should have proposed this: <em>There will be no difference between actual offers and self-reported fair offers</em>. If we had, we would have found that the probability of our data under such an <img src="https://latex.codecogs.com/png.latex?H_0"> was very small<sup>4</sup>, leading us to reject <img src="https://latex.codecogs.com/png.latex?H_0">, and therefore to reject our theory. Specifically, our data showed that although many actual offers were exactly, or very close to, self-reported fair offers (dots that fall on, or close to, the diagonal line), as our theory predicted, many other actual offers differed substantially from self-reported fair offers (dots that are far from the diagonal line), contrary to our prediction:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/F11.large.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Self-reported fair offers vs.&nbsp;actual offers in a framed ultimatum game experiment. There were two framed conditions: banker and customer. From Lightner et al.&nbsp;2017: http://dx.doi.org/10.1098/rsos.170543</figcaption>
</figure>
</div>
<p>We don’t even need to compute a p-value to see that we can reject our substantive <img src="https://latex.codecogs.com/png.latex?H_0">. Our scientific theory is wrong.</p>
<p>Rejecting a theory is cause for excitement, however, not despair. If a physicist did an experiment that convincingly rejected the null that the speed of light in a vacuum is the same in all inertial frames of reference, she would set off an explosion of research in her discipline and end up with a Nobel Prize.</p>
<p>Make no mistake: Aaron and I were delighted that our study confirmed our prediction that offers in the framed conditions would deviate substantially from the unframed condition (clustering near 0 and 1, instead of near 0.50 as in the standard ultimatum game). But, contrary to our prediction, it also found that many participants said that it would be fair to offer X, but then made a very different offer. Why? Great question for a new study!</p>
<p>In the social sciences we need more “Holy Hand Grenade” theories — theories that do not simply make the very weak prediction that, e.g., <img src="https://latex.codecogs.com/png.latex?%5Cbar%7BX%7D%3E0">, which barely deserves to be called a prediction, but instead predict, e.g., that the number shall be three, no more, no less. Such theories can be subjected to severe tests (i.e., potentially falsified) using NHST. Rejecting a substantive <img src="https://latex.codecogs.com/png.latex?H_0%20=%203">, or failing to reject it, would then represent real scientific progress, not the flip of a coin.</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>More precisely, for some test statistic <img src="https://latex.codecogs.com/png.latex?z">, the p-value is the probability of finding a value of <img src="https://latex.codecogs.com/png.latex?z"> equal to or more extreme than that observed, under the assumption that <img src="https://latex.codecogs.com/png.latex?H_0"> is true.↩︎</p></li>
<li id="fn2"><p>In a recent example, the OPERA experiment <a href="https://en.wikipedia.org/wiki/Faster-than-light_neutrino_anomaly">mistakenly observed</a> neutrinos traveling faster than light.↩︎</p></li>
<li id="fn3"><p>Physicists usually demand much smaller p-values than social scientists, e.g., the <a href="https://blogs.scientificamerican.com/observations/five-sigmawhats-that/"><img src="https://latex.codecogs.com/png.latex?5%5Csigma"> rule</a>.↩︎</p></li>
<li id="fn4"><p>To compute confidence intervals, we would need to estimate the precision of our measurements, e.g., how closely do self-reported fair offers correspond to participants’ actual beliefs about fair offers? For a detailed example of parameter estimation for a simple physics problem, see <a href="https://doi.org/10.1137/130929230">Aguilar et al.&nbsp;2015</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>science</category>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/index.html</guid>
  <pubDate>Tue, 16 Jan 2018 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-01-16-our-statistics-dont-suck-our-theories-do/F11.large.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Data dredging is the Dionysian soul of science</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2018-01-01-data-dredging-is-the-dionysian-soul-of-science/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2018-01-01-data-dredging-is-the-dionysian-soul-of-science/BlakeGoodAndEvilAngels.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Good and Evil Angels. Plate 4 of <em>The Marriage of Heaven and Hell</em>. From The William Blake Archive: http://www.blakearchive.org</figcaption>
</figure>
</div>
<p>Yin and Yang. Apollo and Dionysus. Heaven and Hell. Id and Superego. Reason and Emotion. Spock and McCoy. Many intellectual and moral frameworks are structured around two, often opposing, elements. If one element gains the upper hand over the other, beware. William Blake, for example, in <em>The Marriage of Heaven and Hell</em>, took aim at the imbalance he saw in Christian theology. God, Heaven, and the Good were the “passive that obeys reason,” our Apollonian side. Satan, Hell and Evil were the “active springing from Energy,” wrongly suppressed by the Church, the Dionysian excess that “leads to the palace of wisdom.”</p>
<p>Data analysis in the social sciences has two forms, one “good” that is highly developed and has many rules that supposedly will lead us to truth, and one “bad” that lives in the shadows, has few if any rules, and is frequently, but wrongly, vilified. This imbalance is crippling the social sciences.</p>
<section id="angelic-confirmation" class="level1">
<h1>Angelic confirmation</h1>
<p>Science often proceeds in roughly three parts: notice a pattern in nature, form a hypothesis about it, and then test the hypothesis by measuring nature. The challenge in testing our hypotheses is that the world is noisy, and it can be very difficult to distinguish the signal — the patterns in our data that are stable from sample to sample — from the noise — the patterns in our data that change randomly from sample to sample.</p>
<p>Statistics, as a discipline, has focused almost exclusively on the challenges of the third part, hypothesis testing, termed confirmatory data analysis (CDA). CDA is (and must be) the epitome of obedience: obedience to reason, to logic, to complex rules and to a meticulous, pre-specified plan that is focused on answering perhaps a single question. It is Apollonian, governed by the “good” angels of Blake’s Heaven.</p>
<p>Although CDA is one of science’s crown jewels, it is not designed to use data to discover new things about the world, i.e., unexpected patterns in our current sample of measurements that are likely to appear in future samples of measurements. CDA can reliably distinguish signals from noise in a sample of data only if the putative signal is specified independently of those data. If, instead, a researcher notices a pattern in her data, and then tries to use CDA on those same data to determine if the pattern is a signal or noise, she will very likely be mislead.</p>
<p>In a largely futile attempt to insure that hypotheses are independent of the data used to test them, statistics articles and textbooks disparage the discovery of new patterns in data by referring to it with derogatory terms such as dredging, fishing, p-hacking, snooping, cherry-picking, HARKing (Hypothesizing After the Results are Known), data torturing, and the sardonic <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1850704">researcher degrees of freedom</a>.</p>
<p>Notice something? The first, and arguably most important step in a scientific investigation is to identify an interesting pattern in nature, yet we are taught that it is wrong use our data to look for those interesting patterns.</p>
<p>That, my friends, is insane.</p>
</section>
<section id="the-devils-exploration" class="level1">
<h1>The Devil’s exploration</h1>
<p>John Tukey, one of the most <a href="http://www.nytimes.com/2000/07/28/us/john-tukey-85-statistician-coined-the-word-software.html">eminent statisticians</a> of the 20th century, recognized that his discipline had put too much emphasis on CDA and too little on exploratory data analysis (EDA), his approving term for data dredging, which he <a href="http://dx.doi.org/10.2307/2682991">defined</a> thus:</p>
<ol type="1">
<li><em>It is an attitude, AND</em></li>
<li><em>A flexibility, AND</em></li>
<li><em>Some graph paper (or transparencies, or both).</em></li>
</ol>
<blockquote class="blockquote">
<p><em>No catalog of techniques can convey a willingness to look for what can be seen, whether or not anticipated. Yet this is at the heart of exploratory data analysis. The graph paper—and tansparencies—are there, not as a technique, but rather as a recognition that the picture-examining eye is the best finder we have of the wholly unanticipated.</em></p>
</blockquote>
<p>Or, as he wrote in his <a href="https://books.google.com/books/about/Exploratory_Data_Analysis.html?id=UT9dAAAAIAAJ">classic text</a> on EDA:</p>
<blockquote class="blockquote">
<p><em>The greatest value of a picture is when it forces us to notice what we never expected to see.</em></p>
</blockquote>
<p>For Tukey, data analysis was a critical tool for discovery, not only confirmation. As he put it, “Finding the question is often more important than finding the answer.” And “The most important maxim for data analysis to heed, and one which many statisticians seem to have shunned, is this: ‘Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.’”<sup>1</sup></p>
<p>I want to draw out what I see as the radical implications of some of Tukey’s mains points for norms in the social sciences.</p>
<p>The world, especially the world of human cognition and behavior, is far more complex than any of us can imagine. To have any hope of understanding it, to discover the right questions, we have no choice but to collect and explore high quality data. Although running small pilot studies is tempting because they take little time and few resources, they can be worse than useless. The precision of our estimates goes as the square root of sample size. EDA on small, noisy data sets will only lead us down blind allies. Alternatively, because we social scientists get credit for confirmation, and exploration is actively discouraged, we disguise our shameful explorations as confirmations, all dressed up with stars of significance. And then those “effects” don’t replicate</p>
<p>The solution is obvious: we must put at least as much effort into exploration and discovery as we put into confirmation, perhaps more. We will need to collect and explore large sets of data using the best measures available. If those measures do not exist, we will need to develop them. It will take time. It will take money.</p>
<p>But let’s face it: discovery is the fun part of science. EDA draws on the energy, instinct, and rebelliousness of Blake’s Devil and Nietzsche’s Dionysus, that heady mix of intuition, inspiration, luck, analysis, and willingness to throw received wisdom out the door that attracted most of us to science in the first place.</p>
</section>
<section id="the-marriage-of-cda-and-eda" class="level1">
<h1>The marriage of CDA and EDA</h1>
<p>Blake, Nietzsche, and perhaps all great artists and thinkers recognize that there must be a marriage of Heaven and Hell, that neither the Dionysian nor the Apollonian should prevail over the other. Tukey understood well that “Neither exploratory nor confirmatory is sufficient alone. To try to replace either by the other is madness. We need them both.”</p>
<p>Madness it may be, but without institutional carrots or sticks, EDA will remain in the shadows, a pervasive yet unacknowledged practice that undermines rather than strengthens science.</p>
<p>One carrot would be an article type <a href="http://www.sciencedirect.com/science/article/pii/S0010945217302393?via%3Dihub">devoted to exploratory research</a>. It might be worthwhile, though, to wield a stick.</p>
<p>Tukey argues that “to implement the very confirmatory paradigm properly, we need to do a lot of exploratory work.” The reason is, there is “no real alternative, in most truly confirmatory studies, to having a single main question—in which a question is specified by ALL of design, collection, monitoring, AND ANALYSIS” (caps in the original).</p>
<!--As Tukey admonished, "Preplan THE main analysis (having even two main analyses may be too many)!"-->
<p>Answering just one question with statistical test requires decisions about, e.g., the sample population, sample size (which is based on estimated effect sizes and power), which control variables to include, choice of instruments to measure the variables, which model to fit and/or test to perform, whether and how to transform certain variables (e.g., log or square root transform), and whether to include interactions and which ones. To believe the standard textbooks, we can do all that with a single sample of data while at the same time avoiding the temptation to use any of these researcher degrees of freedom to p-hack.</p>
<p>Hah!</p>
<p>If the replication crisis has taught us anything, it is that our statistical tests are surprisingly fragile: small modifications to our procedures can have a large influence on our results. It must therefore become a basic norm in much of science that a confirmatory study – especially one reporting p-values – must preregister “ALL of design, collection, monitoring, AND ANALYSIS.” Everything. In detail.</p>
<p>A good confirmatory study, then, is completely specified. Running it should be like turning a crank. As Tukey said (caps in original):</p>
<blockquote class="blockquote">
<p><em>Whatever those who have tried to teach it may feel, confirmatory data analysis, especially as sanctification, is a routine relatively easy to teach and, hence,</em></p>
</blockquote>
<blockquote class="blockquote">
<p><em>A ROUTINE EASY TO COMPUTERIZE.</em></p>
</blockquote>
<p>The standard I’m personally aiming for (but have not quite yet achieved) is to preregister our R code.</p>
<p>It will be impossible to achieve this ideal without EDA — without first looking at data to evaluate and optimize all the decisions necessary to run a high quality confirmatory study. The stick I envision is that every confirmatory study would be required to have, at a minimum, <em>two</em> samples and <em>two</em> analyses. The first sample would be for EDA, the second for CDA. Every paper reporting results of a confirmatory study must also report the preceding EDA that justified each study design decision. Because the EDA would include estimates of effect sizes, each paper would contain an attempted replication of it’s main result(s).</p>
<p>In some cases, it will be possible to divide a single sample in two, and first perform EDA on one portion, and then CDA on the other. In other cases, it will be possible to use existing data for the EDA, and new data for the CDA. In many other cases, however, researchers will simply have to collect two (or more) samples. Requiring that every paper include an EDA on one sample and a subsequent CDA on a separate sample could cut researchers’ publication productivity in half. It could easily more than double their <em>scientific</em> productivity, however, their publication of results that will replicate.</p>
</section>
<section id="notes" class="level1">
<h1>Notes</h1>
<!--CDA techniques depend on mathematical models of pure noise (e.g., binomial, normal, and Poisson distributions), which specify the probability of making a particular measurement (or a measurement within a certain range) in a system where variation is due entirely to a random process (noise). -->
<!--

Hopefully, you will discover something important in your data that you never expected to see.
* *Finding the question is often more important than finding the answer.*

* *I assert, and I count upon most of you to agree after reflection, that to implement the very confirmatory paradigm properly, we need to do a lot of exploratory work. *

* *Neither exploratory nor confirmatory is sufficient alone. To try to replace either by the other is madness. We need them both.*

* *I see no real alternative, in most truly confirmatory studies, to having a single main question---in which a question is specified by ALL of design, collection, monitoring, AND ANALYSIS.*

* *The only way humans can do BETTER than computers is to take a chance of doing WORSE.*
-->

<!--
https://christophm.github.io/interpretable-ml-book/

http://andrewgelman.com/2013/03/12/misunderstanding-the-p-value/
-->
<!--
EDA relies heavily on graphical techniques to discover structure in data. 

Stated another way, whereas CDA minimizes type I and type II errors, EDA aims to minimize so-called type III errors: precisely solving the wrong problem, when you should have been working on the right problem.
-->
<!--

Tall parents seem to have tall children, for instance, and short parents seem to have short children. We might hypothesize that, on average, childrens' heights increase linearly with each unit change in parents' heights. We could test this hypothesis by measuring the heights of a sample of adults and their parents.


Parents heights are clearly not the only determinants of children's heights, for example, as some tall parents have short children and some short parents have tall children. If, in our sample, we find that, on average, taller parents have taller children, this could either be due to the fact that this is a genuine fact about the world (signal), or it could be that, by accident, we happened to sample tall parents with tall children and short parents with short children (noise). If the latter, our next sample is unlikely to exhibit the same pattern.

We can't test this hypothesis by measuring all adults on the planet -- we don't have the time or money -- but we could test it by measuring the heights of a sample of adults and their parents. If we do, we will discover a couple of things. First, childrens' heights do seem to increase linearly with parents' heights, but even so, many children are taller than one would predict based on their parents' heights, and many are shorter. That is, according to our hypothesis, the height of any given child will be the sum of the height predicted

there is a systematic part of the model (intercept and slope) that we expect to be similar from sample to sample, and a stochastic part that we

that each new sample provides somewhat different estimate of the slope. -->
<!--The different models of noise share the feature that measurements that only deviate a small amount from some central value are common (have high probability), whereas measurements that deviate a large amount from the central value are rare (have small probability). -->
<!--A key step in CDA is to compute the probability of making the measurements in hand (the data) under one or more hypotheses of interest. If the measurements (or summary of the measurements) are close to the value(s) predicted by a hypothesis, the computed probability of making those measurements under that hypothesis will be high, and if they are far, the probability will be low. Depending on your statistical philosophy and type of test, a high or low probability of your data under a hypothesis might lead you to put more or less weight on that hypothesis, sometimes relative to alternative hypotheses.-->
<!--To briefly illustrate, if one predicts that a particular pair of dice will come up two 3's, and then one immediately rolls two 3's, that is fairly strong evidence that the dice are biased toward 3's because the probability of that happening if the dice were fair is low (1/36). If, however, one first rolls two 3's, and then tries to claim the dice must be biased because we can reject the null of fair dice (p = 1/36), one has made exactly this error: the probability of rolling two 3's under a hypothesis of fair dice was computed using the same data that motivated us to compute the probability of two 3's in the first place (as opposed to two 4's or two 5's or two 6's, or two odd numbers, or whatever).-->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Tukey was not the first to recognize the importance of exploring data, nor to clearly distinguish exploration from confirmation. De Groot <a href="https://pdfs.semanticscholar.org/77e4/c0aea8c39b13d4a7b8532f92964a75eb31cc.pdf">made these points in 1956</a>, for example, and even then he noted they were not new. Statistician Andrew Gelman recently <a href="http://andrewgelman.com/2016/11/17/thinking-more-seriously-about-the-design-of-exploratory-studies/">raised the issue on his blog</a>. Unlike others, however, Tukey devoted a chunk of his career to developing and promoting EDA. Much of his writing on the topic has an aphoristic flavor, which reminded me of Blake’s <a href="http://www.gutenberg.org/files/45315/45315.txt"><em>Proverbs of Hell</em></a>. I recommend you read <a href="http://dx.doi.org/10.2307/2682991">Tukey (1980)</a>; it’s short, with no math.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>science</category>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2018-01-01-data-dredging-is-the-dionysian-soul-of-science/index.html</guid>
  <pubDate>Mon, 01 Jan 2018 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2018-01-01-data-dredging-is-the-dionysian-soul-of-science/BlakeGoodAndEvilAngels.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Academic success is either a crapshoot or a scam</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2017-12-05-academic-success-is-either-a-crapshoot-or-a-scam/index.html</link>
  <description><![CDATA[ 




<p><em>Nature</em> just <a href="http://dx.doi.org/10.1038/d41586-017-07522-z">published</a> five brief commentaries by statisticians on the reproducibility crisis:</p>
<blockquote class="blockquote">
<p>As debate rumbles on about how and how much poor statistics is to blame for poor reproducibility, <em>Nature</em> asked influential statisticians to recommend one change to improve science. The common theme? The problem is not our maths, but ourselves.</p>
</blockquote>
<p>The problem <em>is</em> ourselves, but it has little to do with: a failure to adjust for human cognition (Leek), relying on statistical “significance” (McShane and Gelman), failure to appreciate false positive risk (Colquhoun), or not sharing analysis and results (Nuijten) (although addressing all these things would be good). Goodman, who fingers academic norms, comes closest, but doesn’t identify the real culprit.</p>
<p>The problem, in a nut shell, is that empirical researchers have placed the fates of their careers in the hands of nature instead of themselves.</p>
<p>Let me explain.</p>
<p>Academic success for empirical researchers is largely determined by a count of one’s publications, and the prestige of the journals in which those publications appear (and the grants that flow from these). Prestigious journals, in turn, typically only publish papers that they deem to be reporting important new facts about the world.</p>
<p>In my field of anthropology, the minimum acceptable number of pubs per year for a researcher with aspirations for tenure and promotion is about three. This means that, each year, I must discover three important new things about the world.</p>
<p>Is that realistic?</p>
<p>Research outcomes are stochastic – if we knew with 100% certainty what the outcome would be, why research it? The whole point of research is learn something new. When researchers begin a study they have some level of uncertainty – perhaps great, perhaps small – about the outcome. We all hope for a sexy outcome, but we all know that we might not get it.</p>
<p>Let’s say I choose to run 3 studies that each has a 50% chance of getting a sexy result. If I run 3 great studies, mother nature will reward me with 3 sexy results only 12.5% of the time. I would have to run 9 studies to have about a 90% chance that at least 3 would be sexy enough to publish in a prestigious journal.</p>
<p>I do not have the time or money to run 9 new studies every year.</p>
<p>I could instead choose to investigate phenomena that are more likely to yield strong positive results. If I choose to investigate phenomena that are 75% likely to yield such results, for instance, I would only have to run about 5 studies (still too many) for mother nature to usually grace me with at least 3 positive results. But then I run the risk that these results will seem obvious, and not sexy enough to publish in prestigious journals.</p>
<p>To put things in deliberately provocative terms, empirical social scientists with lots of pubs in prestigious journals are either very lucky, or they are p-hacking.</p>
<p>I don’t really blame the p-hackers. By tying academic success to high-profile publications, which, in turn, require sexy results, we academic researchers have put our fates in the hands of a fickle mother nature. Academic success is therefore either a crapshoot or, since few of us are willing to subject the success or failure of our careers to the roll of the dice, a scam.</p>
<p>The solution is straightforward: Although we have almost no control over the sexiness of our outcomes, we have almost full control over the quality of our studies. We can come up with clever designs that discriminate among popular hypotheses. We can invent new measures of important phenomena, and confirm their validity, reliability and precision. We can run high powered studies with representative samples of key populations. We can use experimental designs. We can pre-register our hypotheses and statistical tests. In short, we need to change the system so academic researchers are rewarded for running high quality studies with these sorts of attributes, <em>regardless</em> of outcome.</p>
<p>Changing the incentives to reward high quality studies rather than sexy results would have enormously positive effects for science. Researchers will be able to respond to these incentives in ways that improve science while also advancing their careers. Under the current outcome-based incentives, in contrast, researchers often have little choice but to screw science to advance their careers.</p>
<p>Changing the incentive system won’t be easy. No longer will we be able to easily assess our colleagues based on their number of pubs, weighted by journal impact factors. Instead, we will have to assess them based on the quality of their studies: the importance of the question addressed, the sampling strategy and sample size, the measurements and their ability to discriminate among hypotheses, and the data analysis. All these will have to be recorded in detail, even if there were no sexy results.</p>
<p>Changing the incentive system might not only help solve the replication crisis, it might also help solve the <a href="https://en.wikipedia.org/wiki/Serials_crisis">serials crisis</a> – the recent dramatic increase in the cost of subscribing to scientific journals.</p>
<p>Scientific publishing is an oligopoly. In the social sciences, 5 publishers – Elsevier, Taylor &amp; Francis, Wiley-Blackwell, Springer, and Sage Publications – publish about 70% of all papers:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2017-12-05-academic-success-is-either-a-crapshoot-or-a-scam/journal.pone.0127502.g004.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Percent of journal articles in different disciplines that are published in the big 5. Figure from https://doi.org/10.1371/journal.pone.0127502</figcaption>
</figure>
</div>
<p>These publishers are exploiting their monopolies on journals and journal papers to charge high fees, which are mainly paid by university libraries. Reed-Elsevier’s profit margins, for example, <a href="https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science">exceed those of Apple, Google, or Amazon</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2017-12-05-academic-success-is-either-a-crapshoot-or-a-scam/journal.pone.0127502.g007.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Reed-Elsevier profits. Left: entire business. Right: scientific, technical and medical division. Figure from: https://doi.org/10.1371/journal.pone.0127502.</figcaption>
</figure>
</div>
<p>Student tuition, grant, and endowment dollars are being funneled to highly profitable corporations that add only questionable value to the science they publish.</p>
<p><em>Nature</em>, a big money maker for Springer (one of the scientific publishing oligopolists), tapped 5 statisticians for comment because it is worried about the replication crisis, and with good reason. <em>Nature</em>, as we all know, is the king of kingmakers in science because it only publishes the sexiest of sexy results. Social scientists, myself included, crave a publication in <em>Nature</em>, which can make one’s scientific career. But if those results are often hacked and cannot be replicated, <em>Nature’s</em> status will plummet, and along with the profits it generates for Springer. Yet <em>Nature</em> and the statisticians seem completely oblivious to the irony that it is the prestige of publishing sexy results in high profile journals like <em>Nature</em> that is the central cause of the replication crisis.</p>
<p>Ultimately, though, we academic researchers are responsible for both the replication and serials crises because we created (or bought into) a system that rewards sexy results over quality measurements of the world.</p>



 ]]></description>
  <category>science</category>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2017-12-05-academic-success-is-either-a-crapshoot-or-a-scam/index.html</guid>
  <pubDate>Tue, 05 Dec 2017 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2017-12-05-academic-success-is-either-a-crapshoot-or-a-scam/journal.pone.0127502.g004.PNG" medium="image"/>
</item>
<item>
  <title>PCA: new coordinate system, same data</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index.html</link>
  <description><![CDATA[ 




<p>There are many ways to teach Principal Component Analysis (PCA). This way is mine.</p>
<p>The first constellation I learned to recognize was the <a href="https://en.wikipedia.org/wiki/Big_Dipper">Big Dipper</a>. In the evening it’s in one part of the sky, and in the early morning, another, but it’s still the Big Dipper. Same thing if I look at it while I slowly spin around. To be more specific, in each of the 3 figures below, the stars have different <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> coordinates, yet it is easy to recognize them as the same stars:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/ConstellationBigDipper.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Big Dipper</figcaption>
</figure>
</div>
<p>The point is: we recognize the Big Dipper, not by the specific location of the stars in the sky, but by the location of each star <em>relative to the others</em>.</p>
<p>The first and most important step in understanding PCA is to think about your data in the same way that you think about constellations: it’s the relationships between your data points, not their individual values, that matters.</p>
<p>In a scientific study, we typically measure multiple values on each person (or population, or whatever), e.g., age, height, weight, sex, and so forth. The mental frame shift to make is to think about the collection of multiple values on a single person as a <em>single</em> data point — a single “star” in the sky — and all the data points as a constellation of stars in the sky. If we had two measurements per person – e.g., height and weight – then each person (each data point) has two coordinates; if we had three measurements per person – e.g., height, weight, and age – then each person (each data point) has three coordinates, and so forth.</p>
<p>In general, you can think about each “unit” in the data – person or observation or “row” – as one point in an <img src="https://latex.codecogs.com/png.latex?N">-dimensional Euclidean space, where <img src="https://latex.codecogs.com/png.latex?N"> is the number of variables that you have measured. Viewed this way, the data has a “structure” determined by the relationships of each observations to the others that will be preserved even if the coordinate system is changed.</p>
<p>Here is a concrete example with 2 variables per person – <em>height</em> and <em>weight</em> – and thus a 2-dimensional space of points:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Height and weight of !Kung individuals.</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The !Kung are an ethnic group in</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># southwest Africa.</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># From Howell via McElreath:</span></span>
<span id="cb1-5">d <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> readr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_delim</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">delim =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">';'</span>)</span>
<span id="cb1-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(d, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(height, weight)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb1-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb1-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">limits =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">limits =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"!Kung heights and weights"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Each black dot represents one person.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The red dot indicates the origin of the coordinate system."</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Most students would (correctly) interpret this plot as depicting the relationship between height and weight.</p>
<p>There is another way.</p>
<p>Although each star in the Big Dipper is also described by two variables – an <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> coordinate (or an <a href="http://www.skyandtelescope.com/astronomy-resources/what-are-celestial-coordinates/">ascension and declination</a>) – both variables are in the <em>same units</em> (angles). This is an important reason why we can think about the Big Dipper in space without thinking about the <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> values of each star.</p>
<p>The first step on our journey is therefore to put our height and weight variables into the same units by <a href="https://en.wikipedia.org/wiki/Standard_score">standardizing them</a> (subtract the mean from each variable, and then divide it by its standard deviation):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardize each variable</span></span>
<span id="cb2-2">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>height)[,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-3">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>weight)[,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot</span></span>
<span id="cb2-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(d, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(zheight, zweight)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb2-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xlim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ylim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Standardized !Kung heights and weights"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Each black dot represents one person.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The red dot indicates the origin of the coordinate system."</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Many folks would (correctly) interpret these new variables as transformed versions of the original data. However, I would like you to instead see this as a transformation of the <em>coordinate system</em>: we have translated the origin of the coordinate system to the middle of the data (the red dot), and we have put the <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> axes on the same scale (1 unit of x equals 1 unit of y). The data remain the same.</p>
<p>The translation of the origin to the center of the data is useful because positive values on the <img src="https://latex.codecogs.com/png.latex?x">-axis now indicate values that are greater than the mean, and negative values now indicate values that are less than the mean. The same goes for the <img src="https://latex.codecogs.com/png.latex?y">-axis. The translation of the origin makes it easy to identify individuals whose heights and weights are above or below average. Transforming the coordinate system (not the data!) can help us interpret the data – the new origin has advantages over the original origin.</p>
<p>Putting the <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> axes on the same scale is useful because we can now more easily think about this 2d space as a uniform <em>height-weight</em> space, or <em>height-weight</em> continuum, independent of individual <img src="https://latex.codecogs.com/png.latex?height"> and <img src="https://latex.codecogs.com/png.latex?weight"> values.</p>
<p>We are ready for another transformation of the coordinate system: a rotation around the origin:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">angle <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># angle of rotation in radians</span></span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># New x and y coordinates after rotation</span></span>
<span id="cb3-4">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle)</span>
<span id="cb3-5">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>y <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(d, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(x, y)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb3-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xlim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ylim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Rotated !Kung heights and weights"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Each black dot represents one person.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The red dot indicates the origin of the coordinate system."</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Here are the pairs of coordinates of our first 6 data points in each of our 3 different coordinate systems (the original, standardized, and rotated coordinate system):</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">height</th>
<th style="text-align: right;">weight</th>
<th style="text-align: right;">zheight</th>
<th style="text-align: right;">zweight</th>
<th style="text-align: right;">x</th>
<th style="text-align: right;">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">151.76</td>
<td style="text-align: right;">47.83</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">0.83</td>
<td style="text-align: right;">0.86</td>
<td style="text-align: right;">-0.43</td>
</tr>
<tr class="even">
<td style="text-align: right;">139.70</td>
<td style="text-align: right;">36.49</td>
<td style="text-align: right;">0.05</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">-0.05</td>
</tr>
<tr class="odd">
<td style="text-align: right;">136.52</td>
<td style="text-align: right;">31.86</td>
<td style="text-align: right;">-0.06</td>
<td style="text-align: right;">-0.25</td>
<td style="text-align: right;">-0.26</td>
<td style="text-align: right;">0.04</td>
</tr>
<tr class="even">
<td style="text-align: right;">156.84</td>
<td style="text-align: right;">53.04</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1.18</td>
<td style="text-align: right;">1.23</td>
<td style="text-align: right;">-0.59</td>
</tr>
<tr class="odd">
<td style="text-align: right;">145.42</td>
<td style="text-align: right;">41.28</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">-0.23</td>
</tr>
<tr class="even">
<td style="text-align: right;">163.83</td>
<td style="text-align: right;">62.99</td>
<td style="text-align: right;">0.93</td>
<td style="text-align: right;">1.86</td>
<td style="text-align: right;">1.92</td>
<td style="text-align: right;">-0.79</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Although the pairs of coordinates are radically different, we easily recognize the same constellation of data in the plots, regardless of coordinate system.</p>
<p>We have seen how translating the origin of the coordinate system to the center of the data helps us interpret the data. But how could rotating the coordinate system be helpful?</p>
<p>In most studies, we measure stuff because we know that the things we’re studying – people in this case – vary, and it is exactly this variation that we want to understand. What if we rotated the coordinate system so that the variance of the data was maximized along the <img src="https://latex.codecogs.com/png.latex?x">-axis? Then, in this rotated coordinate system, folks with large positive values on the <img src="https://latex.codecogs.com/png.latex?x">-axis would be maximally “different” from folks with large negative values on the <img src="https://latex.codecogs.com/png.latex?x">-axis in “<em>height-weight</em>” space. Differences in <img src="https://latex.codecogs.com/png.latex?y">-values would then be less important in distinguishing individuals.</p>
<p>We can find the rotation that maximizes variance along the <img src="https://latex.codecogs.com/png.latex?x">-axis by trial and error: simply choose different angles, compute the rotation, and then compute the variance or standard deviation along the <img src="https://latex.codecogs.com/png.latex?x">-axis. Rinse and repeat unit you find an angle that maximizes the standard deviation. There will be two such angles, each <img src="https://latex.codecogs.com/png.latex?%5Cpi"> radians (180 degrees) apart:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run this code over and over with</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># different values for the angle</span></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># until sd(d$x) is at a maximum.</span></span>
<span id="cb4-4">angle <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.78</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This angle comes close; -0.78 + pi would also come close</span></span>
<span id="cb4-5">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle)</span>
<span id="cb4-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># We could also use var(d$x)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.393114</code></pre>
</div>
</div>
<p>A second way would be to use R’s <code>optim</code> function, which automates the above process:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This function rotates and then</span></span>
<span id="cb6-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># computes sd along x.</span></span>
<span id="cb6-3"></span>
<span id="cb6-4">sd_x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(angle) {</span>
<span id="cb6-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle))</span>
<span id="cb6-6">}</span>
<span id="cb6-7"></span>
<span id="cb6-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This function finds the angle that </span></span>
<span id="cb6-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># maximizes the above function</span></span>
<span id="cb6-10">opt <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb6-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">optim</span>(</span>
<span id="cb6-12">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Starting value of angle</span></span>
<span id="cb6-13">    sd_x, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The function to minimize</span></span>
<span id="cb6-14">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Brent"</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The optim procedure that works best in 1-D</span></span>
<span id="cb6-15">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lower =</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>pi,</span>
<span id="cb6-16">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">upper =</span> pi,</span>
<span id="cb6-17">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">control =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fnscale =</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Maximize instead of minimize</span></span>
<span id="cb6-18">    )</span></code></pre></div>
</div>
<p>An angle of rotation (in radians) that maximizes sd along x:</p>
<p><code>opt$par</code> = -0.7853982</p>
<p>The maximized standard deviation:</p>
<p><code>opt$value</code> = 1.393134</p>
<p>Let’s plot our data using that optimal angle of rotation:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># one optimal angle in radians;</span></span>
<span id="cb7-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the other would be opt$par + pi</span></span>
<span id="cb7-3">angle <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> opt<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>par </span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># New x and y coordinates after rotation</span></span>
<span id="cb7-6">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle)</span>
<span id="cb7-7">d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>y <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(angle) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>zweight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(angle)</span>
<span id="cb7-8"></span>
<span id="cb7-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(d, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(x, y)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb7-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xlim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ylim =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"!Kung heights and weights rotated to maximize variance along x-axis"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Each black dot represents one person.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The red dot indicates the origin of the coordinate system."</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Guess what? The <img src="https://latex.codecogs.com/png.latex?x">-axis is principal component 1 (PC1), and the <img src="https://latex.codecogs.com/png.latex?y">-axis is principle component 2 (PC2), as we can confirm by comparing our results to those from R’s <code>prcomp</code> (principal component) function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute PCA using the standard R function</span></span>
<span id="cb8-2">m <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prcomp</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> zheight <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> zweight, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> d)</span>
<span id="cb8-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(m)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Importance of components:
                          PC1     PC2
Standard deviation     1.3931 0.24326
Proportion of Variance 0.9704 0.02959
Cumulative Proportion  0.9704 1.00000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compare the standard deviations above with:</span></span>
<span id="cb10-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.393134</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>y)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2432649</code></pre>
</div>
</div>
<p>Compare our x &amp; y values…</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
<th style="text-align: right;">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.9326787</td>
<td style="text-align: right;">0.2409332</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.0788411</td>
<td style="text-align: right;">0.0052468</td>
</tr>
<tr class="odd">
<td style="text-align: right;">-0.2244852</td>
<td style="text-align: right;">-0.1354080</td>
</tr>
<tr class="even">
<td style="text-align: right;">1.3134063</td>
<td style="text-align: right;">0.3613867</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.4554072</td>
<td style="text-align: right;">0.0890045</td>
</tr>
<tr class="even">
<td style="text-align: right;">1.9703735</td>
<td style="text-align: right;">0.6604768</td>
</tr>
</tbody>
</table>
<p>… with those from <code>prcomp</code></p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: right;">PC1</th>
<th style="text-align: right;">PC2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-0.9326787</td>
<td style="text-align: right;">-0.2409332</td>
</tr>
<tr class="even">
<td style="text-align: right;">-0.0788411</td>
<td style="text-align: right;">-0.0052468</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.2244852</td>
<td style="text-align: right;">0.1354080</td>
</tr>
<tr class="even">
<td style="text-align: right;">-1.3134063</td>
<td style="text-align: right;">-0.3613867</td>
</tr>
<tr class="odd">
<td style="text-align: right;">-0.4554072</td>
<td style="text-align: right;">-0.0890045</td>
</tr>
<tr class="even">
<td style="text-align: right;">-1.9703735</td>
<td style="text-align: right;">-0.6604768</td>
</tr>
</tbody>
</table>
<p>The minus signs are reversed because the axes are rotated 180 degrees, but the variance is still maximized along the x-axis (remember, there are 2 rotations that will maximize the variance).</p>
<p>In summary, principal components are simply a new orthogonal (perpendicular) coordinate system for your data, rotated so the variance of your data is maximized along the first axis (PC1); then, rotating around the first axis, the remaining variance is maximized along the second axis (PC2), which is perpendicular to the first; and so forth, until the directions of all axes are specified. Thus, there will be as many principal components as there are dimensions in your data (i.e., number of variables), and the variance will decrease across each successive component across each successive component.</p>
<p>There are many uses of this new coordinate system. In our example, 97% of the variance in our data falls along PC1. Thus, we might interpret PC1, which is a combination of height and weight, as something like <em>size</em>. By rotating our coordinate system, we have identified underlying “structure” in our data. For 2-d data like our example, PCA is not that useful. But when our data have many dimensions, PCA and related techniques can find structure that would be difficult or impossible to find without them.</p>
<hr>
<p><em>Note #1: The <code>prcomp</code> and other PCA functions do not find these rotations in the same way we did. Instead, they use methods like singular value decomposition, which you can read about on <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">wikipedia</a>.</em></p>
<p><em>Note #2: You might have heard of rotation after PCA, or terms like varimax rotation. These also seek useful rotations, but are distinct from PCA. You can read more about them, and their relationship to PCA <a href="https://stats.stackexchange.com/questions/612/is-pca-followed-by-a-rotation-such-as-varimax-still-pca">here</a>, <a href="https://stats.stackexchange.com/questions/151653/what-is-the-intuitive-reason-behind-doing-rotations-in-factor-analysis-pca-how">here</a>, and <a href="https://stats.stackexchange.com/questions/160422/what-are-rotated-and-unrotated-principal-components-given-that-pca-always-r">here</a>.</em></p>
<p><em>Note #3: There is a great set of alternative explanations of PCA <a href="https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues">here</a> .</em></p>



 ]]></description>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/index.html</guid>
  <pubDate>Wed, 15 Nov 2017 08:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2017-11-15-pca-new-coordinate-system-same-data/ConstellationBigDipper.png" medium="image" type="image/png" height="61" width="144"/>
</item>
<item>
  <title>Put your data in an R package</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2017-10-18-put-your-data-in-an-r-package/index.html</link>
  <description><![CDATA[ 




<p>I used to write long R scripts that imported data files, created new variables, reshaped the data, reshaped it again, and spit out results along the way, all in one file.</p>
<p>That worked so long as I never wanted to use that data again. But what if I did? Should I just tack on more code for the new analysis, and then even more code for yet more analyses? That approach will litter your environment with objects that are irrelevant for, and might even interfere with, a particular analysis. Should I copy all the files into a new directory and then hack away at the code? Now I have two copies of the data – which one is definitive? Should I just treat the original data files as the data? Now I have to repeat the same initial processing steps every time I want to reuse that data.</p>
<section id="the-solution" class="level2">
<h2 class="anchored" data-anchor-id="the-solution">The solution</h2>
<p>For each new data set I create a new R data package. This package lives in my library along with <code>ggplot2</code>, <code>dplyr</code>, <code>lme4</code>, and all my other packages, and is accessible in any project or analysis with a simple:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(mydatapackage)</span></code></pre></div>
</div>
<p>Creating a data package involves some small costs, but these are far outweighed by the benefits.</p>
</section>
<section id="pros" class="level2">
<h2 class="anchored" data-anchor-id="pros">Pros</h2>
<ul>
<li>Your data is cleanly separated from your analyses.</li>
<li>Your data is easily accessible in any future project.</li>
<li>Packages have a built-in documentation system so you can easily document all your variables. The documentation for each data frame (or other object) is accessible with <code>?my_df</code>.</li>
<li>Packages have a versioning system so you can keep track of new versions of your data package.</li>
<li>Share your data with students and colleagues simply by sharing the package.</li>
<li>Archive your data in a public repository simply by uploading the package.</li>
</ul>
</section>
<section id="cons" class="level2">
<h2 class="anchored" data-anchor-id="cons">Cons</h2>
<ul>
<li>Creating a package is a few extra steps.</li>
<li>Every change to the data package requires a rebuild step before the changes are available in your analyses.</li>
<li>If you forget to rebuild, your analyses will be using the outdated version of your data, something that can be hard to detect.</li>
<li>In the early phases of an analysis, you will probably be moving code back and forth from your data package to your analysis until you find the sweet spot between processed data and analyzed data.</li>
</ul>
</section>
<section id="how-to-create-a-data-package" class="level1">
<h1>How to create a data package</h1>
<p>I assume you are using RStudio. Although RStudio can create packages using the GUI, I have gotten obscure errors using that feature. Therefore, do <em>not</em> create a new RStudio project using the GUI. Instead, run this code from the console:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run these from the R console</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check that the `usethis` package is installed. If not:</span></span>
<span id="cb2-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"usethis"</span>)</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create new package. Directory must not exist. </span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This also creates a new RStudio project.</span></span>
<span id="cb2-8">usethis<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">create_package</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path/to/my/data/package/"</span>)</span></code></pre></div>
</div>
<p>Open your new data package using “Open project…” in RStudio. Then run this code from the console:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run this code after opening the new package in RStudio</span></span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up the data-raw directory and data processing script</span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># You can use any name you want for your data</span></span>
<span id="cb3-5">usethis<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">use_data_raw</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mydataset'</span>)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This script in the R directory will contain the documentation.</span></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># You can use any name you want.</span></span>
<span id="cb3-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.create</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R/data.R"</span>)</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize git repository (optional)</span></span>
<span id="cb3-12">usethis<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">use_git</span>()</span></code></pre></div>
</div>
<p>Put your data files into the <code>data-raw</code> folder. Your new package directory should look something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2017-10-18-put-your-data-in-an-r-package/datapackage_screenshot.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Package layout</figcaption>
</figure>
</div>
<p>Write your data processing code in a <code>data-raw/mydataset.R</code> script. It would look something like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data-raw/mydataset.R</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data import and processing pipeline</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(readr)</span>
<span id="cb4-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(readxl)</span>
<span id="cb4-6"></span>
<span id="cb4-7">mydataset <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_csv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data-raw/pendulum data.csv"</span>)</span>
<span id="cb4-8">demographics <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_excel</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data-raw/Demographics.xlsx"</span>)</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data cleaning code here...</span></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (Do NOT put data analysis code here!)</span></span>
<span id="cb4-12"></span>
<span id="cb4-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This should be the last line.</span></span>
<span id="cb4-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Note that names are unquoted.</span></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># I like using overwrite = T so everytime I run the script the </span></span>
<span id="cb4-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># updated objects are saved, but the default is overwrite = F</span></span>
<span id="cb4-17">usethis<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">use_data</span>(mydataset, demographics, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">overwrite =</span> T)</span></code></pre></div>
</div>
<p>That last line writes your R data frames and other data objects to files in the <code>data</code> directory (not the <code>data-raw</code> directory!). The <code>data</code> directory will be created if it does not exist.</p>
<p>Edit your <code>DESCRIPTION</code> file as specified in Hadley Wickham’s book on R packages: http://r-pkgs.had.co.nz/description.html.</p>
<p>You won’t need <code>Imports</code> or <code>Suggests</code>.</p>
<p>At this point you should confirm that you can build and install your package. You should see a <strong>Build</strong> tab in RStudio. Open it and click <strong>Build and Install</strong> (older RStudio versions) or <strong>Install and Restart</strong> (newer RStudio versions), which will build the package and install it in your package library. You should see your package in the <strong>Packages</strong> tab, and you should have access to the data frame objects in any script where you include: <code>library(mydatapackage)</code>.</p>
</section>
<section id="document-your-data" class="level1">
<h1>Document your data</h1>
<p>One of the biggest advantages of creating a data package is that it provides a very convenient system for documenting your data, and for accessing that documentation. Although they are not required, I recommend first installing this utility package:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sinew"</span>)</span></code></pre></div>
</div>
<p>Open your currently blank <code>R/data.R</code> file, which is where you will add the documentation using <a href="https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html">roxygen</a>.</p>
<p>Then use the <code>makeOxygen</code> function from the <code>sinew</code> package to create skeleton documentation, e.g., for the <code>mydataset</code> data frame:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">sinew<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">makeOxygen</span>(mydataset, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">add_fields =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"source"</span>)</span></code></pre></div>
</div>
<p>This will print out a skeleton that you copy and paste into your currently empty <code>R/data.R</code> file:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This goes in R/data.R</span></span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @title DATASET_TITLE</span></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @description DATASET_DESCRIPTION</span></span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @format A data frame with 1559 rows and 5 variables:</span></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' \describe{</span></span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'   \item{\code{Time (s)}}{double COLUMN_DESCRIPTION}</span></span>
<span id="cb7-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'   \item{\code{Acceleration - x (m/s²)}}{double COLUMN_DESCRIPTION}</span></span>
<span id="cb7-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'   \item{\code{Acceleration - y (m/s²)}}{double COLUMN_DESCRIPTION}</span></span>
<span id="cb7-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'   \item{\code{Acceleration - z (m/s²)}}{double COLUMN_DESCRIPTION}</span></span>
<span id="cb7-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'   \item{\code{Acceleration - resultant (m/s²)}}{double COLUMN_DESCRIPTION} </span></span>
<span id="cb7-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'}</span></span>
<span id="cb7-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @source \url{http://somewhere.important.com/}</span></span>
<span id="cb7-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mydataset"</span></span></code></pre></div>
</div>
<p>Do that for each data frame in your package, adding each skeleton to <code>R/data.R</code>. Edit the parts in ALL_CAPS. <code>sinew</code> also provides RStudio addins, available in the <code>Addins</code> menu. Read their documentation to learn how to use them.</p>
<p>For a bit more detail on documenting data packages, see http://r-pkgs.had.co.nz/data.html.</p>
</section>
<section id="building-your-data-package" class="level1">
<h1>Building your data package</h1>
<p>The final step in creating a data package is to build the package along with the new documentation.</p>
<p>In the <strong>Build</strong> tab, first select <code>Document</code> from the <code>More</code> menu – this will generate the documentation from from the roxygen markup you created above. Then click <code>Install and Restart</code> (or <code>Build and Reload</code>). You should now be able to access the help page for each data frame in the standard way:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">?mydataset</span></code></pre></div>
</div>
<p>You’re done! Just remember, when you change something, update the version number in the <code>DESCRIPTION</code> file and rebuild your package.</p>


</section>

 ]]></description>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2017-10-18-put-your-data-in-an-r-package/index.html</guid>
  <pubDate>Wed, 18 Oct 2017 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2017-10-18-put-your-data-in-an-r-package/datapackage_screenshot.png" medium="image" type="image/png" height="71" width="144"/>
</item>
<item>
  <title>Monkey butts, menstrual cycles, sex, and the color pink. The statistical crisis in science</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2015-06-27-monkey-butts-menstrual-cycles-sex-and-the-color-pink-the-statistical-crisis-in-science/index.html</link>
  <description><![CDATA[ 




<p>A couple of years ago, when I was starting a new project that used cross-national data, I picked up a <a href="http://www.stat.columbia.edu/~gelman/arm/">popular statistics textbook</a> by Andrew Gelman and Jennifer Hill because Gelman is known for his analysis of voting patterns across US states, which is conceptually similar to analysis of data across countries. I decided to google Gelman, a prominent statistics professor at Columbia, to see if he had papers on his website that would provide detailed, published examples of these kinds of analyses (’bout ready to head back to Facebook?).</p>
<p>It turned out Gelman is a prolific blogger. At the time, in <a href="http://www.slate.com/articles/health_and_science/science/2013/07/statistics_and_psychology_multiple_comparisons_give_spurious_results.html">Slate</a> and on his <a href="http://andrewgelman.com/2013/07/31/response-by-jessica-tracy-and-alec-beall-to-my-criticism-of-their-paper/">blog</a>, Gelman was accusing authors of four papers of shoddy stats. One paper was the <a href="https://dx.doi.org/10.1037%2Fa0021524">infamous paper on ESP</a> by <a href="https://en.wikipedia.org/wiki/Daryl_Bem">Daryl Bem</a> that had already been <a href="https://dx.doi.org/10.1037%2Fa0025172">debunked</a>. But the <a href="https://dx.doi.org/10.1177/0956797612466415">three</a> <a href="https://dx.doi.org/10.1177/0956797612466416">other</a> <a href="http://dx.doi.org/10.1177/0956797613476045">papers</a> were on evolutionary psychology, and two authors of <a href="https://dx.doi.org/10.1177/0956797612466415">one paper</a> were my former advisors John Tooby and Leda Cosmides.</p>
<p>That got my attention.</p>
<p>My first impression was that Gelman had found a new way to attack ev psych: cherry pick a few EP papers with questionable stats, and use those to tar the field.</p>
<p>Most of the discussion on Gelman’s blog involved the paper by Alec Beall and Jessica Tracy, <a href="http://dx.doi.org/10.1177/0956797613476045">Women more likely to wear red or pink at peak fertility,</a> published in <em>Psychological Science</em>, one of psychology’s top journals. The inspiration for the study was the fact that “females in many closely related species signal their fertile window in an observable manner, often involving red or pink coloration.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-06-27-monkey-butts-menstrual-cycles-sex-and-the-color-pink-the-statistical-crisis-in-science/Darwin_sexual_caricature.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Victorian cartoon</figcaption>
</figure>
</div>
<p>Monkey butts, menstrual cycles, sex, and the color pink. Nothing to mock there. The study, however, is more important than it sounds. If Beall and Tracy were right, human female ovulation is not <a href="http://www.jstor.org/stable/2460555">concealed</a> after all.</p>
<p>In Slate, Gelman <a href="http://www.slate.com/articles/health_and_science/science/2013/07/statistics_and_psychology_multiple_comparisons_give_spurious_results.html">accused</a> Beall and Tracy of conducting a fishing expedition — repeatedly making comparisons until they found one that was “statistically significant” and then reporting it as if they had predicted it in advance — a big, though often inadvertent, no-no that he claimed was widespread in science:</p>
<blockquote class="blockquote">
<p>There’s a larger statistical point to be made here, which is that as long as studies are conducted as fishing expeditions, with a willingness to look hard for patterns and report any comparisons that happen to be statistically significant, we will see lots of dramatic claims based on data patterns that don’t represent anything real in the general population. Again, this fishing can be done implicitly, without the researchers even realizing that they are making a series of choices enabling them to over-interpret patterns in their data.</p>
</blockquote>
<p>Every scientist knows that fishing is wrong, so Beall and Tracy were understandably <a href="http://ubc-emotionlab.ca/2013/07/too-good-does-not-always-mean-not-true/">upset</a> that Gelman accused them of unethical conduct without talking to them first.</p>
<p>I hadn’t met either author (so far as I know), so I googled them. According to Beall’s cv, he was a grad student and this was his first, first-authored paper. What a great introduction to academia! Get published in <em>Psych Science</em> on your first effort, only to be slammed by a prominent statistician, repeatedly. I became a regular reader of Gelman’s blog, and a week rarely goes by that he doesn’t <a href="https://www.google.com/search?num=20&amp;site=&amp;source=hp&amp;q=beall+tracy+site%3Aandrewgelman.com&amp;oq=beall+tracy+site%3Aandrewgelman.com">work in some dig</a> at the Beall and Tracy paper. In fact, I was inspired to write this post after a <a href="http://andrewgelman.com/2015/06/17/born-open-data/">recent dustup</a> over Beall and Tracy’s refusal to share their data with Gelman since Gelman wouldn’t tell them where he was publishing his critique (they have shared their data with others).</p>
<p>Gelman, who presented himself as a disinterested critic who only wanted to improve science, had several criticisms of the paper, but I am going to focus on one: Gelman guessed that Beall and Tracy had originally predicted that, like female chimpanzees who signal estrus with a prominent red swelling, women would tend to choose red shirts around the time of ovulation. Gelman surmised that after collecting their data Beall and Tracy noticed that there was no statistically significant tendency to wear red shirts during the fertile period (red only: p &gt;.05), but if women wearing red shirts and women wearing pink shirts were combined into a single, new category (reddish shirts), there was a statistically significant effect (red + pink: p&lt;.05).</p>
<p>I was a little confused. Researchers often combine conditions and no one blinks an eye (and Beall and Tracy <a href="http://ubc-emotionlab.ca/2013/07/too-good-does-not-always-mean-not-true/">deny</a> they did this). Further, there was no evidence that Beall and Tracy had repeatedly tested various combinations of shirt colors to find one that was “significantly” associated with the fertile period of women’s menstrual cycles, and then, after the fact, had come up with some theory to explain it, which would be a classic fishing expedition.</p>
<p>Gelman began to walk back his accusation that Beall and Tracy went fishing. Instead, <a href="http://dx.doi.org/10.1511/2014.111.460">in a paper with Eric Loken</a> in <em>American Scientist</em>, and on his <a href="http://andrewgelman.com/2014/05/31/jessica-tracy-alec-beall-authors-fertile-women-wear-pink-study-comment-garden-forking-paths-paper-comment-comments/">blog</a>, Gelman claimed that multiple comparisons can be a problem, <em>even when the research hypothesis was posited ahead of time and researchers only conduct one statistical test.</em></p>
<p>Huh?</p>
<p>Gelman’s own stats textbook didn’t mention anything about this. In fact, in the textbook and in a publication, Gelman et al.&nbsp;claimed “we (usually) don’t have to worry about multiple comparisons,” an irony he himself <a href="http://andrewgelman.com/2014/10/14/one-lifes-horrible-ironies-wrote-paper-usually-dont-worry-multiple-comparisons-now-spend-lots-time-worrying-multiple-comparisons/">noted</a>. Further, why pick on a grad student? Or evolutionary psychology? The problem, if there was one, would be pervasive throughout all the sciences.</p>
<p>My first impression was right. A reader of Gelman’s wondered why he spent so much time criticizing a study on pink shirts instead of the statistically flawed medical research that actually harms people, and Gelman <a href="http://andrewgelman.com/2015/06/08/the-psychologists-are-getting-a-hard-time-for-doing-what-they-do-whereas-people-doing-real-harm-to-society-are-happily-roaming-around-like-free-range-chicken/">admitted</a> he had an agenda: surprise, surprise, he doesn’t like evolutionary psychology:</p>
<blockquote class="blockquote">
<p>But I do think these social psychology studies make a difference too, in that they feed the idea that people are shallow and capricious, that we make all sorts of decisions based on our animal instincts etc. Sure, some of that is true but not to the extent claimed by those clueless researchers.</p>
</blockquote>
<blockquote class="blockquote">
<p>To erroneously connect fat arms [the paper co-authored by Tooby and Cosmides] or monthly cycles to political attitudes is to trivialize political attitudes, and I think that’s a mistake, whatever your politics.</p>
</blockquote>
<p>Well, Gelman also makes mistakes: singling out a few articles on one side of a debate that supposedly have statistical flaws, but not looking at articles on the other side of the debate, obviously says nothing about who’s right (even assuming such a debate exists; Gelman knows very little about evolutionary psychology).</p>
<p>Still, if Gelman’s general points were correct, I realized I could easily be making the same mistakes in my own research, and so too would a lot of other people. With some chagrin, I had to admit that although I was aware of the many debates surrounding Frequentist vs.&nbsp;Bayesian approaches to statistical inference, I had never thought critically about the foundation of them both: probability.</p>
<p>Following pointers on Gelman’s blog, I started reading. Late to the party as always, I discovered that many statisticians, such as <a href="https://med.stanford.edu/profiles/john-ioannidis?tab=bio">John Ioannidis</a>, and other quantitative types, such as <a href="http://opim.wharton.upenn.edu/~uws/">Uri Simonsohn</a>, <a href="https://opimweb.wharton.upenn.edu/profile/1666/">Joseph Simmons</a>, and <a href="http://facultybio.haas.berkeley.edu/faculty-list/nelson-leif">Leif Nelson</a>, believed there was a statistical crisis in science, and that it was possible that <a href="http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">most research findings were false</a>. Yikes! After pouring through many <a href="http://dx.doi.org/10.1177/0956797611417632">articles</a> and <a href="http://datacolada.org">blogs</a>, I concluded that although the tools statisticians have given us are powerful, they are very brittle and easy to break because probability is easy to get wrong.</p>
<p>The world is noisy and we humans have a propensity to see patterns in this noise where none exist. To distinguish signal from noise, most scientists therefore rely on the following expression:</p>
<p><a href="http://mathworld.wolfram.com/HypothesisTesting.html">P(D|H0)</a></p>
<p>which is the probability that your data (D) would turn out the way they did given some null hypothesis (H0), such as no difference in shirt color during peak fertility. If p is small, you’re looking at a signal and not noise. Yea! This is called Null Hypothesis Significance Testing (NHST).</p>
<p>There are many critics of NHST. But the problems that Gelman and others were highlighting actually did not involve NHST <em>per se</em>. Instead, they were making a <a href="https://en.wikipedia.org/wiki/Garbage_in,_garbage_out">“garbage in, garbage out”</a> argument. The probabilities spit out by standard software packages — p-values — were, in too many cases, misleadingly small because scientists had inadvertently fed the software the answers they wanted to see.</p>
<p>Probability is a subtle concept (and I’m probably going to screw it up right now!). To illustrate the problem Gelman and others have found, I will use a casino example. Imagine that you have a die you suspect is loaded. You roll it 2 times, and it comes up 3 each time. Can you reject the null that the die is fair? You might think that because the probability of rolling one three with a fair die is 1/6, and you’ve rolled two threes, the probability under the null is <img src="https://latex.codecogs.com/png.latex?(1/6)%5E2">, which is about 0.028, so you can reject the null hypothesis that the die is fair.</p>
<p>If that’s what you thought, you would be wrong, because it’s a trick question. If you had called two threes <em>before</em> rolling the die, that is, you suspected it was loaded to come up threes, and then it came up all threes, you could conclude that the die is (probably) loaded. But I asked you to test the null by computing the probability of two threes based on already having rolled two threes.</p>
<p>Hey, you might respond, it’s odd that the die came up three both times, right? Yes it is. It would also be odd if it came up two ones, or two twos, or two fours, etc., and I gave you no reason to suspect one of these possibilities over the others. The probability that it came up two ones OR two twos OR two threes OR two fours OR two fives OR two sixes is about 0.17, i.e., not odd at all. You can’t test the null by computing a probability as if you hadn’t seen the faces of the die if your choice of probability test is based on having seen those faces. This is the core problem.</p>
<p>In science, collecting data is the analog of rolling the dice. That’s what P(D|H0) means. To use this probability to distinguish signal from noise, we scientists must therefore make a very precise prediction <em>before</em> collecting or looking at the data because the p-values our stat programs compute are only accurate if our “call” was not influenced by the data.</p>
<p>But we all have looked at the data. Almost every statistics textbook, including Gelman’s, recommends that we pour over our data, checking distributional assumptions and so forth, <em>before</em> running any test. And many common choices during data analysis, such as controlling for potential confounds, looking at interactions, and combining conditions, can <a href="http://dx.doi.org/10.1177/0956797611417632">dramatically increase the chance of a false positive</a>.</p>
<p>Current best practice in the sciences is like first rolling the dice, then meticulously examining the numbers that land face up, but promising to not let anything we learn about those numbers influence any aspect of our call.</p>
<p>Think any casino would play by those rules?</p>
<p>Gelman and others are not criticizing NHST <em>per se</em> (or rather, that’s a separate argument). They are showing how easy it is to inadvertently break NHST.</p>
<p>In another irony, Gelman grounds this crisis in human nature: just like the gambler who has the strong monetary incentive to beat the house, scientists can usually only publish (and thus get credit for) “statistically significant” results, and therefore have an incentive to find some justification for altering their predictions after looking at the data (e.g., red+pink, not just red). That is, many scientists are pursuing their self-interest and taking a benefit they don’t deserve, and Gelman’s cheater detection mechanisms are on full alert. Just the phenomenon that put evolutionary psychology <a href="https://books.google.com/books?id=SxX4gRzOS6oC&amp;lpg=PA163&amp;ots=Bh0q1J0LzK&amp;dq=social%20exchange%20cosmides&amp;lr&amp;pg=PA163#v=onepage&amp;q&amp;f=false">on the map</a>!</p>
<p>Although deliberate or inadvertent cheating is certainly part of the story, I want to offer a different framing: scientists currently face an untenable tradeoff between learning about the world, and confirming what they’ve learned. If Beall and Tracy had discovered, rather than predicted, that women tend to wear pink shirts <em>and</em> red shirts during the fertile phase of their cycle, that would be important. Discovering that you need to control for, e.g., age, would be important. After all, aren’t scientists supposed to discover things? Combining the two colors, and studying “reddish” clothing, would be excellent science. So would controlling for previously unsuspected confounds. Unfortunately, these would break the computation of statistical significance that tells us this is a real effect and not just a fluke. Good science can be bad statistics, and good statistics can be bad science.</p>
<p>Science is screwed.</p>
<p>There is a way out of this mess, as statistician John Tukey realized decades ago. I’ll discuss that in my next post. For now, I will just note that there is a long history of ridiculing approaches to human sexuality that take account of our primate heritage. As targets of such ridicule, Beall and Tracy are in pretty good company:</p>
<blockquote class="blockquote">
<p>IN the discussion on Sexual Selection in my “Descent of Man,” no case interested and perplexed me so much as the brightly-coloured hinder ends and adjoining parts of certain monkeys. As these parts are more brightly coloured in one sex than the other, and as they become more brilliant during the season of love, I concluded that the colours had been gained as a sexual attraction. I was well aware that I thus laid myself open to ridicule; though in fact it is not more surprising that a monkey should display his bright-red hinder end than that a peacock should display his magnificent tail.</p>
<p>Charles Darwin (1876) <a href="http://www.nature.com/nature/journal/v15/n366/abs/015018a0.html">Sexual Selection in Relation to Monkeys</a>. <em>Nature</em>, 15, 18-19.</p>
</blockquote>
<!--
> Ed:

> The issues that Eric and I discussed are not special to evolutionary psychology. Much has been written about the propagation of mistaken research claims in medicine (consider the paper by Ioannidis) and neuroscience (consider the papers by Vul and Pashler, and by Button et al.), and in other papers I’ve discussed similar problems with the interpretation of statistical results in other fields such as education policy and public health.

> Why are 3 of our 4 examples in evolutionary psychology? I see two reasons. First, this isn’t quite an independent sample of size 4. The examples have many similar features and I think the central point of our paper is strengthened by the inclusion of several different papers with similar structures that make different decisions on which interactions to consider in their comparisons. Second, all of these are examples which were pointed out to me. Evolutionary psychology has some conceptual links to political science (in that it can be viewed as an alternative way of explaining the world) and maybe that’s one reason people are more likely to point me to articles on that topic, rather than to papers with similar problems that appear in medical research or neuroimaging.

http://andrewgelman.com/2014/05/31/jessica-tracy-alec-beall-authors-fertile-women-wear-pink-study-comment-garden-forking-paths-paper-comment-comments/


-->



 ]]></description>
  <category>science</category>
  <category>stats</category>
  <guid>https://blog.edhagen.net/posts/2015-06-27-monkey-butts-menstrual-cycles-sex-and-the-color-pink-the-statistical-crisis-in-science/index.html</guid>
  <pubDate>Sat, 27 Jun 2015 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2015-06-27-monkey-butts-menstrual-cycles-sex-and-the-color-pink-the-statistical-crisis-in-science/Darwin_sexual_caricature.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Pavlov’s dogs, dopamine and drug use</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/index.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Findings from studies investigating only stimulants (generally cocaine or amphetamine) were often discussed as though they applied to all addictions, even though there was no evidence for such an assumption. (Nutt et al.&nbsp;2015)</p>
</blockquote>
<p>Is it possible to get all the facts right, but still get the explanation wrong? That can happen to <a href="../../2015-05-15-i-am-a-sucker-for-a-good-theory/">anyone</a>. Nutt et al.&nbsp;(2015), writing in <a href="http://dx.doi.org/10.1038/nrn3939">Nature Reviews Neuroscience</a>, argue that it’s happened to an entire subfield, the neuroscience of substance use and addiction.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/olds_milner.2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Olds and Milner</figcaption>
</figure>
</div>
<p>The neuroscience of substance use is grounded in Pavlovian concepts that wield powerful and persistent influences over the behavioral sciences. The story begins over 60 years ago when James Olds and Peter Milner inserted wires into the septal areas of the brains of four rats. The rats were then tested in a Skinner box with a lever (above, right). When the rats pressed the lever, a small voltage was applied to the wire. The rats responded by pressing the lever hundreds of times an hour. Olds and Milner concluded that the “control exercised over the animal’s behavior by means of this reward is extreme, possibly exceeding that exercised by any other reward previously used in animal experimentation” (Old and Milner 1954, p.&nbsp;426).</p>
<p>The critical neurons turned out to be dopamine neurons in the midbrain. It was also discovered that various drugs of abuse increase dopamine release in this region. These and other findings lead Roy Wise and colleagues to propose the “hedonia” hypothesis: dopamine encoded reward itself; it was a “pleasure” molecule. If so, the role of dopamine in both reinforcement learning and drug use was clear: behaviors that resulted in food or sex – “natural” rewards – cause the release of dopamine in the MDS, whose pleasurable effects reinforce those behaviors. Drugs of abuse – conceptualized as “artificial” rewards that “hijack” the brain – also release dopamine, whose pleasurable effects similarly reinforce drug use.</p>
<p>Thus were born two intimately intertwined theories: the dopamine theory of reinforcement learning, and the dopamine theory of substance use and addiction, each deeply rooted in the stimulus-response paradigm at the core of behaviorism.</p>
<p>Twenty years of experiments using these and other methods showed that although dopamine plays some important role in reinforcement learning, it does not directly mediate the hedonic effects of rewards. In an interview in <em>Science</em> (Wickelgren, 1997), Roy Wise acknowledged that the hedonia hypothesis was wrong (<a href="http://www.drugabuse.gov/publications/addiction-science/why-do-people-abuse-drugs/natural-rewards-stimulate-dopamine-neurotransmission">time to update the NIDA website!</a>).</p>
<p>One alternative hypothesis is that mesolimbic dopamine mediates <em>wanting</em>, not liking. Key evidence for this hypothesis is that after 6-hydroxydopamine lesioning of their mesolimbic dopamine neurons, rats still seem to enjoy food and sex, but are no longer motivated to seek them out (Berridge 1996). On this view, drug-induced dopamine release hijacks the brain by inducing craving for the drug, but not pleasure at consuming it (Robinson and Berridge, 1993).</p>
<p>Another influential idea, based on electrophysiological recordings of dopamine neurons in monkeys, and with roots in the experiments of Pavlov, is that the phasic activity of mesolimbic dopamine neurons encodes reward prediction error: dopamine neurons spike with unexpected rewards, and their activity is suppressed with unexpected absence of rewards. But they don’t spike when monkeys get an expected reward (for an exhaustive review, see Schultz, in press). According to Glimcher (2011, p.&nbsp;15647), who eloquently defends this theory,</p>
<blockquote class="blockquote">
<p>[I]ntertwining of theory and experiment now suggests very clearly that the phasic activity of the midbrain dopamine neurons provides a global mechanism for synaptic modification. These synaptic modifications, in turn, provide the mechanistic underpinning for a <strong>specific class of reinforcement learning mechanisms that now seem to underlie much of human and animal behavior.</strong> (emphasis added)</p>
</blockquote>
<p>This ambitious theory has a harder time explaining how drugs hijack the brain (see Schultz, 2011 for some ideas).</p>
<p>Enter David Nutt and colleagues. Whatever the role of dopamine in reinforcement learning, Nutt et al.&nbsp;argue there are problems with the dopamine theory of drug use that have been swept under the carpet. Foremost among these is that, in experiments in humans that directly measure mesolimbic dopamine concentrations using <a href="https://en.wikipedia.org/wiki/Positron_emission_tomography">PET</a> or <a href="https://en.wikipedia.org/wiki/Single-photon_emission_computed_tomography">SPECT</a> scans, some popular drugs of abuse do not increase mesolimbic dopamine much. Here is the key figure in their paper (more negative binding values indicate increased dopamine release):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/nrn3939-f1.dopamine.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Nutt et al.</figcaption>
</figure>
</div>
<p>As you can see, whereas amphetamine clearly increases dopamine, morphine and THC mostly do not (and results for nicotine are variable).</p>
<p>Nutt et al.&nbsp;argue that the relationship between stimulants and dopamine is not surprising because these drugs act directly on the dopamine system:</p>
<blockquote class="blockquote">
<p>[W]hat was overlooked was the fact that methylphenidate and other stimulants act specifically on the dopamine system to increase dopamine levels. Thus, dopamine must be the proximal mediator of <strong>any</strong> psychological response to stimulants, and it should not be surprising that the change in striatal dopamine release correlates with the subjective high. (emphasis added)</p>
</blockquote>
<p>Lower availability of D2/D3 receptors is consistently associated with addiction to some drugs, like cocaine, which supports the dopamine theory of drug use. But this association also presents a paradox:</p>
<blockquote class="blockquote">
<p>If dopamine acting through D2 and/or D3 receptors is necessary to experience a drug high, then lower receptor availability should result in less-rewarding rather than more-rewarding drug effects.</p>
</blockquote>
<p>Lower D2/D3 availability is also not consistently associated with addiction to other drugs, such as opiates, cannabis, or nicotine.</p>
<p>Nutt et al.&nbsp;conclude:</p>
<blockquote class="blockquote">
<p>Tellingly, the dopamine theory has not led to any new treatments for addiction. We suggest that the role of dopamine in addiction is more complicated than the role proposed in the dopamine theory of reward. We propose that dopamine has a central role in addiction to stimulant drugs, which act directly via the dopamine system, but that it has a less important role, if any, in mediating addiction to other drugs, particularly opiates and cannabis.</p>
</blockquote>
<p>Unlike Nutt et al., I don’t fault drug researchers for the dopamine theory. On the contrary, good theories are ambitious, with clear predictions that can be falsified by evidence. It is also easy, when in the grip of a compelling theory with much supporting evidence, to dismiss findings that contradict the theory.</p>
<p>Still, by highlighting evidence that contradicts the dominant dopamine model of drug use, Nutt et al.&nbsp;bolster <a href="http://journal.frontiersin.org/article/10.3389/fpsyt.2013.00142/full">our critique</a> of the dopamine model’s evolutionary rationale that drugs are evolutionary novel, provide no benefits, and “hijack” the brain via these dopamine circuits.</p>
<p>The image at the top of this post epitomizes an approach to studying evolved animal mechanisms, such as reinforcement learning mechanisms, that often abstracts away critical details of the environment that selected for the evolved mechanism. Most popular drugs are plant defensive chemicals, or their close chemical analogs (alcohol is the exception). Plant defensive compounds have infused animal diets since at least the time terrestrial plants and animals evolved, about 400 million years ago. My colleagues and I argue that neurobiological theories of drug use, and perhaps also the related theories that ground much animal behavior in a single neurotransmitter, would profit by incorporating, rather than ignoring, the long co-evolution of plants and animals.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/carboniferous.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Carboniferious</figcaption>
</figure>
</div>
<section id="references" class="level1">
<h1>References</h1>
<p>Berridge, K. C. (1996). Food reward: brain substrates of wanting and liking. Neuroscience &amp; Biobehavioral Reviews, 20(1), 1-25.</p>
<p>Glimcher, P. W. (2011). Colloquium Paper: Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis. Proceedings of the National Academy of Sciences, 108(Supplement_3), 15647–15654. <a href="http://doi.org/10.1073/pnas.1014269108" class="uri">http://doi.org/10.1073/pnas.1014269108</a></p>
<p>Hagen, E. H., Roulette, C. J., &amp; Sullivan, R. J. (2013). Explaining Human Recreational Use of “pesticides”: The Neurotoxin Regulation Model of Substance Use vs.&nbsp;the Hijack Model and Implications for Age and Sex Differences in Drug Consumption. Frontiers in Psychiatry, 4. <a href="http://doi.org/10.3389/fpsyt.2013.00142" class="uri">http://doi.org/10.3389/fpsyt.2013.00142</a></p>
<p>Olds, J. (1958). Self-Stimulation of the Brain Its Use To Study Local Effects of Hunger, Sex, and Drugs. Science, 127(3294), 315–324. http://doi.org/10.1126/science.127.3294.315</p>
<p>Olds, J., &amp; Milner, P. (1954). Positive reinforcement produced by electrical stimulation of septal area and other regions of rat brain. Journal of Comparative and Physiological Psychology, 47(6), 419–427.</p>
<p>Nutt, D. J., Lingford-Hughes, A., Erritzoe, D., &amp; Stokes, P. R. (2015). The dopamine theory of addiction: 40 years of highs and lows. Nature Reviews Neuroscience, 16(5), 305-312. <a href="http://doi.org/10.1038/nrn3939" class="uri">http://doi.org/10.1038/nrn3939</a></p>
<p>Robinson, T. E., &amp; Berridge, K. C. (1993). The neural basis of drug craving: an incentive-sensitization theory of addiction. Brain Research Reviews, 18(3), 247-291.</p>
<p>Schultz, W. (2011). Potential Vulnerabilities of Neuronal Reward, Risk, and Decision Mechanisms to Addictive Drugs. Neuron, 69(4), 603–617. <a href="http://doi.org/10.1016/j.neuron.2011.02.014" class="uri">http://doi.org/10.1016/j.neuron.2011.02.014</a></p>
<p>Schultz, W. (in press). Neuronal reward and decision signals: from theories to data. Physiological Reviews. <a href="http://www.pdn.cam.ac.uk/staff/schultz/pdfs%20website/2015%20Schultz%20PhysiolRev%20in%20press.pdf" class="uri">http://www.pdn.cam.ac.uk/staff/schultz/pdfs%20website/2015%20Schultz%20PhysiolRev%20in%20press.pdf</a></p>
<p>Wickelgren, I. (1997). Getting the brain’s attention. Science, 278(5335), 35-37.</p>
<p>Figure 1: Modified from Olds, 1958.</p>
<p>Figure 2: From Nutt et al., 2015.</p>
<p>Figure 3: Modified from “Carboniferous Pteridophyta (After Dana)” from a the 1896 edition of Underwood’s Native Ferns and their Allies.</p>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/index.html</guid>
  <pubDate>Sat, 16 May 2015 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2015-05-16-pavlovs-dogs-dopamine-and-drug-use/olds_milner.2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>I’m a sucker for a good theory</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/index.html</link>
  <description><![CDATA[ 




<p>I’m a sucker for a good theory.</p>
<p>After getting my BA, I had no idea what I wanted to do with my life. A friend, perhaps exasperated with my refusal to commit to a career, introduced me to her brother-in-law, Bruce Novak, who had just gotten a position in the UC Berkeley Department of Chemistry. Bruce had recently finished his PhD at Cal Tech (under Grubbs, who, to name drop, would later win the Nobel Prize in Chemistry). Bruce needed someone to set up his lab and get projects started, and he asked me if I wanted to do it. I have no idea why he asked me – I had little more than a high school education in chemistry. Also, Bruce was a polymer chemist. Plastics. There’s a great future in plastics. Just not the future I wanted for myself. But hey, it was a paycheck, so I agreed.</p>
<p>I soon realized that polymer chemistry was the ultimate geek discipline: you build cool stuff at the molecular level. Some molecules have these properties, others have those properties. If you can hook them together in a polymer, you’ve now got a material that has both.</p>
<p>Bruce had a very clever idea. Polyphenylene sulfide (PPS) is a tough, light brown, sulfur-based organic polymer that is normally an electrical insulator. PPS p-orbitals overlap, however. Oxidation removes electrons from the overlapping orbitals, which then form a molecule-wide electron conduction band, very similar to the conduction band in metals. Upon this so-called “doping,” PPS becomes dark and shiny (just like metal!), and conducts electricity along its backbone. Yes, you can turn some plastics into “metals,” retaining advantages of both.</p>
<p>Here’s PPS (the bracket with the “n” subscript means repeat n times):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/Polyphenylene_sulfide.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">polyphenylene sulfide</figcaption>
</figure>
</div>
<p>There was another group of sulfur-based molecules with a very similar chemical structure, triarylsulfonium salts, that were photo-reactive:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/triarylsulfonium_reaction.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">triarylsulfonium_reaction</figcaption>
</figure>
</div>
<p>The key, here, is that when you photolyze this molecule (shine light on it, hv), you knock off one of the rings, creating a radical cation – a charged molecule with an unpaired electron (the S+ with the dot over it). If we could make a polymeric form of this molecule, which we dubbed arylated PPS (APPS), it would be very similar to PPS. When we hit it with light, the unpaired electron on the polymer backbone should convert APPS into a conducting polymer – “photo-doping.” In other words, we could imprint conducting circuits directly into a non-conducting plastic simply by exposing it to light.</p>
<p>Here was the reaction with which we hoped to create APPS (the polymer on the right hand side):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/reaction.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">reaction</figcaption>
</figure>
</div>
<p>PPS was hard to work with. It would only dissolve in chloronapthalene at 220 C, conditions that destroyed the other starting material. After weeks of unsuccessful attempts, my undergraduate assistant, Anand Viswanathan, and I finally made something that looked like a light brown polymer, but unlike PPS, it dissolved in acetone at room temperature, as we predicted APPS would do.</p>
<p>What was it? What is photoreactive? Would it conduct electricity? I quickly made a thin film of the stuff. After it dried, I grabbed the lab multimeter, put it on the ohm setting, and stuck the probes on the film. The display was blank – no measurable conductivity. Good. Then I shined a UV light on the film. It turned dark and shiny. I put the probes on again, and the multimeter display started to blink, settling down in the MΩ range. The film was conducting electricity. Not well–it was almost beyond the sensitivity of the meter–<em>but it was conducting</em>!</p>
<p>Months of work followed to confirm we’d made what we thought we’d made, that it reacted with light the way we thought it should, and that electrical conduction was based on that radical on the polymer backbone. I did countless NMR’s, UV/vis spectrograms, elemental analyses, and electron spin resonance analyses that all pointed to the same conclusion: we had made APPS, and when we hit it with UV light, we would cleave off a phenyl group, forming a radical cation on the polymer backbone. The material would become reflective (an indicator that an electron conduction band had formed), and it would conduct electricity. When we quenched the radical cation with water, we eliminated electrical conductivity.</p>
<p>It was time to submit, to <em>Science</em>. Bruce gave me the first author slot. He waited patiently for me to finish my draft, and then rewrote the whole thing (precisely one sentence of mine remained).</p>
<p>While our paper was under review at <em>Science</em>, we wanted to determine the true conductivity of APPS, and increase it, if possible. The challenge was that as soon as we photolyzed the film, it would start to reflect light, limiting further photolyzation. We therefore had an extremely thin conducting layer, but our calculation of conductivity was based on the entire thickness of the, mostly unphotolyzed, film; our estimated conductivity value was therefore far too low. This problem was compounded by the fact that our low conductivity was near the limit that my multimeter could detect. Worse, the photolyzed film would immediately start to absorb moisture, which quenched the radical, killing the conductivity. We were confident that if we could solve these problems, we would achieve much higher conductivity than we had seen so far.</p>
<p>I had tried various quick-and-dirty solutions. I flooded the film with a stream of nitrogen, to keep off moisture, but the building nitrogen was contaminated with water. I pumped my equipment into a dry box, but the static electricity played havoc with my ohm meter. Plus, it was hard to work with a delicate film using large rubber gloves. I built a spinner that created ultra thin films of APPS, but this didn’t seem to improve the conductivity values, probably because my meter wasn’t sensitive enough.</p>
<p>We finally decided to do things right. We needed to run our experiments under dry nitrogen from start to finish, with the thinnest possible film, and with a conductivity meter that could accurately measure the very low values we would get with such a thin film.</p>
<p>We bought what was basically a $10,000 ohm meter that was orders of magnitude more sensitive than my multimeter, and I built a special airtight chamber with a UV light underneath a quartz plate (which transmits UV light), flooded with nitrogen straight off a liquid nitrogen dewar (dry dry dry). We would spin an ultra thin film of APPS on a quartz slide and let it dry in the chamber under a flood of dry nitrogen. We would then lower the conductivity probes and turn on the UV light. If everything worked, we should measure the true, and hopefully much higher, conductivity.</p>
<p>The day I finally had everything assembled, we heard back from <em>Science</em>. Our paper was accepted! The copy editing on our article was even already complete. If we could get the higher conductivity numbers in the paper, that would be icing on the cake.</p>
<p>I rushed into the lab and got the experiment running. I spun a fresh film and put it in the chamber. After a lengthy purge with dry nitrogen, I lowered the probes and measured the conductivity. Nothing. Good. I then flipped the switch on the UV light, and waited. Still no conductivity.</p>
<p>Huh?</p>
<p>I opened the unit to confirm that the probes were in contact with the film, and the conductivity meter started to register. Uh oh. I tried another film. Nitrogen purge + UV: zero conductivity. Open the unit: conductivity. I tried another film. Same thing: no conductivity until I exposed the film to air. And another. Same thing. The implication was obvious, and devastating to the project. I called Bruce in to show him what was happening. By this time, the entire lab had gathered around. Tom, my dour labmate, pronounced the epitaph: “It’s water.”</p>
<p>See that MX- in the figure, above right, hovering near the S+? APPS is a salt. Add water to salt, and you get electrical conduction, not by a cool electronic conduction mechanism along the polymer backbone, but by an ordinary ionic mechanism. All along we had been looking at ionic conduction in water absorbed from the air, not electronic conduction.</p>
<p>We thought we had ruled out ionic conduction. Ionic conduction would not make our film shiny and reflective. With an ionic conduction mechanism, which would not depend on the presence of a radical, water should have increased conductivity. When we deliberately added water to our film, though, it quenched the radical, and also the conductivity, as expected for the electronic mechanism. Somehow, the small amount of moisture in the air was enough to create a thin salty mixture that would conduct, but adding more water degraded the photolyzed polymer so it no longer did.</p>
<p>That afternoon, I flipped back through my lab book, looking at the notes I had taken on hundreds of experiments that mostly yielded positive results. How had I missed this? What I now saw was that every time I got a negative result under exceptionally dry conditions, I had dismissed it: the building nitrogen was wet; the static in the dry box was screwing with my electronics; the conductivity in such thin films was too low for my multimeter. Yet the truth was there, hovering like a Romulan battleship just at the edge of sensor range.</p>
<p>The frustrating thing was that all our chemistry was right. We <em>had</em> made what we thought we’d made – a brand new photopolymer – and it reacted with light the way we predicted. Every fact we reported, was, in fact, a fact (and our results were eventually <a href="http://anthro.vancouver.wsu.edu/media/PDF/Novak_et_al_1994_Synthesis_and_photochemistry_of_aaps.pdf">published in a respectable journal</a>). The problem is that the evidence for electronic conduction mechanisms in polymers is almost always circumstantial. The same evidence that demonstrated electronic conduction in other polymers was misleading in our case.</p>
<p>I had allowed myself to be seduced by a very plausible, and seemingly well-supported, theory.</p>
<p>Driving home that evening as the sun set over San Francisco Bay, I was upbeat, almost euphoric. The truth was, I didn’t want to be a polymer chemist. Over the past year, I had been sneaking off to attend classes by George Lakeoff, John Searle, and Brent Berlin. I was fascinated by theories of cognition and human nature, and I had been reading voraciously in linguistics, philosophy, and anthropology. If our work had been published in <em>Science</em> I would have felt obligated to continue on the project for at least another year, maybe more. Now, with our submission withdrawn and the project more or less dead, I was free.</p>
<p>A few weeks earlier, the same friend who had introduced me to Bruce bought me a book she had seen in a Berkeley bookstore: <em>Intimate Fathers</em> by Barry Hewlett, a study of parenting among Aka pygmies. This has “Ed” written all over it, she said. She was right.</p>
<p>I was jumping, though, from the frying pan into the fire. The cognitive and behavioral sciences, I would soon learn, are, like our APPS Science paper, based on <a href="https://grasshoppermouse.github.io/2015/05/16/pavlovs-dogs-dopamine-and-drug-use/">seductive theories</a> backed by circumstantial evidence.</p>



 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/index.html</guid>
  <pubDate>Fri, 15 May 2015 07:00:00 GMT</pubDate>
  <media:content url="https://blog.edhagen.net/posts/2015-05-15-im-a-sucker-for-a-good-theory/Polyphenylene_sulfide.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Is pregnancy immunosuppression a myth?</title>
  <dc:creator>Ed Hagen</dc:creator>
  <link>https://blog.edhagen.net/posts/2015-04-19-is-pregnancy-immunosuppression-a-myth/index.html</link>
  <description><![CDATA[ 




<p>My grad student Caity Placek is working on behavioral immunity during pregnancy. Behavioral immunity refers to psychological adaptations that help defend against pathogens; avoidance of sick people would be a possible example.</p>
<p>Caity’s results suggest that aversion to meat in pregnancy is related to infection risk, especially in the first trimester. This supports an influential hypothesis put forward in 2000 by Flaxman and Sherman that these aversions are due to the immunosuppression that also occurs early in pregnancy. The rationale is that, during human evolution, meat often harbored pathogens, so immunosuppressed pregnant women should have evolved to avoid it.</p>
<p>The idea that pregnant women are immunosuppressed originated with Peter Medawar, who won a Nobel prize for his work on tissue grafts. In 1953, Medawar pointed out that the fetus was like an organ transplant: with half of its genes coming from dad, it produced many proteins that were foreign to mom. Why, then, didn’t mom’s immune system attack the fetus as it would a transplanted organ? In an article billed as “the most influential contribution made to the development of the field of Reproductive Immunology” (Billington 2003), Medawar asked</p>
<blockquote class="blockquote">
<p>The immunological problem of pregnancy may be formulated thus: how does the pregnant mother contrive to nourish within itself, for many weeks or months, a foetus that is an antigenically foreign body?</p>
</blockquote>
<p>For the next 40 years, much research on this “immunological paradox” was conducted as if the fetal ‘allograft’ were like a surgically transplanted organ (Erlebacher 2013). One solution to the paradox offered by Medawar was “the immunological indolence or inertness of the [pregnant] mother.” In other words, to avoid rejecting the fetus as they would a transplanted kidney, pregnant women were naturally immunosuppressed.</p>
<p>A more recent variant of this hypothesis involved the Th1-Th2 paradigm, in which Th1 cells express proinflammatory cytokines, whereas Th2 cells secrete cytokines promoting humoral immunity, and either pathway can down-regulate the other. The pregnancy state was thought to be a Th2 biased state, to avoid an inflammatory response to the fetus.</p>
<p>But are pregnant women immunosuppressed, or in a Th2 biased state? When Caity and I started looking into the literature on pregnancy immunosuppression, we found that opinion seems to have shifted dramatically since 2000. Recent reviews on the topic in the New England Journal of Medicine and the American Journal of Reproductive Immunology are heaping skepticism on the idea that pregnant women are immunosuppressed. For instance, Racicot et al.&nbsp;(2014), writing in the American Journal of Reproductive Immunology, state that</p>
<blockquote class="blockquote">
<p>The old concept that pregnancy is associated with immune suppression has created a myth of pregnancy as a state of immunological weakness and therefore of increased susceptibility to infectious diseases. Today, there is increasing evidence suggesting that this concept is incorrect and the immune system during pregnancy is functional and highly active.</p>
</blockquote>
<p>In the same journal, Silasi et al.&nbsp;(2015) write</p>
<blockquote class="blockquote">
<p>One of the main hypotheses used to explain the increased risk for infection and mortality during pregnancy has been the concept of ‘pregnancy as an immune-suppressed condition’. The ‘paradox of pregnancy’ as a semi-allograft has been approached from the point of perspective of organ transplantation. The view of the fetus as an organ transplant, and the requirement of systemic immune suppression for the success of the transplant, led to the proposal of pregnancy as a condition of systemic immune suppression as a requirement for the success of the pregnancy. From this point of view, similarly as in immune-suppressed patients, pregnancy is in a state of weak immunologic protection.</p>
</blockquote>
<blockquote class="blockquote">
<p>This concept has been tested for many years in animal models as well as in patients with fertility problems. Unfortunately, after almost 50 years of research following this assumption, there is a lack of evidence to support this hypothesis.</p>
</blockquote>
<p>Writing in the New England Journal of Medicine, Kourtis et al.&nbsp;(2014) similarly conclude</p>
<blockquote class="blockquote">
<p>Elucidation of the immunologic alterations and adaptations that occur during pregnancy suggests that older concepts of pregnancy as a state of systemic immunosuppression are oversimplified. A more useful model may be the view of pregnancy as a modulated immunologic condition, not a state of immunosuppression.</p>
</blockquote>
<p>The evidence against systemic (emphasis on <em>systemic</em>) immunosuppression in pregnancy is pretty compelling.</p>
<p>There is little epidemiological evidence that pregnant women are more vulnerable to infection. In a review of pregnancy and infection, Kourtis et al.&nbsp;(2014) state “The fact that pregnant women do not seem, on the basis of epidemiologic evidence, to be more susceptible to infections in general also contradicts [the pregnancy immunosuppression] theory.” Keeping in mind that, for some infectious diseases, there are national and global surveillance programs involving millions of patients, and that public health researchers are particularly concerned about infections during pregnancy, this is a powerful blow to the theory.</p>
<p>My first thought was that maybe behavioral immunity compensates for immunosuppression, but no, pregnant women respond well to vaccines: “Adequate immunologic responses to vaccination in pregnant women have been demonstrated in several studies and for several pathogens” (Kourtis et al.&nbsp;2014), and these responses do not appear to depend significantly on trimester (Pazos et al.&nbsp;2012).</p>
<p>Further, researchers find that the immune system is “functional and highly active” during pregnancy (Racicot et al.&nbsp;2014). And pregnant women’s immune systems do detect and respond to the fetus. The title of this paper says it all: <em>Fetal-Specific CD8+ Cytotoxic T Cell Responses Develop during Normal Human Pregnancy and Exhibit Broad Functional Capacity</em> (Lissauer et al.&nbsp;2012).</p>
<p>What changed?</p>
<p>First, it is now recognized that many shifts in immunity during pregnancy are specific to the maternal-fetal interface (the uterus and placenta), and these must be clearly distinguished from systemic immune changes. In fact, the Th1-Th2 model of pregnancy was based mostly on studies of the maternal-fetal interface, and might not apply to systemic immunity (Pazos et al.&nbsp;2012):</p>
<blockquote class="blockquote">
<p>Most evidence supporting a Th2 shifts derives from studies of [the maternal/fetal] interface rather than systemic immunity. Although inflammatory events have been shown to be important at critical times at the beginning and end of gestation, for the most part, the uterine environment is biased toward Th2 [34]. Arguments for a Th2 bias in the periphery are much more contentious [35].</p>
</blockquote>
<p>Second, the fetus and placenta are now seen as an active players that generally cooperate with the maternal immune system to provide immunity during pregnancy (Mor et al.&nbsp;2010).</p>
<p>Third, earlier views were heavily influenced by studies of pregnancy complications and loss in humans, as well as mouse models, which might not translate to immune responses during healthy human pregnancies.</p>
<p>What didn’t change?</p>
<p>How the mother tolerates the semiallogeneic fetus is still seen as an important and not fully understood problem.</p>
<p>Although pregnant women are generally not more susceptible to infection, there is solid evidence that if they do become infected, the consequences are more severe. Infections with influenza, hepatitis E virus, herpes simplex virus, malaria, measles, smallpox, HIV, varicella, and coccidioidomycosis are all more severe in pregnant women (Kourtis et al.&nbsp;2014).</p>
<p>Pregnant women do seem to be more susceptible to infection with a few pathogens, in particular malaria and listeriosis (Kourtis et al.&nbsp;2014). Listeriosis is a food borne bacteria, often found on raw dairy products and meat. Hmmm.</p>
<p>There are shifts in immunity during pregnancy. A recent longitudinal study of healthy pregnancies, for example, found that “pregnancy is not a period of immunosuppression but an alteration in immune priorities characterized by a strengthening of innate immune barriers and a concomitant reduction in adaptive/inflammatory immunity in the later stages of pregnancy” (Kraus et al.&nbsp;2012).</p>
<p>Where does this leave Caity? And Flaxman and Sherman? Here are a few obvious possible reinterpretations.</p>
<p>In the &gt;100 million years since the evolution of viviparity, sophisticated (but not infallible) mechanisms have evolved in both mother and fetus to allow the immune system to be fully active against pathogens without jeopardizing the fetus. Many of these mechanisms are localized to the uterine environment.</p>
<p>Pregnant women might have evolved an aversion to meat, not because they are more vulnerable to infection, but because the <em>costs</em> of infection are higher during pregnancy. It is also possible that some pregnancy-related aversions are specific to particular pathogens that do more easily infect pregnant women.</p>
<p>Pregnancy-related shifts in immunity imply shifts in trade-offs: improvements to some aspects of immunity but detriments to others. These might be related to the energetic cost of pregnancy, to the challenges of a semiallogeneic fetus, and/or to the need for placental, fetal, and maternal immune mechanisms to coordinate. Perhaps, <em>a la</em> Haig, there are conflicts with paternal genes that pose special challenges.</p>
<p>Finally, there are still many unknowns and much debate. To give the last word to Medawar, he believed the key factor ensuring the success of gestation was not maternal immunosuppression but rather “the anatomical separation of foetus from mother,” a basic conclusion that, according to Billington (2003), remains substantially valid to this day.</p>
<section id="references" class="level1">
<h1>References</h1>
<p>Billington, W. D. (2003). The immunological problem of pregnancy: 50 years with the hope of progress. A tribute to Peter Medawar. Journal of Reproductive Immunology, 60(1), 1–11. <a href="http://doi.org/10.1016/S0165-0378(03)00083-4" class="uri">http://doi.org/10.1016/S0165-0378(03)00083-4</a></p>
<p>Erlebacher, A. (2013). Mechanisms of T cell tolerance towards the allogeneic fetus. Nature Reviews Immunology, 13(1), 23–33. <a href="http://doi.org/10.1038/nri3361" class="uri">http://doi.org/10.1038/nri3361</a></p>
<p>Flaxman, S. M., &amp; Sherman, P. W. (2000). Morning Sickness: A Mechanism for Protecting Mother and Embryo. The Quarterly Review of Biology, 75(2), 113–148. <a href="http://doi.org/10.2307/2664252" class="uri">http://doi.org/10.2307/2664252</a></p>
<p>Kourtis, A. P., Read, J. S., &amp; Jamieson, D. J. (2014). Pregnancy and Infection. New England Journal of Medicine, 370(23), 2211–2218. <a href="http://doi.org/10.1056/NEJMra1213566" class="uri">http://doi.org/10.1056/NEJMra1213566</a></p>
<p>Lissauer, D., Piper, K., Goodyear, O., Kilby, M. D., &amp; Moss, P. A. H. (2012). Fetal-Specific CD8+ Cytotoxic T Cell Responses Develop during Normal Human Pregnancy and Exhibit Broad Functional Capacity. The Journal of Immunology, 189(2), 1072–1080. <a href="http://doi.org/10.4049/jimmunol.1200544" class="uri">http://doi.org/10.4049/jimmunol.1200544</a></p>
<p>Medawar, P. B. (1953, January). Some immunological and endocrinological problems raised by the evolution of viviparity in vertebrates. In Symp Soc Exp Biol (Vol. 7, No.&nbsp;320, p.&nbsp;38).</p>
<p>Mor, G., &amp; Cardenas, I. (2010). The Immune System in Pregnancy: A Unique Complexity: IMMUNE SYSTEM IN PREGNANCY. American Journal of Reproductive Immunology, 63(6), 425–433. <a href="http://doi.org/10.1111/j.1600-0897.2010.00836.x" class="uri">http://doi.org/10.1111/j.1600-0897.2010.00836.x</a></p>
<p>Pazos, M., Sperling, R. S., Moran, T. M., &amp; Kraus, T. A. (2012). The influence of pregnancy on systemic immunity. Immunologic Research, 54(1-3), 254–261. <a href="http://doi.org/10.1007/s12026-012-8303-9" class="uri">http://doi.org/10.1007/s12026-012-8303-9</a></p>
<p>Placek, C. (2015) Fetal protection: The roles of social learning and innate food aversions in South India. The International Society for Evolution, Medicine, &amp; Public Health Inaugural Meeting, March 19-21, 2015 in Tempe, Arizona.</p>
<p>Racicot, K., Kwon, J.-Y., Aldo, P., Silasi, M., &amp; Mor, G. (2014). Understanding the Complexity of the Immune System during Pregnancy. American Journal of Reproductive Immunology, 72(2), 107–116. <a href="http://doi.org/10.1111/aji.12289" class="uri">http://doi.org/10.1111/aji.12289</a></p>
<p>Silasi, M., Cardenas, I., Kwon, J.-Y., Racicot, K., Aldo, P., &amp; Mor, G. (2015). Viral Infections During Pregnancy. American Journal of Reproductive Immunology, 73(3), 199–213. <a href="http://doi.org/10.1111/aji.12355" class="uri">http://doi.org/10.1111/aji.12355</a></p>


</section>

 ]]></description>
  <category>science</category>
  <guid>https://blog.edhagen.net/posts/2015-04-19-is-pregnancy-immunosuppression-a-myth/index.html</guid>
  <pubDate>Sun, 19 Apr 2015 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
