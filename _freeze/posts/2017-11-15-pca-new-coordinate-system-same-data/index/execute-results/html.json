{
  "hash": "7df8324e5671c1406faac8189429afb8",
  "result": {
    "markdown": "---\ntitle: \"PCA: new coordinate system, same data\"\nauthor: \"Ed Hagen\"\ndate: \"11-15-2017\"\nimage: \"ConstellationBigDipper.png\"\ncategories:\n  - stats\n---\n\n\n\n\nThere are many ways to teach Principal Component Analysis (PCA). This way is mine.\n\nThe first constellation I learned to recognize was the [Big Dipper](https://en.wikipedia.org/wiki/Big_Dipper). In the evening it's in one part of the sky, and in the early morning, another, but it's still the Big Dipper. Same thing if I look at it while I slowly spin around. To be more specific, in each of the 3 figures below, the stars have different $x$ and $y$ coordinates, yet it is easy to recognize them as the same stars:\n\n![Big Dipper](ConstellationBigDipper.png)\n\nThe point is: we recognize the Big Dipper, not by the specific location of the stars in the sky, but by the location of each star *relative to the others*.\n\nThe first and most important step in understanding PCA is to think about your data in the same way that you think about constellations: it's the relationships between your data points, not their individual values, that matters.\n\nIn a scientific study, we typically measure multiple values on each person (or population, or whatever), e.g., age, height, weight, sex, and so forth. The mental frame shift to make is to think about the collection of multiple values on a single person as a *single* data point --- a single \"star\" in the sky --- and all the data points as a constellation of stars in the sky. If we had two measurements per person -- e.g., height and weight -- then each person (each data point) has two coordinates; if we had three measurements per person -- e.g., height, weight, and age -- then each person (each data point) has three coordinates, and so forth.\n\nIn general, you can think about each \"unit\" in the data -- person or observation or \"row\" -- as one point in an $N$-dimensional Euclidean space, where $N$ is the number of variables that you have measured. Viewed this way, the data has a \"structure\" determined by the relationships of each observations to the others that will be preserved even if the coordinate system is changed. \n\nHere is a concrete example with 2 variables per person -- *height* and *weight* -- and thus a 2-dimensional space of points:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Height and weight of !Kung individuals.\n# The !Kung are an ethnic group in\n# southwest Africa.\n# From Howell via McElreath:\nd <- readr::read_delim(\"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv\", delim = ';')\nlibrary(ggplot2)\nggplot(d, aes(height, weight)) + \n  geom_point(alpha = 0.5) + \n  scale_x_continuous(limits = c(0,200)) +\n  scale_y_continuous(limits = c(0,70)) +\n  geom_point(x = 0, y = 0, colour = 'red', size = 3) +\n  labs(title = \"!Kung heights and weights\", subtitle = \"Each black dot represents one person.\\nThe red dot indicates the origin of the coordinate system.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nMost students would (correctly) interpret this plot as depicting the relationship between height and weight.\n\nThere is another way.\n\nAlthough each star in the Big Dipper is also described by two variables -- an $x$ and $y$ coordinate (or an [ascension and declination](http://www.skyandtelescope.com/astronomy-resources/what-are-celestial-coordinates/)) -- both variables are in the *same units* (angles). This is an important reason why we can think about the Big Dipper in space without thinking about the $x$ and $y$ values of each star. \n\nThe first step on our journey is therefore to put our height and weight variables into the same units by [standardizing them](https://en.wikipedia.org/wiki/Standard_score) (subtract the mean from each variable, and then divide it by its standard deviation):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standardize each variable\nd$zheight <- scale(d$height)[,1]\nd$zweight <- scale(d$weight)[,1]\n# Plot\nggplot(d, aes(zheight, zweight)) + \n  geom_point(alpha = 0.5) +\n  geom_point(x = 0, y = 0, colour = 'red', size = 3) +\n  coord_fixed(xlim = c(-4, 3), ylim = c(-3, 3)) +\n  labs(title = \"Standardized !Kung heights and weights\", subtitle = \"Each black dot represents one person.\\nThe red dot indicates the origin of the coordinate system.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nMany folks would (correctly) interpret these new variables as transformed versions of the original data. However, I would like you to instead see this as a transformation of the *coordinate system*: we have translated the origin of the coordinate system to the middle of the data (the red dot), and we have put the $x$ and $y$ axes on the same scale (1 unit of x equals 1 unit of y). The data remain the same.\n\nThe translation of the origin to the center of the data is useful because positive values on the $x$-axis now indicate values that are greater than the mean, and negative values now indicate values that are less than the mean. The same goes for the $y$-axis. The translation of the origin makes it easy to identify individuals whose heights and weights are above or below average. Transforming the coordinate system (not the data!) can help us interpret the data -- the new origin has advantages over the original origin.\n\nPutting the $x$ and $y$ axes on the same scale is useful because we can now more easily think about this 2d space as a uniform *height-weight* space, or *height-weight* continuum, independent of individual $height$ and $weight$ values.\n\nWe are ready for another transformation of the coordinate system: a rotation around the origin:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nangle <- -1.5 # angle of rotation in radians\n\n# New x and y coordinates after rotation\nd$x <- d$zheight * cos(angle) - d$zweight * sin(angle)\nd$y <- d$zheight * sin(angle) + d$zweight * cos(angle)\n\nggplot(d, aes(x, y)) + \n  geom_point(alpha = 0.5) +\n  geom_point(x = 0, y = 0, colour = 'red', size = 3) +\n  coord_fixed(xlim = c(-4, 3), ylim = c(-3, 3)) +\n  labs(title = \"Rotated !Kung heights and weights\", subtitle = \"Each black dot represents one person.\\nThe red dot indicates the origin of the coordinate system.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nHere are the pairs of coordinates of our first 6 data points in each of our 3 different coordinate systems (the original, standardized, and rotated coordinate system):\n\n\n::: {.cell}\n::: {.cell-output-display}\n| height| weight| zheight| zweight|     x|     y|\n|------:|------:|-------:|-------:|-----:|-----:|\n| 151.76|  47.83|    0.49|    0.83|  0.86| -0.43|\n| 139.70|  36.49|    0.05|    0.06|  0.06| -0.05|\n| 136.52|  31.86|   -0.06|   -0.25| -0.26|  0.04|\n| 156.84|  53.04|    0.67|    1.18|  1.23| -0.59|\n| 145.42|  41.28|    0.26|    0.38|  0.40| -0.23|\n| 163.83|  62.99|    0.93|    1.86|  1.92| -0.79|\n:::\n:::\n\n\nAlthough the pairs of coordinates are radically different, we easily recognize the same constellation of data in the plots, regardless of coordinate system.\n\nWe have seen how translating the origin of the coordinate system to the center of the data helps us interpret the data. But how could rotating the coordinate system be helpful?\n\nIn most studies, we measure stuff because we know that the things we're studying -- people in this case -- vary, and it is exactly this variation that we want to understand. What if we rotated the coordinate system so that the variance of the data was maximized along the $x$-axis? Then, in this rotated coordinate system, folks with large positive values on the $x$-axis would be maximally \"different\" from folks with large negative values on the $x$-axis in \"*height-weight*\" space. Differences in $y$-values would then be less important in distinguishing individuals.\n\nWe can find the rotation that maximizes variance along the $x$-axis by trial and error: simply choose different angles, compute the rotation, and then compute the variance or standard deviation along the $x$-axis. Rinse and repeat unit you find an angle that maximizes the standard deviation. There will be two such angles, each $\\pi$ radians (180 degrees) apart:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run this code over and over with\n# different values for the angle\n# until sd(d$x) is at a maximum.\nangle <- -0.78 # This angle comes close; -0.78 + pi would also come close\nd$x <- d$zheight * cos(angle) - d$zweight * sin(angle)\nsd(d$x) # We could also use var(d$x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.393114\n```\n:::\n:::\n\n\nA second way would be to use R's `optim` function, which automates the above process:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This function rotates and then\n# computes sd along x.\n\nsd_x <- function(angle) {\n  sd(d$zheight * cos(angle) - d$zweight * sin(angle))\n}\n\n# This function finds the angle that \n# maximizes the above function\nopt <- \n  optim(\n    0, # Starting value of angle\n    sd_x, # The function to minimize\n    method = \"Brent\", # The optim procedure that works best in 1-D\n    lower = -pi,\n    upper = pi,\n    control = list(fnscale = -1) # Maximize instead of minimize\n    )\n```\n:::\n\n\nAn angle of rotation (in radians) that maximizes sd along x: \n\n`opt$par` = -0.7853982 \n\nThe maximized standard deviation: \n\n`opt$value` = 1.393134\n\nLet's plot our data using that optimal angle of rotation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# one optimal angle in radians;\n# the other would be opt$par + pi\nangle <- opt$par \n\n# New x and y coordinates after rotation\nd$x <- d$zheight * cos(angle) - d$zweight * sin(angle)\nd$y <- d$zheight * sin(angle) + d$zweight * cos(angle)\n\nggplot(d, aes(x, y)) + \n  geom_point(alpha = 0.5) +\n  geom_point(x = 0, y = 0, colour = 'red', size = 3) +\n  coord_fixed(xlim = c(-4, 3), ylim = c(-3, 3)) +\n  labs(title = \"!Kung heights and weights rotated to maximize variance along x-axis\", subtitle = \"Each black dot represents one person.\\nThe red dot indicates the origin of the coordinate system.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nGuess what? The $x$-axis is principal component 1 (PC1), and the $y$-axis is principle component 2 (PC2), as we can confirm by comparing our results to those from R's `prcomp` (principal component) function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute PCA using the standard R function\nm <- prcomp(~ zheight + zweight, data = d)\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nImportance of components:\n                          PC1     PC2\nStandard deviation     1.3931 0.24326\nProportion of Variance 0.9704 0.02959\nCumulative Proportion  0.9704 1.00000\n```\n:::\n\n```{.r .cell-code}\n# Compare the standard deviations above with:\nsd(d$x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.393134\n```\n:::\n\n```{.r .cell-code}\nsd(d$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2432649\n```\n:::\n:::\n\n\nCompare our x & y values...\n\n\n\n|          x|          y|\n|----------:|----------:|\n|  0.9326787|  0.2409332|\n|  0.0788411|  0.0052468|\n| -0.2244852| -0.1354080|\n|  1.3134063|  0.3613867|\n|  0.4554072|  0.0890045|\n|  1.9703735|  0.6604768|\n\n\n\n... with those from `prcomp`\n\n\n\n|        PC1|        PC2|\n|----------:|----------:|\n| -0.9326787| -0.2409332|\n| -0.0788411| -0.0052468|\n|  0.2244852|  0.1354080|\n| -1.3134063| -0.3613867|\n| -0.4554072| -0.0890045|\n| -1.9703735| -0.6604768|\n\n\n\nThe minus signs are reversed because the axes are rotated 180 degrees, but the variance is still maximized along the x-axis (remember, there are 2 rotations that will maximize the variance).\n\nIn summary, principal components are simply a new orthogonal (perpendicular) coordinate system for your data, rotated so the variance of your data is maximized along the first axis (PC1); then, rotating around the first axis, the remaining variance is maximized along the second axis (PC2), which is perpendicular to the first; and so forth, until the directions of all axes are specified. Thus, there will be as many principal components as there are dimensions in your data (i.e., number of variables), and the variance will decrease across each successive component across each successive component.\n\nThere are many uses of this new coordinate system. In our example, 97% of the variance in our data falls along PC1. Thus, we might interpret PC1, which is a combination of height and weight, as something like *size*. By rotating our coordinate system, we have identified underlying \"structure\" in our data. For 2-d data like our example, PCA is not that useful. But when our data have many dimensions, PCA and related techniques can find structure that would be difficult or impossible to find without them.\n\n---\n\n*Note #1: The `prcomp` and other PCA functions do not find these rotations in the same way we did. Instead, they use methods like singular value decomposition, which you can read about on [wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis).*\n\n*Note #2: You might have heard of rotation after PCA, or terms like varimax rotation. These also seek useful rotations, but are distinct from PCA. You can read more about them, and their relationship to PCA [here](https://stats.stackexchange.com/questions/612/is-pca-followed-by-a-rotation-such-as-varimax-still-pca), [here](https://stats.stackexchange.com/questions/151653/what-is-the-intuitive-reason-behind-doing-rotations-in-factor-analysis-pca-how), and [here](https://stats.stackexchange.com/questions/160422/what-are-rotated-and-unrotated-principal-components-given-that-pca-always-r).*\n\n*Note #3: There is a great set of alternative explanations of PCA [here](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues) .*",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}